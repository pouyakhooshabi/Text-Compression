{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S10vWFPyJYdD"
   },
   "source": [
    "# COMP 6321 Assignment 1: Predictive Compression\n",
    "\n",
    "This assignment asks you to do text compression using machine learning. Specifically, you're going to train machine learning models to predict \"the next symbol\" in a string and, by making \"the next symbol\" more predictable, you will make the string easier to compress. Like most real-world problems, a lot of the work is in understanding the problem setup.\n",
    "\n",
    "To understand the idea, ask yourself: if you were given 5 symbols, `impor`, what would you guess for the *next symbol*? If those 5 symbols are enough to predict that the next symbol is a `t`, then there's no need to actually store the code for `t`! \n",
    "\n",
    "<img src=\"img/shannon.png\" style=\"float:left; margin-right:8px\"/>\n",
    "\n",
    "In fact, [Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon#/media/File:ClaudeShannon_MFO3807.jpg), the developer of information entropy, performed this exact experiment by asking his human colleagues to \"guess the next letter\" from context. Read page 1 of Peter Fenwick's [*Symbol Ranking Text Compression with Shannon Recodings*](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.4148&rep=rep1&type=pdf). Question 3 of this assignment will ask you to implement compression using Shannon's \"second method\" (symbol rank encoding), where the classifier you trained in Question 2 plays the role of the \"guesser\". The better the guess, the more compressible the ranks are.\n",
    "\n",
    "To understand how symbol rank encoding works, **consider a toy example**. Assume the symbol alphabet is $\\{a,b,c\\}$, for simplicity. A \"guesser\" receives one \"previous symbol\" and must guess a probabily for each possible \"next symbol.\" The example guesser shown below (at left) believes that strings like `abcabc` are most probable whereas strings like `aaaaaa` or `bbbbbb` are improbable. The steps below depict how these probabilities are used to rank-encode the example string `[a,b,c,b,c]` as sequence of numbers `[0,0,0,1,0]`.\n",
    "\n",
    "<img src=\"img/rank-encoding-1.png\" width=750px/>\n",
    "\n",
    "Notice that, in the rank encoding, the first `b` was encoded as 0, but the second `b` was encoded as 1 because the toy guesser expected `a` to be more probable, based on the previous symbol (i.e., the context).\n",
    "\n",
    "When symbols are predicted correctly (or approximately-correctly), a rank-encoding is more compressible by a Huffman encoder because the new representation (rank ordinals) has lower information entropy than the original (ASCII ordinals)!\n",
    "\n",
    "<img src=\"img/rank-encoding-2.png\" width=520px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnlx4gJwJYdV"
   },
   "source": [
    "---\n",
    "\n",
    "The assignment is very much like a lab, in that many steps build on each other. The main differences are:\n",
    "1. the assignment combines multiple machine learning concepts, rather than one theme;\n",
    "2. the assignment becomes more open-ended as questions progress, with fewer \"guardrails\";\n",
    "3. the assignment will be more carefully graded, including code quality; and\n",
    "4. where <span style=\"color:#080;font-weight:bold\">specified</span>, you must add comments to your code.\n",
    "\n",
    "The goal of the assignment is to exposes you to:\n",
    "* Building a machine learning system for a real practical purpose (compression).\n",
    "* Designing custom scikit-learn data transformers (converting dicts &amp; strings to features) and all the software engineering challenges there,\n",
    "* Doing model selection over a pipeline with configurable stages (hyperparameter search).\n",
    "* Using a loss function (classification performance) that differs from the ultimate measure of success (compression ratio).\n",
    "\n",
    "**Grading.** There are 5 questions: Q1 (20 marks), Q2 (30 marks), Q3 (25 marks), Q4 (30 marks), Q5 (5 BONUS marks).\n",
    "\n",
    "**Rules for academic integrity:**\n",
    "* Like labs, students are encouraged to ask conceptual questions of TAs and of other students, and can answer each others' *conceptual* questions.\n",
    "* Unlike labs, students are *not* allowed to post example code in a public forum, even if the code is wrong; code and pseudocode can only be shared with TAs when requesting help.\n",
    "* Never ask for, or offer, code snippets for the assignment to your fellow students. Doing so is forbidden, and is a major violation of academic integrity, both of the person who shared the code and the person who accepted the code. Violations of academic integrity will be reported to the Dean's Office. Violators risk their academic standing.\n",
    "* *Never* post your assignment on the internet, including Github, even after the course completes; see above rule.\n",
    "\n",
    "**Read the statement below and insert your name:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG4gfbtVJYdZ"
   },
   "source": [
    "I, Pooya Khoshabi, hereby confirm that I have understood and at all times adhered to the above rules of academic integrity, and to the academic code of conduct at Concordia University. All completed steps of this submitted assignment are my own independent work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez62uxEFJYdb"
   },
   "source": [
    "**Advice:**\n",
    "* *Invest in plotting.* Plotting is super important for ML and for data sciences generally. So, put in the time to learn how to make plots properly.\n",
    "* *Set random_state whenever applicable.* Some steps of the assignment involve randomness, usually when calling scikit-learn functions. In order to make your assignment reproducible, you must set the *random_state* to some constant (e.g. 0) whenever applicable.\n",
    "* *Save your notebook frequently.* Although Jupyter notebooks are mostly reliable, it is possible to encounter an erroneous state, where the most recent changes cannot be saved to disk by the notebook's own save functionality.\n",
    "\n",
    "**Run the code cell below** to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmQsH2B580Ii",
    "outputId": "afa64532-53fc-4889-cf79-858b67a4454a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.23.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/c3/5f6e7317246d39b1921d3b697b4e419657eb728a1f02f9df4a019a35ccaf/scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3MB 11.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0) (1.19.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0) (1.0.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed scikit-learn-0.23.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "euPWOSg7JYde"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.feature_selection\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.utils.estimator_checks\n",
    "import zipfile \n",
    "import urllib\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "# Download huffman.py from github before importing\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/soxofaan/dahuffman/' +\n",
    "                           '7bbc964cee6947545ee4dfb4456c96c9be44cebc/dahuffman/' +\n",
    "                           'huffmancodec.py', 'huffman.py')\n",
    "import huffman\n",
    "\n",
    "# Matplotlib might complain if lots of figures are generated; suppress that warning.\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex2UG6-9JYdg"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q1 &mdash; Download and compress text files [20 marks total]\n",
    "\n",
    "This question asks you to download some example Python source code, and then compress it using a Python implementation of Huffman encoding. The specific source code you'll compress will be from scikit-learn's Github repository.\n",
    "\n",
    "The reason to download a copy of scikit-learn's source code is *not* to install or to run it. In fact, you do not even need to extract the zip file. The *only* reason for downloading it to have some example Python source code.\n",
    "\n",
    "Later on in the assignment, you will try to improve the compression using machine learning. In other words, you will be using your already-installed scikit-learn package to compress the separate scikit-learn source code that you just downloaded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh_oSmhyJYdh"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1a &mdash; Download Python code to use for training and testing [10 marks]*\n",
    "\n",
    "**Download some example Python source code.** Specifically, download the source code to scikit-learn version 0.24.1 as a zip file. To do this, visit the scikit-learn github repository, find the tag `0.24.1`, click \"browse files\" and find the URL for `0.24.1.zip`.\n",
    "\n",
    "You should do the download *procedurally*, by writing code in the code cell below, so that any time your notebook is run it will automatically download the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0e6UDsFJYdj",
    "outputId": "14b80f31-c3b1-45b0-836a-f80f3f2b0451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.24.1.zip', <http.client.HTTPMessage at 0x7f96ae933550>)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here.\n",
    "url = 'https://github.com/scikit-learn/scikit-learn/archive/0.24.1.zip' \n",
    "urllib.request.urlretrieve (url, '0.24.1.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2W1oY_NJYdn"
   },
   "source": [
    "**Implement *read_textfiles***. Use the *zipfile* package that is built in to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ciZWj40-JYdr"
   },
   "outputs": [],
   "source": [
    "def read_textfiles(zip_file: str, name_filter, maxbytes=None):\n",
    "    \"\"\"\n",
    "    Open a zip file and returns two lists:\n",
    "      names: list of file names for which name_filter(name) returned True\n",
    "      texts: list of bytes objects with corresponding file contents.\n",
    "    If maxbytes is specified, only the first maxbytes of each file will be read.\n",
    "    \"\"\"\n",
    "    # Your implementation here.\n",
    "    from zipfile import ZipFile\n",
    "    file_name = zip_file\n",
    "    with ZipFile(file_name, 'r') as zip:\n",
    "        path_name = zip.namelist()\n",
    "        names = []\n",
    "        texts = []\n",
    "        for i in path_name:\n",
    "            if i.endswith(name_filter):\n",
    "                names.append(i)\n",
    "                if maxbytes != None:\n",
    "                    texts.append(zip.read(i)[:maxbytes])\n",
    "                else:\n",
    "                    texts.append(zip.read(i))\n",
    "    return names, texts         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDu-NwMCJYdv"
   },
   "source": [
    "**Load a training and test set.** Create two global variables, each referring to what we'll call a \"text list\" (a list of *bytes* objects). One variable should refer to a list of *bytes* objects containing source code from training files, and likewise the other should refer to data from testing files.\n",
    "* training set is the three files ending with `/kernels.py`, `/_logistic.py`, and `/_gaussian_mixture.py`\n",
    "* testing set is the two file ending with `/_ridge.py` and `/naive_bayes.py`\n",
    "\n",
    "To keep reasonably training fast, load only the first 10,000 bytes of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zNIn_aI2JYdw"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "train = []\n",
    "test = []\n",
    "for i in ['/kernels.py', '/_logistic.py', '/_gaussian_mixture.py']:\n",
    "    train.append(read_textfiles(zip_file = '0.24.1.zip', name_filter= i, maxbytes=10000)[1][0])\n",
    "for i in ['/_ridge.py', '/naive_bayes.py']:\n",
    "    test.append(read_textfiles(zip_file = '0.24.1.zip', name_filter= i, maxbytes=10000)[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dprNjvCXJYd_"
   },
   "source": [
    "**Implement *preview_textlist*** and **run it on your training and test sets** so that you and the TA can see excerpts of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PH_AfBiJYd_",
    "outputId": "b7c79f47-f1be-4b54-b956-1103c5e5045b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 2 files totaly 20000 bytes: \n",
      "\n",
      "b'\"\"\"\\nRidge ' \n",
      "\n",
      "b'# -*- codi' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_is_textlist(x):\n",
    "    if not isinstance(x, list) or \\\n",
    "       not all(isinstance(text, bytes) for text in x):\n",
    "        raise ValueError(\"Expected textlist\")\n",
    "\n",
    "def preview_textlist(x: list, maxitems=5, maxbytes=100):\n",
    "    \"\"\"\n",
    "    Prints some example excerpts from the entries of x.    \n",
    "    Up to maxitems entries are shown, and for each up to\n",
    "    maxbytes are printed in the preview.\n",
    "    \n",
    "    For example:\n",
    "       >>> x = [b'good', b'luck on', b'the assignment']\n",
    "       >>> preview_textlist(x, maxfiles=2, maxbytes=4)\n",
    "       Contains 3 file(s) totalling 25 bytes:\n",
    "       \n",
    "       b'good'\n",
    "\n",
    "       b'luck'\n",
    "    \"\"\"\n",
    "    check_is_textlist(x)\n",
    "    # Your implementation here\n",
    "    number_bytes = 0\n",
    "    for i in x:\n",
    "        number_bytes += len(i)\n",
    "    print('contains %d files totaly %d bytes: \\n' %(len(x), number_bytes))\n",
    "    for i in x[:maxitems]:\n",
    "        print (i[:maxbytes], '\\n')\n",
    "\n",
    "# Call your implementation here\n",
    "preview_textlist(x= test, maxitems=2, maxbytes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHAzssg7JYeB"
   },
   "source": [
    "**Define a complete alphabet.** When training on categorical features or targets, whether they be ASCII symbols like $\\{a,b,c\\}$ or job titles like $\\{teacher,police,doctor\\}$, it is important to not assume that your training set contains all the symbols (categories) for which you need to make predictions. Why? Because training sets are often split up in arbitrary ways, such as for cross-validation; if one of those chunks is missing a category that you need to make predictions from, then it will cause your ML system to raise annoying errors at test time or at cross-validation time, often after lots of CPU time invested. So, use the code cell below to define an *ALPHABET* global variable for later use.\n",
    "\n",
    "Ensure *ALPHABET*'s symbols appear in order of increasing ordinal value. Explicitly add the NULL byte with ordinal value 0 (`\\x00`), since it will be used to mean \"no symbol\" later on. Print *ALPHABET*'s length and contents, like below but with `?` replaced with values:\n",
    "```\n",
    "??? symbols\n",
    "b'\\x00??????????????????????....'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay-UkEygJYeC",
    "outputId": "aa8699e9-ec7a-43b6-f9ac-8869b99678b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 symbols\n",
      "b'\\x00\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "ALPHABET = b'\\x00\\n' + bytes(range(32,127))\n",
    "print(len(ALPHABET), 'symbols')\n",
    "print(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "92VKg_pdQl8p"
   },
   "outputs": [],
   "source": [
    "#ALPHABET = b'\\0'+b'\\n'+b' '+b'!'+b'\"'+b'#'+b'%'+b\"'\"+b'('+b')'+b'*'+b'+'+b','+b'-'+b'.'+b'/'+b'0'+b'1'+b'2'+b'3'+b'4'+b\"5\"+b'6'+b'7'+b'8'+b'9'+b':'+b';'+b'<'+b'='+b'>'+b'@'+b'A'+b'B'+b'C'+b'D'+b'E'+b'F'+b'G'+b'H'+b'I'+b'J'+b'K'+b'L'+b'M'+b'N'+b'O'+b'P'+b'R'+b'S'+b'T'+b'U'+b'V'+b'W'+b'X'+b'Y'+b'['+b'\\x5C' +b']'+b'^'+b'_'+b'`'+b'a'+b'b'+b'c'+b'd'+b'e'+b'f'+b'g'+b'h'+b'i'+b'j'+b'k'+b'l'+b'm'+b'n'+b'o'+b'p'+b'q'+b'r'+b's'+b't'+b'u'+b'v'+b'w'+b'x'+b'y'+b'z'+b'{'+b'|'+b'}'+b'~'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gq2EUFsJYeD"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1b &mdash; Define a scikit-learn Transformer to compress text files [10 marks]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtaD30I8JYeE"
   },
   "source": [
    "**Define a *HuffmanEncoder* transformer class.** Define a custom scikit-learn transformer, so that the following code would run:\n",
    "```python\n",
    ">>> x = [b'aaaa', b'bbb']\n",
    ">>> huff = HuffmanEncoder()\n",
    ">>> huff.fit(x).transform(x)   # Success!\n",
    "[b'\\n', b'\\xfe']\n",
    ">>> huff.fit_transform(x)      # Same, provided by TransformerMixin!\n",
    "[b'\\n', b'\\xfe']\n",
    ">>> z = [b'c']                 # New text not in training set\n",
    ">>> huff.transform(z)          # Uh-oh, unrecognized symbol 'c' (ord 99)\n",
    "KeyError: 99\n",
    ">>> HuffmanEncoder(alphabet=b'abc').fit(x).transform(z)  # Force 'c' into alphabet\n",
    "[b'\\x94']\n",
    "\n",
    "```\n",
    "And as for all steps in this assignment it's important to do basic sanity checks of arguments:\n",
    "```python\n",
    ">>> huff = HuffmanEncoder()\n",
    ">>> huff.transform(x)          # Checks that fit() has been called\n",
    "NotFittedError: This HuffmanEncoder instance is not fitted yet.\n",
    ">>> huff.fit(x, y=[1,2,3])     # Checks that y arg not used\n",
    "ValueError: Expected None\n",
    ">>> huff.fit(b'abc')           # Checks that x is a textlist\n",
    "ValueError: Expected textlist\n",
    "\n",
    "```\n",
    "\n",
    "To do this correctly, you're going to want to:\n",
    "1. Look at the *a1-intro.ipynb* notebook and learn how the downloaded *huffman* Python module could help make your class very easy to implement. All the pieces you need are there, including \"dealing with unrecognized symbols.\"\n",
    "2. Look at examples of how other scikit-learn transformers have been implemented, such as the [source code for *StandardScaler*](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/preprocessing/_data.py#L564), and understand why it inherits both [*BaseEstimator*](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) and [*TransformerMixin*](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html). \n",
    "3. Understand scikit-learn conventions around \"[estimated attributes](https://scikit-learn.org/stable/developers/develop.html#estimated-attributes)\" to signify that *fit* has been called, the meaning of \"trailing underscores\", the fact that estimator attributes are \"cloned\" from the original prototype argument before *fit* (important for making hyperparameter search work), and how [*check_is_fitted*](https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html) automatically raises *NotFittedError* for you.\n",
    "\n",
    "The documentation on [developing scikit-learn estimators](https://scikit-learn.org/stable/developers/develop.html) may also help, although it discusses many features you do not need for this particular exercise. Your *HuffmanEncode* class transforms a *list* object to a new *list* object, rather than an $\\mathbf{X}$ matrix. As such, it will not pass the checks by *sklearn.utils.estimator_checks.check_estimator*, but that is OK! \n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oR2ETtALJYeV"
   },
   "outputs": [],
   "source": [
    "def check_is_none(y):\n",
    "    if y is not None:\n",
    "        raise ValueError(\"Expected None\")\n",
    "            \n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/soxofaan/dahuffman/' +\n",
    "                           '7bbc964cee6947545ee4dfb4456c96c9be44cebc/dahuffman/' +\n",
    "                           'huffmancodec.py', 'huffman.py')\n",
    "import huffman\n",
    "import sys        \n",
    "        \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from collections import Counter\n",
    "#from sklearn.utils.validation import check_is_fittedclass \n",
    "\n",
    "# Your class definition here. You can also import whatever you need.\n",
    "class HuffmanEncoder(TransformerMixin, BaseEstimator):\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, alphabet=b''):\n",
    "        self.alphabet= alphabet\n",
    "        self.encoded= None\n",
    "        self.transformed_values= []\n",
    "        self.decoded_values= []\n",
    "\n",
    "    def check_fitted(self):\n",
    "        sklearn.utils.validation.check_is_fitted(self)    \n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        check_is_none(y)\n",
    "        check_is_textlist(x)\n",
    "        \n",
    "        \n",
    "        words = b''\n",
    "        for i in x:\n",
    "            words = words + i \n",
    "        if self.alphabet == b'':\n",
    "            self.encoded = huffman.HuffmanCodec.from_data(words)\n",
    "        else:\n",
    "            freqs_data = Counter(words)\n",
    "            freqs_min = Counter({c: 1e-6 for c in self.alphabet})\n",
    "            freqs = freqs_data | freqs_min\n",
    "            self.encoded = huffman.HuffmanCodec.from_frequencies(freqs, concat=bytes)\n",
    "        \n",
    "        self.alphabet_ = self.alphabet #just wanted to satisfy the check_fitted method while compiling.    \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        self.check_fitted()\n",
    "        check_is_textlist(x)\n",
    "        \n",
    "        self.transformed_values = []\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            for j in x:\n",
    "                self.transformed_values.append(self.encoded.encode(j))\n",
    "        except KeyError as e:\n",
    "                print(\"KeyError:\", e)\n",
    "                \n",
    "        return self.transformed_values   \n",
    "    \n",
    "    def score(self, x, y=0):\n",
    "        fit = self.fit_transform(x)\n",
    "        uncompressed = sum(len(i) for i in x) \n",
    "        compressed   = sum(len(j) for j in fit) \n",
    "        #print('uncompressed: ', uncompressed)\n",
    "        #print('compressed: ', compressed)\n",
    "        return uncompressed/compressed\n",
    "    \n",
    "    def inverse_transform(self, x, y=None):\n",
    "        for i in x:\n",
    "            self.decoded_values.append(self.encoded.decode(i))\n",
    "        return self.decoded_values \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSksTIaYJYeX"
   },
   "source": [
    "**Preview Huffman-encoded versions of your datasets.** The output should be similar to your earlier preview, except the total bytes should be smaller and the data should mostly be non-printable byte codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIKoyJTcJYeY",
    "outputId": "dde0cccc-49c4-42e4-f1ce-15a5e8b121ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed1: [b'\\xf0', b'T']\n",
      "compressed2: [b'\\xf0', b'T']\n",
      "compressed4: [b'\\x94']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#================================================================\n",
    "#part1\n",
    "x = [b'aaaa', b'bbb']\n",
    "z = [b'c'] \n",
    "huff = HuffmanEncoder()\n",
    "compressed1 = huff.fit(x).transform(x) \n",
    "compressed2 = huff.fit_transform(x)\n",
    "#compressed3 = huff.transform(z) #contains error\n",
    "compressed4 = HuffmanEncoder(alphabet=b'abc').fit(x).transform(z)\n",
    "\n",
    "print('compressed1:' ,compressed1)\n",
    "print('compressed2:' ,compressed2)\n",
    "#print('compressed3:' ,compressed3) \n",
    "print('compressed4:' ,compressed4)\n",
    "#================================================================\n",
    "#part2\n",
    "#huff = HuffmanEncoder()   \n",
    "#huff.transform(x)         #contains error\n",
    "#huff.fit(x, y=[1,2,3])    #contains error             \n",
    "#huff.fit(b'abc')          #contains error \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3q4wKGK3JYea"
   },
   "source": [
    "**Implement a *score* method** on your *HuffmanEncode* class definition. Do so by editing the earlier code cell. A *HuffmanEncode* object should score a text list by returning the [compression ratio](https://en.wikipedia.org/wiki/Data_compression_ratio) achieved. For example:\n",
    "```python\n",
    ">>> huff.score(x)   # If hypothetically a 3.5x compression ratio\n",
    "3.5\n",
    "```\n",
    "In the code cell below, print the compression ratio of your training and (separately) testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRg85CVSJYea",
    "outputId": "7c13cd18-6121-40f8-d83c-f125ee14db7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train compression ratio:  1.7361111111111112\n",
      "test compression ratio:  1.734304543877905\n"
     ]
    }
   ],
   "source": [
    "# Print the compression ratios of your training and testing sets here\n",
    "huff = HuffmanEncoder()\n",
    "huff.fit(train).transform(train) \n",
    "print('train compression ratio: ', huff.score(train))\n",
    "\n",
    "huff.fit(test).transform(test)\n",
    "print('test compression ratio: ',huff.score(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dp8pBZmJYeb"
   },
   "source": [
    "**Implement an *inverse_transform* method** on your *HuffmanEncode* class definition in the earlier code cell. Just like for other scikit-learn transformers, this should \"undo\" the transformation (i.e., decompress a compressed textlist). Once you have added that function, use it in the code cell below to **assert that it decompresses your training and (separately) testing data correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htGW5oXvJYec",
    "outputId": "d7a61043-4033-486b-c06d-7ea002731f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'aaaa', b'bbb']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your assertions here\n",
    "huff = HuffmanEncoder()\n",
    "compressed = huff.fit(x).transform(x) \n",
    "huff.inverse_transform(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4662Se3JYec"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q2 &mdash; Extract features and train a model [30 marks total]\n",
    "\n",
    "This question is a simplified version of the core learning task of the assignent. Specifically, you'll extract features and train a \"next symbol predictor\", but in a way that only requires small, easy, isolated steps, without any fancy software engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov-5MHvjJYed"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2a &mdash; Extract symbol context features [10 marks]*\n",
    "\n",
    "**Implement *extract_text_context*.** For example:\n",
    "```python\n",
    ">>> extract_text_context(b'ABCDEFG', 3)\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'B', b'C', b'D'],\n",
    "       [b'C', b'D', b'E'],\n",
    "       [b'D', b'E', b'F']], dtype='|S1')\n",
    "```\n",
    "Use Numpy effectively in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCXSdRJOJYee",
    "outputId": "5a08c23c-116c-4f2e-a2e2-6f55895370a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'A'],\n",
       "       [b'', b'A', b'B'],\n",
       "       [b'A', b'B', b'C'],\n",
       "       [b'B', b'C', b'D'],\n",
       "       [b'C', b'D', b'E'],\n",
       "       [b'D', b'E', b'F']], dtype='|S1')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text_context(text: bytes, size):\n",
    "    \"\"\"\n",
    "    Returns an array X representing the ASCII symbol context\n",
    "    that preceeded each byte position of byte string 'text'.\n",
    "    \n",
    "    Specifically, row X[i,:] contains the 'size' symbols that\n",
    "    preceeded the symbol text[i]. If no such symbol existed,\n",
    "    (too close to start) a NULL byte (0) is used in its place.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    buffer = np.frombuffer(text, dtype='|S1')\n",
    "    X = np.full((len(text),size), b'')\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        for j in range(size):\n",
    "            if i<size:\n",
    "                if i+j <size:\n",
    "                    X[i,j] = b''   \n",
    "                else:\n",
    "                    X[i,j] = buffer[i+j-size]\n",
    "            else:\n",
    "                X[i,:] = np.frombuffer(text, dtype='|S1', count=size, offset=i-size)  \n",
    "    return X           \n",
    "\n",
    "extract_text_context(b'ABCDEFG', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnbGKDsqJYef"
   },
   "source": [
    "**Implement *extract_context*.** This will be useful for converting a list of *bytes* objects into a feature matrix. For example:\n",
    "```python\n",
    ">>> extract_context([b'ABCD', b'EFG'], 3)\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-djRGEOmJYek",
    "outputId": "91d3a08a-7899-40ba-b67f-12f9a0d64d0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'A'],\n",
       "       [b'', b'A', b'B'],\n",
       "       [b'A', b'B', b'C'],\n",
       "       [b'', b'', b''],\n",
       "       [b'', b'', b'E'],\n",
       "       [b'', b'E', b'F']], dtype='|S1')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_context(x: list, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a concatenation of all context features extracted\n",
    "    from every text string in the given filedict, in the order\n",
    "    that the text entries appear. Any extra arguments are\n",
    "    forwarded to extract_text_context.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "\n",
    "    list_of_features = None\n",
    "    for i in x:\n",
    "        temp = extract_text_context(i, *args, **kwargs)\n",
    "\n",
    "        if list_of_features is None:\n",
    "          list_of_features = extract_text_context(i, *args, **kwargs)\n",
    "\n",
    "        else:\n",
    "          list_of_features = np.concatenate((list_of_features, temp), axis=0)  \n",
    "    \n",
    "    return list_of_features\n",
    "    \n",
    "\n",
    "extract_context([b'ABCD', b'EFG'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1jNVdTtJYel"
   },
   "source": [
    "**Implement *make_sklearn_dataset*.** This function is just a convenient way to get not just the context features $\\mathbf{X}$ but also corresponding targets $\\mathbf{y}$ for scikit-learn style training or testing.\n",
    "```python\n",
    ">>> X, y = make_sklearn_dataset([b'ABCD', b'EFG'], 3)\n",
    ">>> X\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    ">>> y\n",
    "array([b'A', b'B', b'C', b'D', b'E', b'F', b'G'], dtype='|S1')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHs7usk2JYeo",
    "outputId": "40fa298d-e9f0-4e64-d844-29b388810b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[b'', b'', b''],\n",
       "        [b'', b'', b'A'],\n",
       "        [b'', b'A', b'B'],\n",
       "        [b'A', b'B', b'C'],\n",
       "        [b'', b'', b''],\n",
       "        [b'', b'', b'E'],\n",
       "        [b'', b'E', b'F']], dtype='|S1'),\n",
       " array([b'A', b'B', b'C', b'D', b'E', b'F', b'G'], dtype='|S1'))"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_sklearn_dataset(x: list, *args, **kwargs):\n",
    "    \"\"\"    \n",
    "    Converts a list of bytes objects into arrays X and y suitable\n",
    "    for use as a dataset with a scikit-learn estimator.\n",
    "    \"\"\"\n",
    "    # Your implementation here.\n",
    "    X = extract_context(x, *args, **kwargs)\n",
    "    \n",
    "    buffer = b''\n",
    "    for i in x:\n",
    "        buffer = buffer + i\n",
    "    y = np.frombuffer(buffer, dtype='|S1')\n",
    "    \n",
    "    return X , y\n",
    "make_sklearn_dataset([b'ABCD', b'EFG'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZJ9tfPbJYep"
   },
   "source": [
    "**Convert your training and test sets to arrays.** Use your *make_sklearn_dataset* function to build training and testing arrays. Each feature vector should contain the 5 ASCII symbols preceeding each corresponding target. In future steps we may refer to these arrays as $(\\mathbf{X}_\\text{trn}, \\mathbf{y}_\\text{trn})$ and $(\\mathbf{X}_\\text{tst}, \\mathbf{y}_\\text{tst})$. Your code cell should also **print the first 10 rows of your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{y}_\\text{trn}$ arrays, then $\\mathbf{X}_\\text{tst}$ and $\\mathbf{y}_\\text{tst}$ arrays**, so that the TA can see your raw symbol features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1SxC6OC_JYeq",
    "outputId": "2112feff-139b-4e63-8663-04c3dbf66e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrn is:\n",
      " [[b'' b'' b'' b'' b'']\n",
      " [b'' b'' b'' b'' b'\"']\n",
      " [b'' b'' b'' b'\"' b'\"']\n",
      " [b'' b'' b'\"' b'\"' b'\"']\n",
      " [b'' b'\"' b'\"' b'\"' b'K']\n",
      " [b'\"' b'\"' b'\"' b'K' b'e']\n",
      " [b'\"' b'\"' b'K' b'e' b'r']\n",
      " [b'\"' b'K' b'e' b'r' b'n']\n",
      " [b'K' b'e' b'r' b'n' b'e']\n",
      " [b'e' b'r' b'n' b'e' b'l']]\n",
      "ytrn is:\n",
      " [b'\"' b'\"' b'\"' ... b'v' b'a' b'r']\n",
      "Xtst is:\n",
      " [[b'' b'' b'' b'' b'']\n",
      " [b'' b'' b'' b'' b'\"']\n",
      " [b'' b'' b'' b'\"' b'\"']\n",
      " [b'' b'' b'\"' b'\"' b'\"']\n",
      " [b'' b'\"' b'\"' b'\"' b'\\n']\n",
      " [b'\"' b'\"' b'\"' b'\\n' b'R']\n",
      " [b'\"' b'\"' b'\\n' b'R' b'i']\n",
      " [b'\"' b'\\n' b'R' b'i' b'd']\n",
      " [b'\\n' b'R' b'i' b'd' b'g']\n",
      " [b'R' b'i' b'd' b'g' b'e']]\n",
      "ytst is:\n",
      " [b'\"' b'\"' b'\"' ... b' ' b' ' b' ']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "Xtrn, ytrn = make_sklearn_dataset(train, 5)\n",
    "Xtst, ytst = make_sklearn_dataset(test, 5)\n",
    "print('Xtrn is:\\n' , Xtrn[0:10, :])\n",
    "print('ytrn is:\\n' , ytrn)\n",
    "print('Xtst is:\\n' , Xtst[0:10, :])\n",
    "print('ytst is:\\n' , ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhWClZAcJYet"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2b &mdash; Train a DummyClassifier to predict symbol probabilities  [10 marks]*\n",
    "\n",
    "**Train a *DummyClassifier* on your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{y}_\\text{trn}$ arrays.** Your code should:\n",
    "* Set the *strategy* argument to ensure *predict_proba* counts the frequency of each symbol in target vector $\\mathbf{y}_\\text{trn}$.\n",
    "* Force the *DummyClassifier* to output probabilities for every symbol in *ALPHABET*, not just those appearing in $\\mathbf{y}_\\text{trn}$.\n",
    "\n",
    "Your code cell should print the training and testing accuracy, and the *DummyClassifier*'s number of output classes, as in:\n",
    "```\n",
    "accuracy: trn=0.?????? tst=0.??????\n",
    "nclasses: ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rKqtZzOjJYev"
   },
   "outputs": [],
   "source": [
    "def add_alphabet(X, y, alphabet: bytes):\n",
    "    \"\"\"\n",
    "    Modify a training set so as to force a scikit-learn classifier\n",
    "    to be capable of outputting every symbol in the given alphabet,\n",
    "    even if those symbols did not appear in 'y'.\n",
    "    \n",
    "    For example:\n",
    "       >>> X_, y_, w_ = add_alphabet(X, y, b'abc')\n",
    "       >>> classifier.fit(X_, y_, sample_weight=w_)\n",
    "    \"\"\"\n",
    "    if alphabet is None:\n",
    "        return X, y, None\n",
    "    n, m = X.shape[0], len(alphabet)\n",
    "    X_ = X[np.maximum(0, np.arange(-m, n))]  # Works for sparse or dense\n",
    "    y_ = np.concatenate([np.frombuffer(alphabet, 'S1'), y])\n",
    "    w_ = np.concatenate([np.full(m, 1e-100), np.ones(n)])  # 1e-100 rather than 0.0; see https://github.com/scikit-learn/scikit-learn/issues/19654\n",
    "    return X_, y_, w_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjr6FmF2JYev",
    "outputId": "16249a6b-d3ed-43e4-d92e-1f0142aa0268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: trn= 0.260 tst=0.238\n",
      "nclasses: 97\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, y_train, w_train = add_alphabet(Xtrn, ytrn, ALPHABET)\n",
    "clf = sklearn.dummy.DummyClassifier(strategy='prior', random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight = w_train)\n",
    "train_accuracy  = sklearn.metrics.accuracy_score(y_train, clf.predict(X_train))\n",
    "test_accuracy   = sklearn.metrics.accuracy_score(ytst, clf.predict(Xtst))\n",
    "n_classes       = clf.n_classes_\n",
    "\n",
    "\n",
    "print(\"accuracy: trn= %.3f tst=%.3f\" %(test_accuracy, train_accuracy))\n",
    "print(\"nclasses: %d\" %(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xNaJMGrnJYew"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGixuYTnJYew"
   },
   "source": [
    "**Print an example of the *DummyClassifier*'s predictions.** Specifically, print the first 10 training targets in $\\mathbf{y}_\\text{trn}$ alongside the *DummyClassifier*'s predicted symbol. You should convert targets and predictions to *bytes*, so that the output is formatted like:\n",
    "```\n",
    "targets: b'??????????'\n",
    "predict: b'??????????'\n",
    "```\n",
    "where each `?` is replaced by a symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU7wtXFWJYex",
    "outputId": "0aae4626-cf24-4f33-a7c1-47a912c2ab8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  b'\"\"\"Kernels for Gauss'\n",
      "predict: b'                    '\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "target  = b''\n",
    "predict = b''\n",
    "for i in y_train[0+97:20+97]             : target  = target+i\n",
    "for i in clf.predict(X_train[0+97:20+97]): predict = predict+i\n",
    "print('target: ', target)\n",
    "print('predict:', predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n83i-U3-JYey"
   },
   "source": [
    "**Run the code cell below** to define a helpful function for printing symbols like `a` instead of `b'a'`. Just for readability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqStWZPxJYez",
    "outputId": "a1d5ddc5-65d4-47cb-9463-94e88042435c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', ' ', '\\\\n', '©']"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def as_printable(text: bytes):\n",
    "    \"\"\"\n",
    "    Converts each byte into a string suitable for printing and plots,\n",
    "    where most non-printable characters are converted to number strings.\n",
    "\n",
    "    For example:\n",
    "       >>> as_printable(b'ab \\n\\xa9')  # a, b, space, newline (10), copyright (169)\n",
    "       ['a', 'b', ' ', '\\\\n', '©']\n",
    "    \"\"\"\n",
    "    assert isinstance(text, bytes), \"Expected bytes object\"\n",
    "    return [chr(c) if chr(c).isprintable() else '\\\\n' if c == 10 else '\\\\'+str(c) for c in text]\n",
    "\n",
    "as_printable(b'ab \\n\\xa9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN11yN_cJYe1"
   },
   "source": [
    "**Print the *DummyClassifier*'s symbols and frequencies.** Figure out which attribute of your trained *DummyClassifier* are helpful here. Your cell output should look something like below with the `?` values filled in:\n",
    "```\n",
    "rank  frequency symbol\n",
    "0     0.??????  ?  \n",
    "1     0.??????  ?\n",
    "2     0.??????  ?\n",
    "...\n",
    "?     0.??????  ?\n",
    "```\n",
    "You can apply *as_printable* to the symbols if you like to make the printing nicer, but you do not have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETLPEcM_JYe2",
    "outputId": "ddb8da4c-2334-47e1-88e7-5717002645c9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank     freq                      symbol     \n",
      "0        0.2385                    b' '       \n",
      "1        0.07663333333333333       b'e'       \n",
      "2        0.056                     b'a'       \n",
      "3        0.0495                    b's'       \n",
      "4        0.04613333333333333       b'r'       \n",
      "5        0.045                     b't'       \n",
      "6        0.040933333333333335      b'n'       \n",
      "7        0.0373                    b'i'       \n",
      "8        0.034333333333333334      b'o'       \n",
      "9        0.030166666666666668      b'\\n'      \n",
      "10       0.026766666666666668      b'p'       \n",
      "11       0.023666666666666666      b'l'       \n",
      "12       0.022                     b'c'       \n",
      "13       0.020733333333333333      b'm'       \n",
      "14       0.019233333333333335      b'_'       \n",
      "15       0.017433333333333332      b'h'       \n",
      "16       0.0172                    b'f'       \n",
      "17       0.015366666666666667      b'u'       \n",
      "18       0.014833333333333334      b'd'       \n",
      "19       0.014333333333333333      b'.'       \n",
      "20       0.013533333333333333      b'-'       \n",
      "21       0.0117                    b','       \n",
      "22       0.009866666666666666      b'g'       \n",
      "23       0.009366666666666667      b'('       \n",
      "24       0.009333333333333334      b')'       \n",
      "25       0.008433333333333333      b'y'       \n",
      "26       0.0084                    b'\"'       \n",
      "27       0.007333333333333333      b':'       \n",
      "28       0.0067666666666666665     b'#'       \n",
      "29       0.0067666666666666665     b'v'       \n",
      "30       0.0056                    b'k'       \n",
      "31       0.0054                    b'='       \n",
      "32       0.005166666666666667      b'w'       \n",
      "33       0.004366666666666666      b'b'       \n",
      "34       0.0033                    b\"'\"       \n",
      "35       0.002766666666666667      b'x'       \n",
      "36       0.0022                    b'1'       \n",
      "37       0.0021333333333333334     b'X'       \n",
      "38       0.0020666666666666667     b'['       \n",
      "39       0.0020666666666666667     b']'       \n",
      "40       0.002033333333333333      b'T'       \n",
      "41       0.0017666666666666666     b'0'       \n",
      "42       0.0015666666666666667     b'*'       \n",
      "43       0.0015333333333333334     b'>'       \n",
      "44       0.0015                    b'z'       \n",
      "45       0.0014666666666666667     b'C'       \n",
      "46       0.0012666666666666666     b'R'       \n",
      "47       0.0009666666666666667     b'+'       \n",
      "48       0.0009                    b'P'       \n",
      "49       0.0008666666666666666     b'%'       \n",
      "50       0.0008333333333333334     b'E'       \n",
      "51       0.0008                    b'A'       \n",
      "52       0.0008                    b'N'       \n",
      "53       0.0007                    b'2'       \n",
      "54       0.0006                    b'L'       \n",
      "55       0.0006                    b'M'       \n",
      "56       0.0005333333333333334     b'B'       \n",
      "57       0.0005333333333333334     b'I'       \n",
      "58       0.0005333333333333334     b'V'       \n",
      "59       0.0005                    b'/'       \n",
      "60       0.0005                    b'G'       \n",
      "61       0.0005                    b'j'       \n",
      "62       0.0005                    b'q'       \n",
      "63       0.00046666666666666666    b'{'       \n",
      "64       0.00046666666666666666    b'}'       \n",
      "65       0.0004333333333333333     b'S'       \n",
      "66       0.0004                    b'@'       \n",
      "67       0.0004                    b'H'       \n",
      "68       0.00036666666666666667    b'<'       \n",
      "69       0.0003333333333333333     b'4'       \n",
      "70       0.0003                    b'3'       \n",
      "71       0.0003                    b'F'       \n",
      "72       0.0002666666666666667     b'`'       \n",
      "73       0.00023333333333333333    b'!'       \n",
      "74       0.00023333333333333333    b'5'       \n",
      "75       0.00023333333333333333    b'Y'       \n",
      "76       0.0002                    b'K'       \n",
      "77       0.0002                    b'O'       \n",
      "78       0.0002                    b'W'       \n",
      "79       0.00016666666666666666    b'6'       \n",
      "80       0.00013333333333333334    b'D'       \n",
      "81       0.0001                    b'8'       \n",
      "82       6.666666666666667e-05     b'\\\\'      \n",
      "83       3.3333333333333335e-05    b'J'       \n",
      "84       3.3333333333333335e-05    b'U'       \n",
      "85       3.3333333333333335e-105   b''        \n",
      "86       3.3333333333333335e-105   b'$'       \n",
      "87       3.3333333333333335e-105   b'&'       \n",
      "88       3.3333333333333335e-105   b'7'       \n",
      "89       3.3333333333333335e-105   b'9'       \n",
      "90       3.3333333333333335e-105   b';'       \n",
      "91       3.3333333333333335e-105   b'?'       \n",
      "92       3.3333333333333335e-105   b'Q'       \n",
      "93       3.3333333333333335e-105   b'Z'       \n",
      "94       3.3333333333333335e-105   b'^'       \n",
      "95       3.3333333333333335e-105   b'|'       \n",
      "96       3.3333333333333335e-105   b'~'       \n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "rank      = np.arange(0, n_classes)\n",
    "frequency = clf.class_prior_\n",
    "symbol    = clf.classes_  \n",
    "\n",
    "Dict = {}\n",
    "for i in range(0, len(rank)):\n",
    "    Dict[symbol[i]] = frequency[i]\n",
    "    \n",
    "Dict_sorted = {key: value for key, value in sorted(Dict.items(), key=lambda item: item[1], reverse=1)}\n",
    "\n",
    "general_dict = {}\n",
    "j= 0\n",
    "for i in Dict_sorted:\n",
    "    general_dict[rank[j]] = [Dict_sorted[i],i]\n",
    "    j = j+1\n",
    "    \n",
    "print (\"{:<8} {:<25} {:<10} \".format('rank','freq','symbol'))\n",
    "for k, v in general_dict.items():\n",
    "    freq, symbol  = v\n",
    "    print (\"{:<8} {:<25} {:<10} \".format(k, freq, symbol))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ4eRJhSJYe3"
   },
   "source": [
    "**Implement *plot_symbol_probs.*** This function visualizes the \"next symbol\" probabilities (the class probabilities) and the corresponding true symbols (the targets). When applied to your *DummyClassifier* and training set, your plot should look something like the one below. You will use this plotting function to visualize probabilities and predictions:\n",
    "<img src=\"img/symbol-probs-dummy.png\"/>\n",
    "*Hint:* Try using `colorbar(fraction=0.01, pad=0.01)` or similar to shrink the colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "TeBv7xA_JYe8",
    "outputId": "f44f6a9a-ad48-4c7f-f66c-62abad1fa082"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_symbol_probs(estimator, X, y, rows=20):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots a heatmap where each row shows two things:\n",
    "      1. a target symbol (shown as y-axis label, and by a white 'x'\n",
    "         in the column corresponding to that symbol)\n",
    "      2. the estimator's class probabilities when trying to predict\n",
    "         that symbol from context X (classes shown on x-axis labels).\n",
    "    The max number of rows (true next symbols) shown is given by 'rows'.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert sklearn.base.is_classifier(estimator)\n",
    "    # Your implementation here\n",
    "    \n",
    "    probability = np.zeros((rows,estimator.n_classes_))\n",
    "    for i in range(rows):\n",
    "        probability[i] = estimator.predict_proba(X)[i]\n",
    "\n",
    "    plt.figure(figsize=(20,5)) \n",
    "    for i in range(len(ALPHABET)):\n",
    "        for j in range(len(y[0:rows])):\n",
    "            if np.frombuffer(ALPHABET, dtype='S1')[i] == y[j]:\n",
    "                plt.plot(i, j, marker='x', color='w') \n",
    "    color_map = plt.imshow(probability, origin='upper')\n",
    "    plt.colorbar(fraction=0.01, pad=0.01)\n",
    "    plt.title('possibility of next symbol')\n",
    "    plt.xlabel('possible next symbol')\n",
    "    plt.ylabel('true next symbol')\n",
    "    plt.xticks(list(range(len(ALPHABET))), as_printable(ALPHABET))\n",
    "    plt.yticks(list(range(rows)), as_printable(y.tobytes()[0:20]))\n",
    "    color_map.set_cmap('jet')\n",
    "\n",
    "\n",
    "# Call your implementation on your trained DummyClassifier here\n",
    "plot_symbol_probs(clf, Xtrn, ytrn, rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVBF0XkOJYe-"
   },
   "source": [
    "**Question.** Complete the following sentence: \"My *DummyClassifier* will correctly predict the 'next symbol' if...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hElSEuOnJYe_"
   },
   "source": [
    "My DummyClassifier will correctly predict the 'next symbol' if it's space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJSj2fnUJYfA"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2c &mdash; Train a DecisionTreeClassifier to predict symbol probabilities [10 marks]*\n",
    "\n",
    "Most scikit-learn estimators do not accept ASCII bytes (*dtype='S1'*) as input features. Instead, they expect *dtype=float64*. So, before training your *DecisionTreeClassifier*, you need a way to transform your ASCII feature matrix $\\mathbf{X}_\\text{trn}$ into some numerical representation compatible with scikit-learn estimators. Standard choices are *OrdinalEncoder* and *OneHotEncoder*.\n",
    "\n",
    "**Train an OrdinalEncoder on your $\\mathbf{X}_\\text{trn}$ array.** Your encoder should be able to accept any extended ASCII symbol (any byte) in any feature column. Your code cell should also print the transformed version of the first 10 rows of $\\mathbf{X}_\\text{trn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-3zlUaqJYfA",
    "outputId": "f2fa2d83-d507-412b-b179-eda545d9d5a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  4.  4.]\n",
      " [ 0.  0.  4.  4.  4.]\n",
      " [ 0.  4.  4.  4. 39.]\n",
      " [ 4.  4.  4. 39. 62.]\n",
      " [ 4.  4. 39. 62. 75.]\n",
      " [ 4. 39. 62. 75. 71.]\n",
      " [39. 62. 75. 71. 62.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "def convert_ascii(X):\n",
    "    oe= sklearn.preprocessing.OrdinalEncoder(dtype= np.float64)\n",
    "    X_= oe.fit(X).transform(X)\n",
    "\n",
    "    return X_\n",
    "\n",
    "print(convert_ascii(Xtrn)[0:9,:])\n",
    "print(convert_ascii(X_train)[0:9,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMKCDeGWJYfB"
   },
   "source": [
    "**Train a *DecisionTreeClassifier*.** Use default hyperparameters (but always set *random_state*). Your code cell should print the training and testing accuracy:\n",
    "```\n",
    "accuracy: trn=0.?????? tst=0.??????\n",
    "nclasses: ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUQV6q5mJYfC",
    "outputId": "bc396fe7-f93e-4d08-de9a-1323a0c9bbda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: trn= 0.877297 tst=0.300050\n",
      "nclasses: 97\n"
     ]
    }
   ],
   "source": [
    "dt = sklearn.tree.DecisionTreeClassifier()\n",
    "dt.fit(convert_ascii(X_train), y_train, sample_weight = w_train) \n",
    "\n",
    "train_accuracy  = sklearn.metrics.accuracy_score(y_train, dt.predict(convert_ascii(X_train)))\n",
    "test_accuracy   = sklearn.metrics.accuracy_score(ytst, dt.predict(convert_ascii(Xtst)))\n",
    "n_classes       = dt.n_classes_\n",
    "\n",
    "\n",
    "print(\"accuracy: trn= %.6f tst=%.6f\" %(train_accuracy, test_accuracy))\n",
    "print(\"nclasses: %d\" %(n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqTYcfVjJYfD"
   },
   "source": [
    "**Plot the predicted symbol probabilities.** Use your *plot_symbol_probs* function from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "9zfZzzcmJYfE",
    "outputId": "01d5789c-92df-4a15-f00c-1175dc8eb061"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call your plotting function here\n",
    "plot_symbol_probs(dt, convert_ascii(Xtrn), ytrn, rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTInZrTYJYfF"
   },
   "source": [
    "The rows should now have different probabilities, and the \"true next symbol\" should be predicted correctly more often!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo0Z9YlBJYfG"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q3 &mdash; Use predictions to compress text [25 marks total]\n",
    "\n",
    "This question asks you to use your *DecisionTreeClassifier* from Question 2 to transform a symbol (e.g., `e` or `+`) into the \"rank of that symbol's predicted probability\" (e.g., 0 or 13). The idea is depicted visually at the top of this assignment.\n",
    "\n",
    "The core part of this question will be to define a scikit-learn style trainable pipeline with two top-level steps:\n",
    "1. Rank-encode the symbols using tools you built in Question 2:\n",
    "   * extract context features (e.g., symbols like `['i', 'm', 'p', 'o', 'r']`)\n",
    "   * convert features to numbers (e.g., ordinal encoding like `[73, 77, 80, 79, 82]`)\n",
    "   * predict probability of each possible \"next symbol\" (e.g., like `'t'`) from the context features\n",
    "2. Huffman-encode the ranks using your class from Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEWsl3EDJYfG"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3a &mdash; Transform symbols into their predicted rank [5 marks]*\n",
    "\n",
    "**Implement *rankencode*.** \n",
    "\n",
    "```python\n",
    ">>> y = np.frombuffer(b'abcbc', 'S1')   # Symbols to encode\n",
    ">>> c = np.frombuffer(b'abc', 'S1')     # Symbol class for each column of p\n",
    ">>> p = np.array([[.5, .2, .3],         # Predicted symbol probabilities\n",
    "...               [.0, .7, .3],\n",
    "...               [.3, .0, .7],\n",
    "...               [.7, .3, .0],\n",
    "...               [.3, .0, .7]])\n",
    ">>> rankencode(y, c, p)                 # Convert each symbol to a rank\n",
    "array([0, 0, 0, 1, 0], dtype=uint8)\n",
    "\n",
    ">>> y = np.frombuffer(b'abcxyz', 'S1')  # Uh-oh, can't encode symbols 'xyz'!\n",
    ">>> rankencode(y, c, p)\n",
    "ValueError: Not all symbols in y were found in the classes c\n",
    ">>> rankencode(y.astype('S4'), c, p)\n",
    "ValueError: Dtypes of y and c must match\n",
    "```\n",
    "Only a few lines of vectorized code are needed. <span style=\"color:#080;font-weight:bold\">Briefly comment each line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EeY4tUWlJYfH"
   },
   "outputs": [],
   "source": [
    "def rankencode(y, c, p):\n",
    "    \"\"\"\n",
    "    Returns a rank-encoded version of array y.\n",
    "\n",
    "    y: length-N array to encode.\n",
    "    c: length-M array of symbols in the alphabet.\n",
    "    p: NxM array of probabilities where probs[i,j] is\n",
    "       the probability that input symbol i is going\n",
    "       to match alphabet element j; this is the same\n",
    "       layout scikit-learn's predict_proba function.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    if c.dtype != y.dtype: # type match\n",
    "        raise ValueError('Dtypes of y and c must match')\n",
    "    rank = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] not in c:\n",
    "            raise ValueError('Not all symbols in y were found in the classes c') # existence match\n",
    "        \n",
    "        row = p[i] #each line of p in each iteration\n",
    "        Dict = dict(zip(c,row)) #{b'a': 0.5, b'c': 0.3, b'b': 0.2} giving sth like this\n",
    "        Dict_sorted = {key: value for key, value in sorted(Dict.items(), key=lambda item: item[1], reverse=1)}\n",
    "        rank.append(list(Dict_sorted.keys()).index(y[i])) # find symbols rank in sorted list of probabilities\n",
    "    return np.array(rank, 'uint8') # return rank as a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QndgxYi5JYfI"
   },
   "source": [
    "**Check your answer** by running the code cell below. It should reproduce the example from the top of this assignment, encoding *[a,b,c,b,c]* as *[0, 0, 0, 1, 0]*, along with some other sample strings that you can use to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzB2gO6cJYfI",
    "outputId": "d92e00a3-c01c-4147-ce26-315c4c609cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcbc -> [0 0 0 1 0]\n",
      "abcabc -> [0 0 0 0 0 0]\n",
      "cbaacba -> [1 1 1 2 1 1 1]\n",
      "aaa -> [0 2 2]\n",
      "bbb -> [2 2 2]\n",
      "ccc -> [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "class ToyGuesser:\n",
    "    \"\"\"Toy \"guesser\" from the top of the assignment as scikit-learn style class.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classes_ = np.frombuffer(b'abc', 'S1')  # Mimick sklearn classes_ attribute\n",
    "        \n",
    "    def predict_proba(self, text: bytes):\n",
    "        p = dict(zip(b'\\0abc', [[.5, .2, .3], [.0, .7, .3], [.3, .0, .7], [.7, .3, .0]]))\n",
    "        return np.array([p[c] for c in (b'\\0' + text[:-1])])  # unvectorized for simplicity\n",
    "\n",
    "toy = ToyGuesser()\n",
    "for text in [b'abcbc', b'abcabc', b'cbaacba', b'aaa', b'bbb', b'ccc']:\n",
    "    print(text.decode('ascii'), '->',\n",
    "          rankencode(np.frombuffer(text, 'S1'), toy.classes_, toy.predict_proba(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEGYoVyVJYfI"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3b &mdash; Measure the entropy of your rank-encoded datasets [2 marks]*\n",
    "\n",
    "\n",
    "**Rank-encode the first 20 rows your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{X}_\\text{trn}$ arrays.** Use your *DummyClassifier* and (separately) your *DecisionTreeClassifier* from Question 2. Your code cell should print something like this, but with the `?` replaced by integers:\n",
    "```\n",
    "train:\n",
    "  dummy: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "  dtree: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "test:\n",
    "  dummy: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "  dtree: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fsm6l0_bJYfJ",
    "outputId": "130a332b-6300-46a2-c4e6-f683dfab1f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  dummy: [26 26 26 76  1  4  6  1 11  3  0 16  8  4  0 60  2 17  3  3]\n",
      "  dtree: [0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 4 0 0 0 0]\n",
      "test:\n",
      "  dummy: [26 26 26  9 46  7 18 22  1  0  4  1 22  4  1  3  3  7  8  6]\n",
      "  dtree: [ 0  0  0  2  6 75 71 74 72  3 84  0 73 85 71 85  0 75 81 81]\n"
     ]
    }
   ],
   "source": [
    "### train ###\n",
    "print('train:')\n",
    "# Dummy Classifier\n",
    "p = clf.predict_proba(Xtrn)[0:20]\n",
    "y = np.frombuffer(ytrn[0:20], dtype='S1')\n",
    "c = np.frombuffer(ALPHABET, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "print('  dummy:', r)\n",
    "# Decision Tree\n",
    "p = dt.predict_proba(convert_ascii(Xtrn))[0:20]\n",
    "y = np.frombuffer(ytrn[0:20], dtype='S1')\n",
    "c = np.frombuffer(ALPHABET, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "print('  dtree:', r)\n",
    "### test ###\n",
    "print('test:')\n",
    "# Dummy Classifier\n",
    "p = clf.predict_proba(Xtst)[0:20]\n",
    "y = np.frombuffer(ytst[0:20], dtype='S1')\n",
    "c = np.frombuffer(ALPHABET, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "print('  dummy:', r)\n",
    "# Decision Tree\n",
    "p = dt.predict_proba(convert_ascii(Xtst))[0:20]\n",
    "y = np.frombuffer(ytst[0:20], dtype='S1')\n",
    "c = np.frombuffer(ALPHABET, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "print('  dtree:', r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjKOKt6xJYfL"
   },
   "source": [
    "**Compare the entropy of different encodings.** Print the entropy (in bits) of your $\\mathbf{y}_\\text{trn}$ and $\\mathbf{y}_\\text{tst}$ arrays using three encodings:\n",
    "1. *ascii:* the raw symbol arrays with no rank encoding applied,\n",
    "2. *dummy:* rank encoding with your *DummyClassifier* from Question 2, and\n",
    "3. *dtree:* rank encoding with your *DecisionTreeClassifier* from Question 2.\n",
    "\n",
    "Your code cell should print output like the following, where 1.0000 would indicate 1 bit of entropy.\n",
    "```\n",
    "ascii: trn=?.???? tst=?.????\n",
    "dummy: trn=?.???? tst=?.????\n",
    "dtree: trn=?.???? tst=?.????\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6qXwOEhJYfN",
    "outputId": "eafc9685-c2ac-41b4-8fbc-d73280ca2add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii: trn=4.5825 tst=4.5912\n",
      "dummy: trn=4.5825 tst=4.5912\n",
      "dtree: trn=0.8408 tst=4.6346\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import collections\n",
    "\n",
    "freq = list(collections.Counter(ytrn).values())\n",
    "e_trn = scipy.stats.entropy(freq, base=2)\n",
    "freq = list(collections.Counter(ytst).values())\n",
    "e_tst = scipy.stats.entropy(freq, base=2)\n",
    "print('ascii: trn={:0.4f} tst={:0.4f}'.format(e_trn, e_tst))\n",
    "p = clf.predict_proba(Xtrn)\n",
    "y = np.frombuffer(ytrn, dtype='S1')\n",
    "c = np.frombuffer(ALPHABET, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "freq = list(collections.Counter(r).values())\n",
    "e_trn = scipy.stats.entropy(freq, base=2)\n",
    "p = clf.predict_proba(Xtst)\n",
    "y = np.frombuffer(ytst, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "freq = list(collections.Counter(r).values())\n",
    "e_tst = scipy.stats.entropy(freq, base=2)\n",
    "print('dummy: trn={:0.4f} tst={:0.4f}'.format(e_trn, e_tst))\n",
    "p = dt.predict_proba(convert_ascii(Xtrn))\n",
    "y = np.frombuffer(ytrn, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "freq = list(collections.Counter(r).values())\n",
    "e_trn = scipy.stats.entropy(freq, base=2)\n",
    "p = dt.predict_proba(convert_ascii(Xtst))\n",
    "y = np.frombuffer(ytst, dtype='S1')\n",
    "r = rankencode(y, c, p)\n",
    "freq = list(collections.Counter(r).values())\n",
    "e_tst = scipy.stats.entropy(freq, base=2)\n",
    "print('dtree: trn={:0.4f} tst={:0.4f}'.format(e_trn, e_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjUEy5xYJYfO"
   },
   "source": [
    "**Question.** Why is the entropy of *DummyClassifier*'s rank encoding no different than the original ASCII encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4vMjcS-JYfO"
   },
   "source": [
    "Because the Dummy Classifier predicts the same result for every row based on the original frequency of the symbols. Hence, the same frequency of symbols will appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_hmji53JYfP"
   },
   "source": [
    "**Question.** Why is the entropy of *DecisionTreeClassifier*'s rank encoding different on the training set than on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6eVoslJJYfP"
   },
   "source": [
    "Using the Decision Tree Classifier, the prediction will differ depending on the input. More precisely, it predicts a better result. Hence, the ranking of the output are closer to 0 which means it is easier to predict. The smaller the ranks, the samller the entrpy of the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xy2qW7rJYfP"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3c &mdash; Define a scikit-learn style feature extractor [6 marks]*\n",
    "\n",
    "This question takes things you already know how to do and asks you to start putting them together in a scikit-learn style class. It is essentially a \"machine learning software engineering\" exercise.\n",
    "\n",
    "\n",
    "**Define an *ExtractContext* transformer class.** This feature-extraction class should do two things:\n",
    "1. wrap your *extract_context* function from *Q2a* in a scikit-learn style transformer; and\n",
    "2. allow the resulting ASCII byte features to be transformed into numbers like you did in *Q2c*\n",
    "\n",
    "Your implementation should behave as depicted below:\n",
    "\n",
    "```python\n",
    ">>> x = [b'ABCD', b'EFG']\n",
    ">>> z = [b'FOO']\n",
    ">>> ctx = ExtractContext(size=3)\n",
    ">>> ctx.fit_transform(x)   # Extracts ASCII features for all text in x\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    ">>> ctx.transform(z)       # All columns can handle any extended ASCII symbol\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'F'],\n",
    "       [b'', b'F', b'O']], dtype='|S1')\n",
    "```\n",
    "And it should support a custom 'encoder' to transform the ASCII symbols into some numeric representation. The encoder shoould be configured to work with any input symbol:\n",
    "```python\n",
    ">>> enc = OrdinalEncoder()\n",
    ">>> ctx = ExtractContext(encoder=enc)\n",
    ">>> ctx.fit_transform(x)     # ASCII symbols now get fed through an encoder\n",
    "array([[ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 32.],\n",
    "       [ 0., 32., 33.],\n",
    "       [32., 33., 34.],\n",
    "       [ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 36.],\n",
    "       [ 0., 36., 37.]])\n",
    ">>> ctx.transform([b'FOO'])  # All columns still handle any symbol\n",
    "array([[ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 37.],\n",
    "       [ 0., 37., 46.]])\n",
    ">>> enc.categories           # The original \"enc\" object is not fitted...\n",
    "'auto'\n",
    ">>> ctx.encoder_.categories  # ...by sklearn convention, a clone is fitted\n",
    "[array([b'', b'\\n', b' ', b'!', ...), ...]\n",
    "       \n",
    "```\n",
    "And of course the usual sanity checking:\n",
    "```python\n",
    ">>> ExtractContext(3)        # By sklearn convention, only keyword args allowed\n",
    "TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ">>> ctx = ExtractContext()\n",
    ">>> ctx.transform(x)\n",
    "NotFittedError: This ExtractContext instance is not fitted yet.\n",
    ">>> ctx.fit(b'ABC')          # Should accept textlist to transform\n",
    "ValueError: Expected list of bytes objects\n",
    ">>> ctx.fit(x, y=[1,2,3])    # Should not accept separate training targets\n",
    "ValueError: Expected None\n",
    "```\n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hqe5G1NcJYfQ"
   },
   "outputs": [],
   "source": [
    "# Your class definition here and anything else supporting it\n",
    "def check_is_none(y):\n",
    "    if y is not None:\n",
    "        raise ValueError(\"Expected None\")\n",
    "\n",
    "def check_is_textlist(x):\n",
    "    if not isinstance(x, list) or \\\n",
    "       not all(isinstance(text, bytes) for text in x):\n",
    "        raise ValueError(\"Expected textlist\")\n",
    "        \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "import huffman\n",
    "import sys\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/soxofaan/dahuffman/' +\n",
    "                           '7bbc964cee6947545ee4dfb4456c96c9be44cebc/dahuffman/' +\n",
    "                           'huffmancodec.py', 'huffman.py')\n",
    "           \n",
    "\n",
    "class ExtractContext(TransformerMixin, BaseEstimator):\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, *, size = 3, encoder = None):\n",
    "        self.size = size\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def check_fitted(self):\n",
    "        sklearn.utils.validation.check_is_fitted(self) #scikit learn conventional style\n",
    "\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        check_is_none(y)\n",
    "        check_is_textlist(x)\n",
    "        \n",
    "        \n",
    "        if self.encoder != None:\n",
    "            a = np.frombuffer(ALPHABET, 'S1') #Here I am using a matrix with alphabet colomns so that we can fit on that and then transfer it on the model\n",
    "            b = np.full((len(a), self.size), dtype=bytes, fill_value=b'')\n",
    "            for i in range(b.shape[1]):\n",
    "                b[: , i] = a\n",
    "\n",
    "            self.encoder_ = sklearn.base.clone(self.encoder).fit(b) #scikit learn conventional style.\n",
    "        \n",
    "        else:\n",
    "            self.encoder_= None \n",
    "            \n",
    "        self.size_ = self.size #satisfying check_fitted. It check every attr_ to be defined in fit.\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        self.check_fitted()\n",
    "        check_is_textlist(x)\n",
    "        transformed_values = []\n",
    "        \n",
    "        try:\n",
    "            transformed_values = extract_context(x, self.size_)\n",
    "        except KeyError as e:\n",
    "            print(\"KeyError:\", e)\n",
    "            \n",
    "        if self.encoder_ != None:\n",
    "            transformed_values = self.encoder_.transform(transformed_values)\n",
    "         \n",
    "        \n",
    "        return transformed_values   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFPMVQonpAwI",
    "outputId": "f7b119cf-d527-4b58-e461-3cf0a74c76f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'' b'' b'']\n",
      " [b'' b'' b'A']\n",
      " [b'' b'A' b'B']\n",
      " [b'A' b'B' b'C']\n",
      " [b'' b'' b'']\n",
      " [b'' b'' b'E']\n",
      " [b'' b'E' b'F']]\n",
      "[[b'' b'' b'']\n",
      " [b'' b'' b'F']\n",
      " [b'' b'F' b'O']]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. 35.]\n",
      " [ 0. 35. 36.]\n",
      " [35. 36. 37.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. 39.]\n",
      " [ 0. 39. 40.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. 40.]\n",
      " [ 0. 40. 49.]]\n",
      "auto\n",
      "[array([b'', b'\\n', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(',\n",
      "       b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3',\n",
      "       b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>',\n",
      "       b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I',\n",
      "       b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T',\n",
      "       b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_',\n",
      "       b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j',\n",
      "       b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u',\n",
      "       b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~'], dtype='|S1'), array([b'', b'\\n', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(',\n",
      "       b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3',\n",
      "       b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>',\n",
      "       b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I',\n",
      "       b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T',\n",
      "       b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_',\n",
      "       b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j',\n",
      "       b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u',\n",
      "       b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~'], dtype='|S1'), array([b'', b'\\n', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(',\n",
      "       b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3',\n",
      "       b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>',\n",
      "       b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I',\n",
      "       b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T',\n",
      "       b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_',\n",
      "       b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j',\n",
      "       b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u',\n",
      "       b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~'], dtype='|S1')]\n"
     ]
    }
   ],
   "source": [
    "### test 1 ###\n",
    "x = [b'ABCD', b'EFG']\n",
    "z = [b'FOO']\n",
    "ctx = ExtractContext(size = 3)\n",
    "print(ctx.fit_transform(x))\n",
    "print(ctx.transform(z))\n",
    "### test 2 ###\n",
    "enc = sklearn.preprocessing.OrdinalEncoder()\n",
    "ctx = ExtractContext(encoder=enc)\n",
    "print(ctx.fit_transform(x))\n",
    "print(ctx.transform([b'FOO']))\n",
    "print(enc.categories)\n",
    "print(ctx.encoder_.categories_)\n",
    "### test 3 ###\n",
    "#xtractContext(3)\n",
    "#tx = ExtractContext()\n",
    "#ctx.transform(x)\n",
    "#ctx.fit('ABC')\n",
    "#ctx.fit(x, y=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cX0SkfOA_wv0",
    "outputId": "129004c9-9f48-4847-97ca-e46ee4ef8e3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4.],\n",
       "       [ 0.,  4.,  4.],\n",
       "       ...,\n",
       "       [65., 69., 81.],\n",
       "       [69., 81., 88.],\n",
       "       [81., 88., 67.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [b'ABCD', b'EFG']\n",
    "z = [b'FOO']\n",
    "enc = sklearn.preprocessing.OrdinalEncoder()\n",
    "ctx = ExtractContext(encoder=enc)\n",
    "ctx.fit_transform(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYocy0iTJYfR"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3c &mdash; Define a scikit-learn style rank encoder [8 marks]*\n",
    "\n",
    "\n",
    "**Define a *RankEncoder* transformer class.** This class should be designed similarly to *HuffmanEncoder* from Question 1. However, *RankEncoder* is only responsible for rank-encoding the text list passed in, not actually compressing them. It should explcitly take two arguments:\n",
    "* *estimator:* an instance of the kind of classifier to use for predicting the next symbol, analogous to how the *base_estimator* parameter of [*BaggingClassifier*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) is used. The default should be a *DummyClassifier*.\n",
    "* *extractor:* a feature extractor to convert a filedict object into featre vectors that *estimator* accepts. For example, if *estimator* is a *DecisionTreeClassifier*, then *extractor* must transform a text list into an array $\\mathbf{X}$ of numbers, not ASCII bytes.\n",
    "\n",
    "For example of expected behaviour:\n",
    "```python\n",
    ">>> x = [b'HELLO', b'THERE']\n",
    ">>> rank = RankEncoder(extractor=ExtractContext(size=3, encoder=OrdinalEncoder()),\n",
    "...                    estimator=DecisionTreeClassifier(random_state=0, max_depth=3))\n",
    ">>> rank.fit_transform(x)              # Fit extractor and estimator to x\n",
    "[b'\\x00\\x00\\x00\\x00\\x00', b'\\x01\\x00\\x01\\x00\\x01']\n",
    ">>> rank.transform([b'FOO'])           # Handle symbol in ALPHABET even if not trained\n",
    "[b'\\x11//']\n",
    ">>> rank.estimator_.classes_\n",
    "array([b'', b'\\x01', b'\\x02', ...])\n",
    ">>> rank.estimator_ is rank.estimator  # By sklearn convention, estimator_ is clone\n",
    "False\n",
    "```\n",
    "If no *extractor* and *estimator* prototypes are specified, defaults should be created:\n",
    "```python\n",
    ">>> rank = RankEncoder()\n",
    ">>> rank.fit_transform(x)              # DummyClassifier encodes E=0, L=1, H=2, etc\n",
    "[b'\\x02\\x00\\x01\\x01\\x03', b'\\x05\\x02\\x00\\x04\\x00']\n",
    ">>> rank.extractor, rank.estimator     # No value was given for these...\n",
    "(None, None)\n",
    ">>> rank.extractor_, rank.estimator_   # ...so defaults get created on fit\n",
    "(ExtractContext(), DummyClassifier(strategy='prior'))\n",
    "```\n",
    "And as usual do sanity checking and try to adhere to sklearn conventions:\n",
    "```python\n",
    ">>> RankEncoder(ExtractContext())      # Require keyword args (sklearn convention)\n",
    "TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ">>> RankEncoder().transform(x)\n",
    "NotFittedError: This RankEncoder instance is not fitted yet.\n",
    "```\n",
    "\n",
    "You do *not* need to implement an *inverse_transform* (rank decode) method, although it is one way to sanity-check your code.\n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "osjrUxacJYfR"
   },
   "outputs": [],
   "source": [
    "# Your class definition here and anything else supporting it\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "import huffman\n",
    "\n",
    "def check_is_textlist(x):\n",
    "    if not isinstance(x, list) or \\\n",
    "       not all(isinstance(text, bytes) for text in x):\n",
    "        raise ValueError(\"Expected textlist\")\n",
    "\n",
    "def check_is_none(y):\n",
    "    if y is not None:\n",
    "        raise ValueError(\"Expected None\")        \n",
    "\n",
    "class RankEncoder(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    \n",
    "    def __init__(self, *, extractor= None, estimator=None):\n",
    "        self.extractor  = extractor\n",
    "        #self.extractor_ = ExtractContext(size=3)\n",
    "        self.estimator  = estimator\n",
    "        #self.estimator_ = sklearn.dummy.DummyClassifier(strategy= 'prior')\n",
    "\n",
    "    def check_fitted(self):\n",
    "        sklearn.utils.validation.check_is_fitted(self)\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        check_is_none(y)\n",
    "        check_is_textlist(x)\n",
    " \n",
    "        \n",
    "        buffer = b'' #concatenating the list elements\n",
    "        for i in x:\n",
    "            buffer = buffer +i\n",
    "            \n",
    "\n",
    "        if self.extractor != None:\n",
    "            extractor = self.extractor #checking if the defualt format of attrinbutes are used or not\n",
    "            #X_ = self.extractor.fit_transform(x) #extracting x so we can use it as features.\n",
    "        else:\n",
    "            extractor = ExtractContext(size=3)\n",
    "            #X_ = self.extractor_.fit_transform(x) #default\n",
    "        \n",
    "        self.extractor_ = sklearn.base.clone(extractor).fit(x)\n",
    "        \n",
    "        X_ = self.extractor_.transform(x)\n",
    "        y_ = np.frombuffer(buffer, dtype='|S1')\n",
    "        X_train, y_train, w_train = add_alphabet(X_, y_, ALPHABET)\n",
    "\n",
    "        if self.estimator != None:\n",
    "            estimator = self.estimator\n",
    "        else:\n",
    "            estimator = sklearn.dummy.DummyClassifier(strategy='prior')\n",
    "        \n",
    "        #fitting models on weighted format of Xtr and ytr\n",
    "        self.estimator_ = sklearn.base.clone(estimator).fit(X_train, y_train, w_train)\n",
    "        \n",
    "              \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        self.check_fitted()\n",
    "        check_is_textlist(x)\n",
    "        transformed_values = []\n",
    "        \n",
    "        for i in x:\n",
    "            \n",
    "\n",
    "            X_ = self.extractor_.fit_transform([i])\n",
    "\n",
    "            p = self.estimator_.predict_proba(X_)\n",
    "\n",
    "            c =  self.estimator_.classes_ \n",
    "            y = np.frombuffer(i, 'S1')\n",
    "            transformed_values.append(rankencode(y, c, p))\n",
    "\n",
    "        chara = ''\n",
    "        transformed_values_chara = []\n",
    "        for i in transformed_values: #Creating character-type of the list.(not the integer format!)\n",
    "            chara = ''\n",
    "            for j in i:\n",
    "                chara = chara + chr(j)\n",
    "            transformed_values_chara.append(bytes(chara, 'utf-8'))\n",
    "        \n",
    "        return transformed_values_chara\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoC6MqajpKHc",
    "outputId": "cd51e296-ee28-484c-f942-e7098e99c5e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\x00\\x00\\x00\\x00\\x01', b'\\x01\\x00\\x00\\x00\\x01']\n",
      "[b'*11']\n",
      "[b'' b'\\n' b' ' b'!' b'\"' b'#' b'$' b'%' b'&' b\"'\" b'(' b')' b'*' b'+'\n",
      " b',' b'-' b'.' b'/' b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9'\n",
      " b':' b';' b'<' b'=' b'>' b'?' b'@' b'A' b'B' b'C' b'D' b'E' b'F' b'G'\n",
      " b'H' b'I' b'J' b'K' b'L' b'M' b'N' b'O' b'P' b'Q' b'R' b'S' b'T' b'U'\n",
      " b'V' b'W' b'X' b'Y' b'Z' b'[' b'\\\\' b']' b'^' b'_' b'`' b'a' b'b' b'c'\n",
      " b'd' b'e' b'f' b'g' b'h' b'i' b'j' b'k' b'l' b'm' b'n' b'o' b'p' b'q'\n",
      " b'r' b's' b't' b'u' b'v' b'w' b'x' b'y' b'z' b'{' b'|' b'}' b'~']\n",
      "False\n",
      "[b'\\x01\\x00\\x02\\x02\\x03', b'\\x05\\x01\\x00\\x04\\x00']\n",
      "None None\n",
      "ExtractContext() DummyClassifier(strategy='prior')\n",
      "[b'-\\x03\\x03']\n"
     ]
    }
   ],
   "source": [
    "### test 1 ###\n",
    "x = [b'HELLO', b'THERE']\n",
    "re = RankEncoder(extractor=ExtractContext(size=3, encoder=sklearn.preprocessing.OrdinalEncoder()),\n",
    "                 estimator=sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth=3))\n",
    "print(re.fit_transform(x))\n",
    "print(re.transform([b'FOO']))\n",
    "print(re.estimator_.classes_)\n",
    "print(re.estimator_ is re.estimator)\n",
    "### test 2 ###\n",
    "x = [b'HELLO', b'THERE']\n",
    "re = RankEncoder()\n",
    "print(re.fit_transform(x))\n",
    "print(re.extractor, re.estimator)\n",
    "print(re.extractor_, re.estimator_)\n",
    "print(re.transform([b'FOO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh8q2dGzJYfS"
   },
   "source": [
    "**Write a few lines of code** to demonstrate to the TA that your *RankEncoder* implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5RNk6QGGJYfT"
   },
   "outputs": [],
   "source": [
    "### Your sanity-checking code here ###\n",
    "# RankEncoder(ExtractContext())\n",
    "# RankEncoder().transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOTxUIyBJYfV"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3d &mdash; Pipeline your RankEncoder and HuffmanEncoder together [4 marks]*\n",
    "\n",
    "**Create a scikit-learn *Pipeline* and train it.** Your [*Pipeline*](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object (a [composite estimator](https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators)) should transform a list of uncompressed bytes objects (texts) into a list of compressed bytes objects (Huffman codes), like this:\n",
    "```python\n",
    ">>> compress = Pipeline([...])\n",
    ">>> compress.fit_transform([b'abcabc', b'abc'])  # Fits and transforms each stage\n",
    "[b'\\xfd', b'\\xe8']\n",
    ">>> compress.transform([b'bca', b'zzz'])         # Handle any symbol in ALPHABET\n",
    "[b' \\xd0', b'\\n\\n\\n']\n",
    "```\n",
    "\n",
    "The rank-encoding step should be configured to extract 3 context symbols, encoded as ordinals, and fed into a *DecisionTreeClassifier* having *random_state=0*. Fit the pipeline to your training set. *Hint:* Think about what your *HuffmanEncoder*'s alphabet should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fsadKT1JYfV",
    "outputId": "0ebc88bf-0cb4-48c9-a0e3-7bd5d7c3146a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\xfd', b'\\xe8']\n",
      "[b'2\\xe8', b'>\\x9fO\\xa8']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "re = RankEncoder(extractor=ExtractContext(size=3, encoder=sklearn.preprocessing.OrdinalEncoder()),\n",
    "                 estimator=sklearn.tree.DecisionTreeClassifier(random_state=0))\n",
    "\n",
    "huff = HuffmanEncoder(alphabet = ALPHABET)\n",
    "\n",
    "compress = sklearn.pipeline.Pipeline([('RankEncoder', re),('HuffmanEncoder', huff)])\n",
    "print(compress.fit_transform([b'abcabc', b'abc']))\n",
    "print(compress.transform([b'bca', b'zzz']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqwN3giSJYfV"
   },
   "source": [
    "**Display your pipeline as a diagram.** Use [*sklearn.set_config*](https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html) to display your pipeline as an interactive diagram, like below.\n",
    "\n",
    "<img src=\"img/pipeline-diagram.png\" width=300px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "LMGl1rxhJYfW",
    "outputId": "efac677c-f0f8-4073-e80f-589b03781302"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f0e1cccd-a403-4d11-91eb-d9087684f5a8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f0e1cccd-a403-4d11-91eb-d9087684f5a8\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('RankEncoder',\n",
       "                 RankEncoder(estimator=DecisionTreeClassifier(random_state=0),\n",
       "                             extractor=ExtractContext(encoder=OrdinalEncoder()))),\n",
       "                ('HuffmanEncoder',\n",
       "                 HuffmanEncoder(alphabet=b'\\x00\\n !\"#$%&\\'()*+,-./0123456789'\n",
       "                                         b':;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXY'\n",
       "                                         b'Z[\\\\]^_`abcdefghijklmnopqrstuvwxy'\n",
       "                                         b'z{|}~'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f0cc9a39-5f2e-42bd-b649-9a43e1aba6ea\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f0cc9a39-5f2e-42bd-b649-9a43e1aba6ea\">RankEncoder: RankEncoder</label><div class=\"sk-toggleable__content\"><pre>RankEncoder(estimator=DecisionTreeClassifier(random_state=0),\n",
       "            extractor=ExtractContext(encoder=OrdinalEncoder()))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"89bcbba0-2a7e-4827-be20-eb4c866d97b0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"89bcbba0-2a7e-4827-be20-eb4c866d97b0\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"38098ea4-e77f-4c01-97b0-216dbc8195d3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"38098ea4-e77f-4c01-97b0-216dbc8195d3\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6ba10410-b94e-404d-b58f-93834cb564ba\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6ba10410-b94e-404d-b58f-93834cb564ba\">HuffmanEncoder</label><div class=\"sk-toggleable__content\"><pre>HuffmanEncoder(alphabet=b'\\x00\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLM'\n",
       "                        b'NOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~')</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('RankEncoder',\n",
       "                 RankEncoder(estimator=DecisionTreeClassifier(random_state=0),\n",
       "                             extractor=ExtractContext(encoder=OrdinalEncoder()))),\n",
       "                ('HuffmanEncoder',\n",
       "                 HuffmanEncoder(alphabet=b'\\x00\\n !\"#$%&\\'()*+,-./0123456789'\n",
       "                                         b':;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXY'\n",
       "                                         b'Z[\\\\]^_`abcdefghijklmnopqrstuvwxy'\n",
       "                                         b'z{|}~'))])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here (couple of lines)\n",
    "sklearn.set_config(display = 'diagram')\n",
    "compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSJ8JlzfJYfW"
   },
   "source": [
    "**Print compression ratios of your pipeline.** Use your *Pipline* object to print the compression ratios of your training and testing texts, much like you did for just the *HuffmanEncoder* in Question 1. (Remember that when you ask a *Pipeline* object to score some input, it will call the *score* method of the last object in the pipeline.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pE53IZhNJYfX",
    "outputId": "7c42a7c3-1d9c-48be-e73c-12a8783e5138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  4.970178926441352\n",
      "Testing score:  2.4110910186859553\n"
     ]
    }
   ],
   "source": [
    "# Print the compression ratios of your training and testing textlists here\n",
    "compress.fit_transform(train)\n",
    "print('Training score: ', compress.score(train))\n",
    "print('Testing score: ', compress.score(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzhsE_5XJYfY"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q4 &mdash; Maximize the compression rate [30 marks total]\n",
    "\n",
    "This question challenges you to maximize the compression on held-out test data. To do so, you'll need to try swapping different scikit-learn estimators into your \"compression pipeline\" and then optimizing their hyperparameters.\n",
    "\n",
    "Before you get started, it's important to inspect the hyperparameters of your basic decision-tree compression pipeline from Question 3. **Edit and run the code cell below** to print the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp81RjNkJYfY",
    "outputId": "9464262f-05b7-4886-b3e9-77637925d08d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "RankEncoder\n",
      "HuffmanEncoder\n",
      "RankEncoder__estimator__ccp_alpha\n",
      "RankEncoder__estimator__class_weight\n",
      "RankEncoder__estimator__criterion\n",
      "RankEncoder__estimator__max_depth\n",
      "RankEncoder__estimator__max_features\n",
      "RankEncoder__estimator__max_leaf_nodes\n",
      "RankEncoder__estimator__min_impurity_decrease\n",
      "RankEncoder__estimator__min_impurity_split\n",
      "RankEncoder__estimator__min_samples_leaf\n",
      "RankEncoder__estimator__min_samples_split\n",
      "RankEncoder__estimator__min_weight_fraction_leaf\n",
      "RankEncoder__estimator__presort\n",
      "RankEncoder__estimator__random_state\n",
      "RankEncoder__estimator__splitter\n",
      "RankEncoder__estimator\n",
      "RankEncoder__extractor__encoder__categories\n",
      "RankEncoder__extractor__encoder__dtype\n",
      "RankEncoder__extractor__encoder\n",
      "RankEncoder__extractor__size\n",
      "RankEncoder__extractor\n",
      "HuffmanEncoder__alphabet\n"
     ]
    }
   ],
   "source": [
    "def print_param_names(estimator):\n",
    "    for name in estimator.get_params():  # get_params() returns a dict, so iterate keys\n",
    "        print(name)\n",
    "    \n",
    "print_param_names(compress)  # Uncomment and edit this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JredxYuwJYfY"
   },
   "source": [
    "Take special note of the kinds of parameters that you might like to \"tune\" to maximize compression:\n",
    "* `...__extractor`, the object wholly responsible for feature extraction;\n",
    "* `...__extractor__size`, an *ExtractContext*-specific hyperparameter dictating the context size;\n",
    "* `...__extractor__encoder`, the object (if any) responsible for transforming ASCII context features into numbers\n",
    "* `...__estimator`, the classifier responsible for predicting \"next-symbol probabilities\" from the features\n",
    "* `...__estimator__max_depth`, a tree-specific hyperparameter that would not exist for other *estimator* types.\n",
    "* and more, depending on which feature extraction pipeline and classifier you use\n",
    "\n",
    "Scikit-learn's *get_params* method is provided by [*BaseEstimator*](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html). It automatically discovers all [nested parameters](https://scikit-learn.org/stable/modules/compose.html#nested-parameters). This makes it possible to override parameters by name during a hyperparameter search, such as [*GridSearchCV*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or [*RandomizedSearchCV*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "In fact you can try replacing the prototype *estimator* attribute (not to be confused with the fitted *estimator_* attribute) with something completely different, like a [*LogisticRegression*](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), and the list of hyperparameters at your disposal will change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ4iI8uhJYfZ"
   },
   "source": [
    "When you are ready, use the code cell below to define any utility functions that simplify your remaining code cells, to make those code cells as concise as possible. Ideas for useful stuff (optional!):\n",
    "* import whatever you need that isn't already imported yet;\n",
    "* function to save/load results that took a long time to compute;\n",
    "* function to make sorting and displaying results as a pandas *DataFrame* convenient;\n",
    "* function to run hyperparameter search with whatever defaults you currently want (*verbose*, *n_jobs*, *refit*, etc.);\n",
    "* function to strip down the items of textlist, to make a \"mini\" training set for faster experimentation on initial hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-7u8mjZwJYfa"
   },
   "outputs": [],
   "source": [
    "# Your utility functions here\n",
    "from joblib import dump, load\n",
    "import pandas as pd   \n",
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdgzJRCGJYfa"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4a &mdash; Maximize compression with a DecisionTreeClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *DecisionTreeClassifier* estimator.** There are two requirements:\n",
    "1. Once the search is complete, you must save the search object, e.g., `a1q4-dtree.joblib`; see the scikit-learn documentation on [how to save objects](https://scikit-learn.org/stable/modules/model_persistence.html) to pickle files efficiently using *joblib*. <span style=\"color:red\">The pickle file should be submitted as part of your assignment, as a pre-trained model.</span>\n",
    "2. Running your code cell must also result in the results of the hyperparameter search being displayed as a *pandas* *DataFrame* object, sorted to show the best cross-validation scores first (the *mean_test_score* column). For example, if the TA scrolls through the columns they should see most of the hyperparameter settings for each trial and the *test_score* columns should look something like this:\n",
    "\n",
    "<img src=\"img/search-dataframe-example.png\" width=280/>\n",
    "\n",
    "Some tips:\n",
    "* Since your training set is a list of 3 files, use 3-fold cross validation so that each file gets a turn being \"held out\".\n",
    "* *RandomizedSearchCV* gives easier control over total training time (number of samples) than *GridSearchCV* does. (If you use the faster \"*Halving*\" CV types to explore settings, do not submit your assignment with them: they are new and not yet available in the version of sklearn used in this course.)\n",
    "* The CV search's *n_jobs* parameter is a powerful way to speed things up, using all your CPU cores.\n",
    "* Keep a variable that remembers the search object, or save it to disk, since you'll need it for a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txqwRyBoJYfa",
    "outputId": "99ae6565-d962-4c11-c277-6ec3408fbede",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator__max_depth': 8, 'RankEncoder__extractor__encoder': OrdinalEncoder(), 'RankEncoder__extractor__size': 1}\n",
      "best validation score is:  1.9708748318485754\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "param_grid = {'RankEncoder__estimator__max_depth' : randint(1, 10),\n",
    "              'RankEncoder__extractor__size' : randint(1, 9),\n",
    "              'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid, \n",
    "                                                 verbose= 1, cv=3, random_state= 0, n_iter=50, n_jobs=-1)\n",
    "RSC.fit(train)\n",
    "print('best parameter combination is: ', RSC.best_params_)\n",
    "print('best validation score is: ', RSC.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocV9_PXvuW9m",
    "outputId": "596314d1-02a0-4e6e-890e-f26ca38cf014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-dtree.joblib']"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC, \"a1q4-dtree.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_m10qTFZu5jH",
    "outputId": "052a6aa3-9ccc-4b25-9d8f-6dc98de5aa4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator__max_depth</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.296273</td>\n",
       "      <td>0.039207</td>\n",
       "      <td>1.106948</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>8</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 8, 'Rank...</td>\n",
       "      <td>1.924187</td>\n",
       "      <td>1.931248</td>\n",
       "      <td>2.057190</td>\n",
       "      <td>1.970875</td>\n",
       "      <td>0.061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.454174</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>1.139460</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>8</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 8, 'Rank...</td>\n",
       "      <td>1.879699</td>\n",
       "      <td>1.968504</td>\n",
       "      <td>2.049600</td>\n",
       "      <td>1.965935</td>\n",
       "      <td>0.069386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.995291</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>1.270356</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>9</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 9, 'Rank...</td>\n",
       "      <td>1.830831</td>\n",
       "      <td>1.959248</td>\n",
       "      <td>2.008032</td>\n",
       "      <td>1.932704</td>\n",
       "      <td>0.074737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.355255</td>\n",
       "      <td>0.121540</td>\n",
       "      <td>1.100324</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>6</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 6, 'Rank...</td>\n",
       "      <td>1.919017</td>\n",
       "      <td>1.864976</td>\n",
       "      <td>1.992826</td>\n",
       "      <td>1.925606</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.987152</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>1.281191</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>7</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 7, 'Rank...</td>\n",
       "      <td>1.859773</td>\n",
       "      <td>1.917546</td>\n",
       "      <td>1.994018</td>\n",
       "      <td>1.923779</td>\n",
       "      <td>0.054982</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.850993</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>1.218456</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>6</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 6, 'Rank...</td>\n",
       "      <td>1.882885</td>\n",
       "      <td>1.895375</td>\n",
       "      <td>1.964251</td>\n",
       "      <td>1.914170</td>\n",
       "      <td>0.035778</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.486661</td>\n",
       "      <td>0.068297</td>\n",
       "      <td>1.410454</td>\n",
       "      <td>0.013039</td>\n",
       "      <td>7</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>8</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 7, 'Rank...</td>\n",
       "      <td>1.856321</td>\n",
       "      <td>1.916076</td>\n",
       "      <td>1.969279</td>\n",
       "      <td>1.913892</td>\n",
       "      <td>0.046141</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.586916</td>\n",
       "      <td>0.033160</td>\n",
       "      <td>1.442045</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>6</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>8</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 6, 'Rank...</td>\n",
       "      <td>1.880760</td>\n",
       "      <td>1.887861</td>\n",
       "      <td>1.931994</td>\n",
       "      <td>1.900205</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.469444</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>1.149765</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>9</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 9, 'Rank...</td>\n",
       "      <td>1.877582</td>\n",
       "      <td>1.838235</td>\n",
       "      <td>1.943635</td>\n",
       "      <td>1.886484</td>\n",
       "      <td>0.043487</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.271445</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>1.116683</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>5</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.909490</td>\n",
       "      <td>1.820499</td>\n",
       "      <td>1.897893</td>\n",
       "      <td>1.875961</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.897007</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>1.252598</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>9</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 9, 'Rank...</td>\n",
       "      <td>1.876877</td>\n",
       "      <td>1.819174</td>\n",
       "      <td>1.914608</td>\n",
       "      <td>1.870220</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.447763</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>1.135708</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>8</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 8, 'Rank...</td>\n",
       "      <td>1.871257</td>\n",
       "      <td>1.820167</td>\n",
       "      <td>1.912412</td>\n",
       "      <td>1.867945</td>\n",
       "      <td>0.037731</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.047005</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>1.311976</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>9</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 9, 'Rank...</td>\n",
       "      <td>1.863933</td>\n",
       "      <td>1.815871</td>\n",
       "      <td>1.906578</td>\n",
       "      <td>1.862127</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.668210</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>1.196091</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>8</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 8, 'Rank...</td>\n",
       "      <td>1.868810</td>\n",
       "      <td>1.807991</td>\n",
       "      <td>1.902950</td>\n",
       "      <td>1.859917</td>\n",
       "      <td>0.039273</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.515211</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>1.152148</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.883594</td>\n",
       "      <td>1.827485</td>\n",
       "      <td>1.855976</td>\n",
       "      <td>1.855685</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.240933</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>1.418213</td>\n",
       "      <td>0.061852</td>\n",
       "      <td>8</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 8, 'Rank...</td>\n",
       "      <td>1.864280</td>\n",
       "      <td>1.799208</td>\n",
       "      <td>1.900057</td>\n",
       "      <td>1.854515</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.874068</td>\n",
       "      <td>0.049725</td>\n",
       "      <td>1.248975</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.864280</td>\n",
       "      <td>1.825151</td>\n",
       "      <td>1.856321</td>\n",
       "      <td>1.848584</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.647395</td>\n",
       "      <td>0.046608</td>\n",
       "      <td>1.179081</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.862891</td>\n",
       "      <td>1.825484</td>\n",
       "      <td>1.852195</td>\n",
       "      <td>1.846857</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.494706</td>\n",
       "      <td>0.059131</td>\n",
       "      <td>1.421030</td>\n",
       "      <td>0.053118</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.861158</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.858736</td>\n",
       "      <td>1.846466</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.772539</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>1.474421</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>8</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.861158</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.858736</td>\n",
       "      <td>1.846466</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.705850</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>1.486566</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>4</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>8</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.861158</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.858736</td>\n",
       "      <td>1.846466</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.319547</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>1.102413</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>7</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 7, 'Rank...</td>\n",
       "      <td>1.861851</td>\n",
       "      <td>1.778410</td>\n",
       "      <td>1.845700</td>\n",
       "      <td>1.828653</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.283527</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>1.100819</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>3</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.871958</td>\n",
       "      <td>1.781896</td>\n",
       "      <td>1.814553</td>\n",
       "      <td>1.822802</td>\n",
       "      <td>0.037228</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.399630</td>\n",
       "      <td>0.136249</td>\n",
       "      <td>1.356481</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>3</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.861504</td>\n",
       "      <td>1.797914</td>\n",
       "      <td>1.806685</td>\n",
       "      <td>1.822034</td>\n",
       "      <td>0.028138</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.845943</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>1.241686</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>3</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.861504</td>\n",
       "      <td>1.797591</td>\n",
       "      <td>1.806685</td>\n",
       "      <td>1.821927</td>\n",
       "      <td>0.028231</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.354291</td>\n",
       "      <td>0.106679</td>\n",
       "      <td>1.162810</td>\n",
       "      <td>0.045375</td>\n",
       "      <td>6</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 6, 'Rank...</td>\n",
       "      <td>1.850824</td>\n",
       "      <td>1.760253</td>\n",
       "      <td>1.832173</td>\n",
       "      <td>1.814417</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.653595</td>\n",
       "      <td>0.020855</td>\n",
       "      <td>1.183628</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.834189</td>\n",
       "      <td>1.758706</td>\n",
       "      <td>1.828822</td>\n",
       "      <td>1.807239</td>\n",
       "      <td>0.034388</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.891842</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>1.279520</td>\n",
       "      <td>0.043252</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.834189</td>\n",
       "      <td>1.758706</td>\n",
       "      <td>1.824818</td>\n",
       "      <td>1.805904</td>\n",
       "      <td>0.033593</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.023461</td>\n",
       "      <td>0.058879</td>\n",
       "      <td>1.296684</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.830831</td>\n",
       "      <td>1.756852</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.802396</td>\n",
       "      <td>0.032535</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.034378</td>\n",
       "      <td>0.052199</td>\n",
       "      <td>1.300428</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.830831</td>\n",
       "      <td>1.756852</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.802396</td>\n",
       "      <td>0.032535</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.192745</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>1.361051</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.830496</td>\n",
       "      <td>1.751927</td>\n",
       "      <td>1.820499</td>\n",
       "      <td>1.800974</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.413230</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>1.403171</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 5, 'Rank...</td>\n",
       "      <td>1.830496</td>\n",
       "      <td>1.752848</td>\n",
       "      <td>1.818843</td>\n",
       "      <td>1.800729</td>\n",
       "      <td>0.034189</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.074680</td>\n",
       "      <td>0.144965</td>\n",
       "      <td>1.300579</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>2</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.848087</td>\n",
       "      <td>1.761184</td>\n",
       "      <td>1.790831</td>\n",
       "      <td>1.800034</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.580814</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>1.455769</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>2</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>8</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.848087</td>\n",
       "      <td>1.761184</td>\n",
       "      <td>1.790831</td>\n",
       "      <td>1.800034</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.640952</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>1.196738</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>2</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.848087</td>\n",
       "      <td>1.761184</td>\n",
       "      <td>1.790831</td>\n",
       "      <td>1.800034</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.663074</td>\n",
       "      <td>0.076551</td>\n",
       "      <td>1.231025</td>\n",
       "      <td>0.053104</td>\n",
       "      <td>4</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.749475</td>\n",
       "      <td>1.792436</td>\n",
       "      <td>1.792146</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.040149</td>\n",
       "      <td>0.087809</td>\n",
       "      <td>1.305113</td>\n",
       "      <td>0.029589</td>\n",
       "      <td>4</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.832509</td>\n",
       "      <td>1.748557</td>\n",
       "      <td>1.793400</td>\n",
       "      <td>1.791489</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.481281</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>1.156863</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>4</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.831166</td>\n",
       "      <td>1.748863</td>\n",
       "      <td>1.791794</td>\n",
       "      <td>1.790608</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.397980</td>\n",
       "      <td>0.067269</td>\n",
       "      <td>1.393802</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>4</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 4, 'Rank...</td>\n",
       "      <td>1.831502</td>\n",
       "      <td>1.743679</td>\n",
       "      <td>1.792757</td>\n",
       "      <td>1.789313</td>\n",
       "      <td>0.035936</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3.398453</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>1.459577</td>\n",
       "      <td>0.062546</td>\n",
       "      <td>3</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.828154</td>\n",
       "      <td>1.744896</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.786255</td>\n",
       "      <td>0.033992</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.042476</td>\n",
       "      <td>0.024032</td>\n",
       "      <td>1.322497</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>3</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.828154</td>\n",
       "      <td>1.744896</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.786255</td>\n",
       "      <td>0.033992</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.345736</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>1.092740</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>3</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.820499</td>\n",
       "      <td>1.732502</td>\n",
       "      <td>1.766784</td>\n",
       "      <td>1.773262</td>\n",
       "      <td>0.036215</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.321570</td>\n",
       "      <td>0.011513</td>\n",
       "      <td>1.048277</td>\n",
       "      <td>0.068235</td>\n",
       "      <td>3</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 3, 'Rank...</td>\n",
       "      <td>1.820499</td>\n",
       "      <td>1.732502</td>\n",
       "      <td>1.766784</td>\n",
       "      <td>1.773262</td>\n",
       "      <td>0.036215</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.846512</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>1.260587</td>\n",
       "      <td>0.009068</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 1, 'Rank...</td>\n",
       "      <td>1.840265</td>\n",
       "      <td>1.716738</td>\n",
       "      <td>1.759015</td>\n",
       "      <td>1.772006</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.649156</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>1.182112</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 1, 'Rank...</td>\n",
       "      <td>1.840265</td>\n",
       "      <td>1.716738</td>\n",
       "      <td>1.759015</td>\n",
       "      <td>1.772006</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.474897</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>1.151109</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>2</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.815871</td>\n",
       "      <td>1.737016</td>\n",
       "      <td>1.753771</td>\n",
       "      <td>1.768886</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.523986</td>\n",
       "      <td>0.128375</td>\n",
       "      <td>1.183180</td>\n",
       "      <td>0.073473</td>\n",
       "      <td>2</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.815871</td>\n",
       "      <td>1.737016</td>\n",
       "      <td>1.753771</td>\n",
       "      <td>1.768886</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.991816</td>\n",
       "      <td>0.057822</td>\n",
       "      <td>1.292775</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>2</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 2, 'Rank...</td>\n",
       "      <td>1.815871</td>\n",
       "      <td>1.737016</td>\n",
       "      <td>1.753771</td>\n",
       "      <td>1.768886</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.237219</td>\n",
       "      <td>0.059374</td>\n",
       "      <td>1.367190</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 1, 'Rank...</td>\n",
       "      <td>1.812251</td>\n",
       "      <td>1.719986</td>\n",
       "      <td>1.738828</td>\n",
       "      <td>1.757022</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.692459</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>1.194977</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator__max_depth': 1, 'Rank...</td>\n",
       "      <td>1.812251</td>\n",
       "      <td>1.719986</td>\n",
       "      <td>1.738828</td>\n",
       "      <td>1.757022</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "6        2.296273      0.039207  ...        0.061102                1\n",
       "14       2.454174      0.034859  ...        0.069386                2\n",
       "4        2.995291      0.010682  ...        0.074737                3\n",
       "36       2.355255      0.121540  ...        0.052402                4\n",
       "20       2.987152      0.073252  ...        0.054982                5\n",
       "0        2.850993      0.012107  ...        0.035778                6\n",
       "28       3.486661      0.068297  ...        0.046141                7\n",
       "10       3.586916      0.033160  ...        0.022664                8\n",
       "22       2.469444      0.052211  ...        0.043487                9\n",
       "30       2.271445      0.036032  ...        0.039502               10\n",
       "12       2.897007      0.040335  ...        0.039244               11\n",
       "23       2.447763      0.021837  ...        0.037731               12\n",
       "8        3.047005      0.046588  ...        0.037053               13\n",
       "42       2.668210      0.015519  ...        0.039273               14\n",
       "45       2.515211      0.016808  ...        0.022907               15\n",
       "32       3.240933      0.021251  ...        0.041746               16\n",
       "9        2.874068      0.049725  ...        0.016885               17\n",
       "39       2.647395      0.046608  ...        0.015731               18\n",
       "44       3.494706      0.059131  ...        0.019090               19\n",
       "35       3.772539      0.181842  ...        0.019090               19\n",
       "24       3.705850      0.039956  ...        0.019090               19\n",
       "48       2.319547      0.029616  ...        0.036134               22\n",
       "18       2.283527      0.002621  ...        0.037228               23\n",
       "38       3.399630      0.136249  ...        0.028138               24\n",
       "43       2.845943      0.019706  ...        0.028231               25\n",
       "33       2.354291      0.106679  ...        0.039049               26\n",
       "31       2.653595      0.020855  ...        0.034388               27\n",
       "16       2.891842      0.013203  ...        0.033593               28\n",
       "27       3.023461      0.058879  ...        0.032535               29\n",
       "29       3.034378      0.052199  ...        0.032535               29\n",
       "19       3.192745      0.038235  ...        0.034921               31\n",
       "3        3.413230      0.031819  ...        0.034189               32\n",
       "37       3.074680      0.144965  ...        0.036070               33\n",
       "5        3.580814      0.005819  ...        0.036070               33\n",
       "47       2.640952      0.024260  ...        0.036070               33\n",
       "2        2.663074      0.076551  ...        0.034722               36\n",
       "26       3.040149      0.087809  ...        0.034300               37\n",
       "1        2.481281      0.014516  ...        0.033611               38\n",
       "13       3.397980      0.067269  ...        0.035936               39\n",
       "46       3.398453      0.043347  ...        0.033992               40\n",
       "17       3.042476      0.024032  ...        0.033992               40\n",
       "25       2.345736      0.031966  ...        0.036215               42\n",
       "49       2.321570      0.011513  ...        0.036215               42\n",
       "11       2.846512      0.028866  ...        0.051259               44\n",
       "41       2.649156      0.014650  ...        0.051259               44\n",
       "7        2.474897      0.033822  ...        0.033920               46\n",
       "34       2.523986      0.128375  ...        0.033920               46\n",
       "21       2.991816      0.057822  ...        0.033920               46\n",
       "40       3.237219      0.059374  ...        0.039803               49\n",
       "15       2.692459      0.019618  ...        0.039803               49\n",
       "\n",
       "[50 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(RSC.cv_results_)\n",
    "df = df.sort_values(by ='rank_test_score')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXGk854EJYfb"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4b &mdash; Maximize compression with a RandomForestClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *RandomForestClassifier* estimator.** Again, your code cell should save the search object and also display a *DataFrame* of results like for *Q4a*.\n",
    "\n",
    "Some new tips:\n",
    "* If you want the hyperparameter search to replace your default estimator (*DecisionTreeClassifier*) with a different type, you can add an entry like this in your hyperparameter search space:\n",
    "\n",
    "```python\n",
    "    '...__estimator': [RandomForestClassifier(random_state=0)],\n",
    "```\n",
    "\n",
    "* *RandomForestClassifier* takes a lot longer to train than *DecisionTreeClassifier*, so you will not be able to try as many hyperparameter settings in a reasonable time. That is OK, it can still perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efHdlJEbJYfc",
    "outputId": "25ca32ed-6e89-416d-e16a-8cb6822a79d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator': RandomForestClassifier(max_depth=10, n_estimators=90, random_state=0), 'RankEncoder__estimator__max_depth': 10, 'RankEncoder__estimator__n_estimators': 90, 'RankEncoder__extractor__encoder': OrdinalEncoder(), 'RankEncoder__extractor__size': 4}\n",
      "best validation score is:  2.2782844697593734\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "param_grid1 = {'RankEncoder__estimator':[sklearn.ensemble.RandomForestClassifier(random_state=0)],\n",
    "               'RankEncoder__estimator__n_estimators':[60,70,80,90,100],\n",
    "               'RankEncoder__estimator__max_depth' : randint(1, 11),\n",
    "               'RankEncoder__extractor__size' : randint(1, 8),\n",
    "               'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC1 = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid1, \n",
    "                                                 verbose= 1, cv=3, random_state= 0, n_iter=40, n_jobs=-1)\n",
    "RSC1.fit(train)\n",
    "print('best parameter combination is: ', RSC1.best_params_)\n",
    "print('best validation score is: ', RSC1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hUQpMbyxQtQ",
    "outputId": "ba1a86cb-e536-47f5-b1b0-6518b1565525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-RandomForest.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC1, \"a1q4-RandomForest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iIiNkvvdxgEh",
    "outputId": "caf951e1-b6ca-4ee1-c671-16054d8cd472"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator</th>\n",
       "      <th>param_RankEncoder__estimator__max_depth</th>\n",
       "      <th>param_RankEncoder__estimator__n_estimators</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.491546</td>\n",
       "      <td>0.079875</td>\n",
       "      <td>1.702994</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>2.166847</td>\n",
       "      <td>2.308403</td>\n",
       "      <td>2.359604</td>\n",
       "      <td>2.278284</td>\n",
       "      <td>0.081523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.893778</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>1.783222</td>\n",
       "      <td>0.020056</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>2.111486</td>\n",
       "      <td>2.223210</td>\n",
       "      <td>2.281022</td>\n",
       "      <td>2.205240</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.033401</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>1.499564</td>\n",
       "      <td>0.040836</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>2.071680</td>\n",
       "      <td>2.138580</td>\n",
       "      <td>2.209456</td>\n",
       "      <td>2.139906</td>\n",
       "      <td>0.056255</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.186403</td>\n",
       "      <td>0.043475</td>\n",
       "      <td>1.725797</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>2.002804</td>\n",
       "      <td>2.032520</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>2.043188</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.325040</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>1.545377</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>2.009646</td>\n",
       "      <td>2.032107</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>2.041696</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.712382</td>\n",
       "      <td>0.029579</td>\n",
       "      <td>1.455430</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.007226</td>\n",
       "      <td>2.081165</td>\n",
       "      <td>2.026676</td>\n",
       "      <td>0.039052</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.342252</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>1.509118</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.997603</td>\n",
       "      <td>2.009646</td>\n",
       "      <td>2.064410</td>\n",
       "      <td>2.023886</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.549224</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>1.708735</td>\n",
       "      <td>0.031839</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.979806</td>\n",
       "      <td>1.990842</td>\n",
       "      <td>2.048341</td>\n",
       "      <td>2.006330</td>\n",
       "      <td>0.030046</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.999582</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>1.607092</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.976675</td>\n",
       "      <td>1.986492</td>\n",
       "      <td>2.042067</td>\n",
       "      <td>2.001745</td>\n",
       "      <td>0.028792</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.107613</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>1.485452</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.960016</td>\n",
       "      <td>1.935359</td>\n",
       "      <td>2.010050</td>\n",
       "      <td>1.968475</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.103709</td>\n",
       "      <td>0.893820</td>\n",
       "      <td>1.512258</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>1.939864</td>\n",
       "      <td>1.996008</td>\n",
       "      <td>1.962364</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.869731</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>1.731080</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.947040</td>\n",
       "      <td>1.910585</td>\n",
       "      <td>1.934985</td>\n",
       "      <td>1.930870</td>\n",
       "      <td>0.015165</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.275611</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>1.834327</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.929757</td>\n",
       "      <td>1.872309</td>\n",
       "      <td>1.911680</td>\n",
       "      <td>1.904582</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.995958</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>1.537123</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.920492</td>\n",
       "      <td>1.869508</td>\n",
       "      <td>1.910950</td>\n",
       "      <td>1.900317</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.137856</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>1.590446</td>\n",
       "      <td>0.051872</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.905851</td>\n",
       "      <td>1.862544</td>\n",
       "      <td>1.921968</td>\n",
       "      <td>1.896788</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.605225</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>1.884302</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.916076</td>\n",
       "      <td>1.871608</td>\n",
       "      <td>1.887149</td>\n",
       "      <td>1.891611</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.287035</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>1.826053</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.915709</td>\n",
       "      <td>1.870907</td>\n",
       "      <td>1.883594</td>\n",
       "      <td>1.890070</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.606790</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>1.658682</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.883594</td>\n",
       "      <td>1.858045</td>\n",
       "      <td>1.902226</td>\n",
       "      <td>1.881288</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.674518</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>1.416562</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.897173</td>\n",
       "      <td>1.829826</td>\n",
       "      <td>1.888931</td>\n",
       "      <td>1.871977</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.115341</td>\n",
       "      <td>0.059440</td>\n",
       "      <td>1.773673</td>\n",
       "      <td>0.034691</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.877934</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.896094</td>\n",
       "      <td>1.864511</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.416499</td>\n",
       "      <td>0.052594</td>\n",
       "      <td>1.353070</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.914608</td>\n",
       "      <td>1.821162</td>\n",
       "      <td>1.856665</td>\n",
       "      <td>1.864145</td>\n",
       "      <td>0.038514</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.459850</td>\n",
       "      <td>0.077494</td>\n",
       "      <td>1.631540</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.867762</td>\n",
       "      <td>1.818843</td>\n",
       "      <td>1.855632</td>\n",
       "      <td>1.847412</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.506469</td>\n",
       "      <td>0.043365</td>\n",
       "      <td>1.645086</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.867762</td>\n",
       "      <td>1.818843</td>\n",
       "      <td>1.855632</td>\n",
       "      <td>1.847412</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.347605</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>1.578494</td>\n",
       "      <td>0.017996</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.866368</td>\n",
       "      <td>1.812908</td>\n",
       "      <td>1.852881</td>\n",
       "      <td>1.844052</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.542997</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>1.395152</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.871608</td>\n",
       "      <td>1.797591</td>\n",
       "      <td>1.861851</td>\n",
       "      <td>1.843683</td>\n",
       "      <td>0.032834</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.544341</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>1.664771</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.887505</td>\n",
       "      <td>1.803752</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.841927</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.463176</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>1.671375</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.856321</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>1.846381</td>\n",
       "      <td>1.835159</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.510488</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>1.652675</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.856665</td>\n",
       "      <td>1.801153</td>\n",
       "      <td>1.839926</td>\n",
       "      <td>1.832582</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.045708</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>1.540251</td>\n",
       "      <td>0.019446</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.882530</td>\n",
       "      <td>1.787949</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.829554</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.923963</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>1.473414</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.882885</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.815871</td>\n",
       "      <td>1.828157</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.200701</td>\n",
       "      <td>0.034476</td>\n",
       "      <td>1.853379</td>\n",
       "      <td>0.073651</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.859773</td>\n",
       "      <td>1.789229</td>\n",
       "      <td>1.813894</td>\n",
       "      <td>1.820965</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.767243</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>1.753550</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.863933</td>\n",
       "      <td>1.784758</td>\n",
       "      <td>1.812579</td>\n",
       "      <td>1.820423</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.602961</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>1.458927</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.849112</td>\n",
       "      <td>1.782214</td>\n",
       "      <td>1.813894</td>\n",
       "      <td>1.815073</td>\n",
       "      <td>0.027324</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.896511</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>1.536504</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.842639</td>\n",
       "      <td>1.773050</td>\n",
       "      <td>1.815541</td>\n",
       "      <td>1.810410</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.180032</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>1.838248</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.844678</td>\n",
       "      <td>1.759634</td>\n",
       "      <td>1.820499</td>\n",
       "      <td>1.808270</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.417059</td>\n",
       "      <td>0.050997</td>\n",
       "      <td>1.698550</td>\n",
       "      <td>0.051708</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.837560</td>\n",
       "      <td>1.755002</td>\n",
       "      <td>1.793400</td>\n",
       "      <td>1.795321</td>\n",
       "      <td>0.033731</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.182359</td>\n",
       "      <td>0.036222</td>\n",
       "      <td>1.646646</td>\n",
       "      <td>0.050617</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.825151</td>\n",
       "      <td>1.749169</td>\n",
       "      <td>1.792115</td>\n",
       "      <td>1.788811</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.468883</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>1.480378</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.825151</td>\n",
       "      <td>1.737921</td>\n",
       "      <td>1.775253</td>\n",
       "      <td>1.779442</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.716258</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>1.795986</td>\n",
       "      <td>0.033364</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.820167</td>\n",
       "      <td>1.724138</td>\n",
       "      <td>1.757778</td>\n",
       "      <td>1.767361</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.074612</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>1.618128</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>RandomForestClassifier(max_depth=10, n_estimat...</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': RandomForestClassif...</td>\n",
       "      <td>1.824152</td>\n",
       "      <td>1.717328</td>\n",
       "      <td>1.747335</td>\n",
       "      <td>1.762938</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "17       5.491546      0.079875  ...        0.081523                1\n",
       "25       5.893778      0.017070  ...        0.070369                2\n",
       "3        4.033401      0.018878  ...        0.056255                3\n",
       "35       5.186403      0.043475  ...        0.038084                4\n",
       "37       4.325040      0.035852  ...        0.030837                5\n",
       "14       3.712382      0.029579  ...        0.039052                6\n",
       "10       4.342252      0.033404  ...        0.029073                7\n",
       "34       5.549224      0.011739  ...        0.030046                8\n",
       "5        4.999582      0.014383  ...        0.028792                9\n",
       "16       4.107613      0.024710  ...        0.031074               10\n",
       "39       5.103709      0.893820  ...        0.024237               11\n",
       "11       4.869731      0.020996  ...        0.015165               12\n",
       "23       5.275611      0.008845  ...        0.023984               13\n",
       "15       3.995958      0.030728  ...        0.022130               14\n",
       "0        4.137856      0.039158  ...        0.025092               15\n",
       "22       5.605225      0.032399  ...        0.018426               16\n",
       "20       5.287035      0.010372  ...        0.018855               17\n",
       "24       4.606790      0.016988  ...        0.018110               18\n",
       "29       3.674518      0.026533  ...        0.029994               19\n",
       "21       5.115341      0.059440  ...        0.032676               20\n",
       "38       3.416499      0.052594  ...        0.038514               21\n",
       "19       4.459850      0.077494  ...        0.020800               22\n",
       "33       4.506469      0.043365  ...        0.020800               22\n",
       "32       4.347605      0.049731  ...        0.022700               24\n",
       "9        3.542997      0.040317  ...        0.032834               25\n",
       "30       4.544341      0.034924  ...        0.034590               26\n",
       "6        4.463176      0.011354  ...        0.023255               27\n",
       "1        4.510488      0.022654  ...        0.023250               28\n",
       "12       4.045708      0.064478  ...        0.039441               29\n",
       "36       3.923963      0.038244  ...        0.040610               30\n",
       "18       5.200701      0.034476  ...        0.029230               31\n",
       "31       4.767243      0.014128  ...        0.032795               32\n",
       "28       3.602961      0.016065  ...        0.027324               33\n",
       "27       3.896511      0.025080  ...        0.028640               34\n",
       "2        5.180032      0.022381  ...        0.035780               35\n",
       "8        4.417059      0.050997  ...        0.033731               36\n",
       "4        4.182359      0.036222  ...        0.031107               37\n",
       "7        3.468883      0.043672  ...        0.035734               38\n",
       "13       4.716258      0.029976  ...        0.039785               39\n",
       "26       4.074612      0.012470  ...        0.044985               40\n",
       "\n",
       "[40 rows x 16 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(RSC1.cv_results_)\n",
    "df1 = df1.sort_values(by ='rank_test_score')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMHa8MMwJYff"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4c &mdash; Maximize compression with a LogisticRegression [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *LogisticRegression* estimator.** Again, your code cell should display a *DataFrame* of your search results like for *Q4a*. Some tips:\n",
    "\n",
    "* Since *LogisticRegression* supports sparse feature matrices, your search should include both *OrdinalEncoder* and *OneHotEncoder* as choices for the context features. Check the results to see which representation works best.\n",
    "* *LogisticRegression* can still take a very long time to train. The `sag` solver tends to scale a bit better. You can choose to limit the number of training steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2R4v71GJYfh",
    "outputId": "729118cd-a685-4963-b048-d72884112901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 21.1min finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator': LogisticRegression(random_state=0, solver='sag'), 'RankEncoder__extractor__encoder': OneHotEncoder(), 'RankEncoder__extractor__size': 6}\n",
      "best validation score is:  2.177312924888644\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "param_grid2 = {'RankEncoder__estimator':[sklearn.linear_model.LogisticRegression(random_state=0, solver='sag')],\n",
    "               'RankEncoder__extractor__size' : randint(1, 8),\n",
    "               'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC2 = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid2, \n",
    "                                                 verbose= 1, cv=3, random_state= 0, n_iter=40, n_jobs=-1)\n",
    "RSC2.fit(train)\n",
    "print('best parameter combination is: ', RSC2.best_params_)\n",
    "print('best validation score is: ', RSC2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCjeZN1r3A42",
    "outputId": "e06af367-9615-41b9-c0f4-fd1c73c37505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-lr.joblib']"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC2, \"a1q4-lr.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S82-8Q_A3J70",
    "outputId": "fdac165d-e6c9-403a-ea14-b3b91c755d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23.526981</td>\n",
       "      <td>0.156104</td>\n",
       "      <td>1.340306</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.014910</td>\n",
       "      <td>2.176752</td>\n",
       "      <td>2.340276</td>\n",
       "      <td>2.177313</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.291620</td>\n",
       "      <td>0.103523</td>\n",
       "      <td>1.327852</td>\n",
       "      <td>0.041902</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.014910</td>\n",
       "      <td>2.176752</td>\n",
       "      <td>2.340276</td>\n",
       "      <td>2.177313</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.530664</td>\n",
       "      <td>0.255699</td>\n",
       "      <td>1.426936</td>\n",
       "      <td>0.054671</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.014910</td>\n",
       "      <td>2.176752</td>\n",
       "      <td>2.340276</td>\n",
       "      <td>2.177313</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23.401217</td>\n",
       "      <td>0.116204</td>\n",
       "      <td>1.313538</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.014910</td>\n",
       "      <td>2.176752</td>\n",
       "      <td>2.340276</td>\n",
       "      <td>2.177313</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.942655</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>1.265434</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.027164</td>\n",
       "      <td>2.172968</td>\n",
       "      <td>2.324500</td>\n",
       "      <td>2.174878</td>\n",
       "      <td>0.121395</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>22.054128</td>\n",
       "      <td>0.045790</td>\n",
       "      <td>1.244816</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.027164</td>\n",
       "      <td>2.172968</td>\n",
       "      <td>2.324500</td>\n",
       "      <td>2.174878</td>\n",
       "      <td>0.121395</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.726078</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>1.270770</td>\n",
       "      <td>0.040289</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.037490</td>\n",
       "      <td>2.160294</td>\n",
       "      <td>2.310536</td>\n",
       "      <td>2.169440</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.766550</td>\n",
       "      <td>1.335187</td>\n",
       "      <td>1.021240</td>\n",
       "      <td>0.230929</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.037490</td>\n",
       "      <td>2.160294</td>\n",
       "      <td>2.310536</td>\n",
       "      <td>2.169440</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.728874</td>\n",
       "      <td>0.051281</td>\n",
       "      <td>1.238800</td>\n",
       "      <td>0.044777</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.037490</td>\n",
       "      <td>2.160294</td>\n",
       "      <td>2.310536</td>\n",
       "      <td>2.169440</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.720190</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>1.353819</td>\n",
       "      <td>0.023107</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.008032</td>\n",
       "      <td>2.180549</td>\n",
       "      <td>2.318572</td>\n",
       "      <td>2.169051</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.699335</td>\n",
       "      <td>0.131455</td>\n",
       "      <td>1.351811</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.008032</td>\n",
       "      <td>2.180549</td>\n",
       "      <td>2.318572</td>\n",
       "      <td>2.169051</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.700513</td>\n",
       "      <td>0.268886</td>\n",
       "      <td>1.424955</td>\n",
       "      <td>0.048699</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.008032</td>\n",
       "      <td>2.180549</td>\n",
       "      <td>2.318572</td>\n",
       "      <td>2.169051</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>19.415823</td>\n",
       "      <td>0.109606</td>\n",
       "      <td>1.139874</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.005214</td>\n",
       "      <td>2.164971</td>\n",
       "      <td>2.266032</td>\n",
       "      <td>2.145406</td>\n",
       "      <td>0.107374</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19.357410</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>1.156025</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>2.005214</td>\n",
       "      <td>2.164971</td>\n",
       "      <td>2.266032</td>\n",
       "      <td>2.145406</td>\n",
       "      <td>0.107374</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.995572</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>1.097263</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.093802</td>\n",
       "      <td>2.214839</td>\n",
       "      <td>2.100092</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.193832</td>\n",
       "      <td>0.082205</td>\n",
       "      <td>1.168315</td>\n",
       "      <td>0.041318</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.093802</td>\n",
       "      <td>2.214839</td>\n",
       "      <td>2.100092</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18.037211</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>1.079606</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.093802</td>\n",
       "      <td>2.214839</td>\n",
       "      <td>2.100092</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17.977864</td>\n",
       "      <td>0.049927</td>\n",
       "      <td>1.080350</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.093802</td>\n",
       "      <td>2.214839</td>\n",
       "      <td>2.100092</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.462445</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>1.142624</td>\n",
       "      <td>0.069428</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.991635</td>\n",
       "      <td>2.093802</td>\n",
       "      <td>2.214839</td>\n",
       "      <td>2.100092</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.463723</td>\n",
       "      <td>0.067681</td>\n",
       "      <td>1.055671</td>\n",
       "      <td>0.027458</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.966182</td>\n",
       "      <td>1.976675</td>\n",
       "      <td>2.060157</td>\n",
       "      <td>2.001004</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.497595</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>1.113116</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.966182</td>\n",
       "      <td>1.976675</td>\n",
       "      <td>2.060157</td>\n",
       "      <td>2.001004</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.537114</td>\n",
       "      <td>0.052730</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.966182</td>\n",
       "      <td>1.976675</td>\n",
       "      <td>2.060157</td>\n",
       "      <td>2.001004</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16.283222</td>\n",
       "      <td>0.063435</td>\n",
       "      <td>1.022868</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.554662</td>\n",
       "      <td>0.268085</td>\n",
       "      <td>1.057477</td>\n",
       "      <td>0.057425</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.443324</td>\n",
       "      <td>0.153099</td>\n",
       "      <td>1.021904</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.343123</td>\n",
       "      <td>0.048172</td>\n",
       "      <td>1.027963</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16.317760</td>\n",
       "      <td>0.104987</td>\n",
       "      <td>1.030067</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16.419563</td>\n",
       "      <td>0.114966</td>\n",
       "      <td>1.082128</td>\n",
       "      <td>0.050424</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.847063</td>\n",
       "      <td>1.751007</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.800824</td>\n",
       "      <td>0.039296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.815717</td>\n",
       "      <td>0.090722</td>\n",
       "      <td>1.081876</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.755310</td>\n",
       "      <td>1.793722</td>\n",
       "      <td>1.794519</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.884533</td>\n",
       "      <td>0.034072</td>\n",
       "      <td>1.121486</td>\n",
       "      <td>0.051666</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.755310</td>\n",
       "      <td>1.793722</td>\n",
       "      <td>1.794519</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.739260</td>\n",
       "      <td>0.118267</td>\n",
       "      <td>1.091959</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.834526</td>\n",
       "      <td>1.755310</td>\n",
       "      <td>1.793722</td>\n",
       "      <td>1.794519</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.097568</td>\n",
       "      <td>0.046035</td>\n",
       "      <td>1.123953</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.751927</td>\n",
       "      <td>1.804403</td>\n",
       "      <td>1.791945</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21.558908</td>\n",
       "      <td>0.155649</td>\n",
       "      <td>1.270289</td>\n",
       "      <td>0.058202</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.803752</td>\n",
       "      <td>1.754694</td>\n",
       "      <td>1.814553</td>\n",
       "      <td>1.790999</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.907797</td>\n",
       "      <td>0.113831</td>\n",
       "      <td>1.358242</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.803752</td>\n",
       "      <td>1.754694</td>\n",
       "      <td>1.814553</td>\n",
       "      <td>1.790999</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21.562854</td>\n",
       "      <td>0.118717</td>\n",
       "      <td>1.284673</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.803752</td>\n",
       "      <td>1.754694</td>\n",
       "      <td>1.814553</td>\n",
       "      <td>1.790999</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.363264</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>1.167590</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.810610</td>\n",
       "      <td>1.742768</td>\n",
       "      <td>1.805706</td>\n",
       "      <td>1.786361</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.410103</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>1.183160</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.810610</td>\n",
       "      <td>1.742768</td>\n",
       "      <td>1.805706</td>\n",
       "      <td>1.786361</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.393155</td>\n",
       "      <td>0.049279</td>\n",
       "      <td>1.227959</td>\n",
       "      <td>0.040231</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.810610</td>\n",
       "      <td>1.742768</td>\n",
       "      <td>1.805706</td>\n",
       "      <td>1.786361</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.504418</td>\n",
       "      <td>0.155444</td>\n",
       "      <td>1.241111</td>\n",
       "      <td>0.053317</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.810610</td>\n",
       "      <td>1.742768</td>\n",
       "      <td>1.805706</td>\n",
       "      <td>1.786361</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.285055</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>1.351957</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>LogisticRegression(random_state=0, solver='sag')</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': LogisticRegression(...</td>\n",
       "      <td>1.795655</td>\n",
       "      <td>1.750088</td>\n",
       "      <td>1.809627</td>\n",
       "      <td>1.785123</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "20      23.526981      0.156104  ...        0.132831                1\n",
       "16      23.291620      0.103523  ...        0.132831                1\n",
       "4       23.530664      0.255699  ...        0.132831                1\n",
       "31      23.401217      0.116204  ...        0.132831                1\n",
       "14      21.942655      0.031920  ...        0.121395                5\n",
       "34      22.054128      0.045790  ...        0.121395                5\n",
       "21      20.726078      0.134494  ...        0.111658                7\n",
       "39      19.766550      1.335187  ...        0.111658                7\n",
       "2       20.728874      0.051281  ...        0.111658                7\n",
       "9       24.720190      0.126437  ...        0.127038               10\n",
       "10      24.699335      0.131455  ...        0.127038               10\n",
       "6       24.700513      0.268886  ...        0.127038               10\n",
       "35      19.415823      0.109606  ...        0.107374               13\n",
       "25      19.357410      0.063394  ...        0.107374               13\n",
       "12      17.995572      0.056840  ...        0.091231               15\n",
       "3       18.193832      0.082205  ...        0.091231               15\n",
       "38      18.037211      0.055861  ...        0.091231               15\n",
       "37      17.977864      0.049927  ...        0.091231               15\n",
       "23      18.462445      0.059128  ...        0.091231               15\n",
       "13      16.463723      0.067681  ...        0.042046               20\n",
       "15      16.497595      0.043186  ...        0.042046               20\n",
       "24      16.537114      0.052730  ...        0.042046               20\n",
       "32      16.283222      0.063435  ...        0.039296               23\n",
       "29      16.554662      0.268085  ...        0.039296               23\n",
       "7       16.443324      0.153099  ...        0.039296               23\n",
       "17      16.343123      0.048172  ...        0.039296               23\n",
       "36      16.317760      0.104987  ...        0.039296               23\n",
       "22      16.419563      0.114966  ...        0.039296               23\n",
       "33      17.815717      0.090722  ...        0.032345               29\n",
       "19      17.884533      0.034072  ...        0.032345               29\n",
       "11      17.739260      0.118267  ...        0.032345               29\n",
       "8       19.097568      0.046035  ...        0.028961               32\n",
       "30      21.558908      0.155649  ...        0.026048               33\n",
       "5       21.907797      0.113831  ...        0.026048               33\n",
       "28      21.562854      0.118717  ...        0.026048               33\n",
       "27      20.363264      0.054762  ...        0.030890               36\n",
       "26      20.410103      0.085233  ...        0.030890               36\n",
       "18      20.393155      0.049279  ...        0.030890               36\n",
       "1       20.504418      0.155444  ...        0.030890               36\n",
       "0       23.285055      0.115234  ...        0.025422               40\n",
       "\n",
       "[40 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(RSC2.cv_results_)\n",
    "df2 = df2.sort_values(by ='rank_test_score')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAyeKxXzJYfi"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4d &mdash; Maximize compression with a AdaBoostClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with an *AdaBoostClassifier*.** Again, your code cell should display a *DataFrame* of your search results like for *Q4a*. Be sure to also consider setting adjusting hyperparameters of the *base_estimator* used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jA59vhwJYfi",
    "outputId": "6f07a4b5-3d1b-460a-c03c-ef5be5ca6e54",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 18.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator': AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=8,\n",
      "                                                         random_state=0),\n",
      "                   n_estimators=80, random_state=0), 'RankEncoder__estimator__algorithm': 'SAMME', 'RankEncoder__estimator__base_estimator__max_depth': 8, 'RankEncoder__estimator__n_estimators': 80, 'RankEncoder__extractor__encoder': OrdinalEncoder(), 'RankEncoder__extractor__size': 4}\n",
      "best validation score is:  2.17434118114916\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "param_grid3 = {'RankEncoder__estimator':[sklearn.ensemble.AdaBoostClassifier(sklearn.tree.DecisionTreeClassifier(random_state=0), random_state=0)],\n",
    "               'RankEncoder__estimator__algorithm' : ['SAMME', 'SAMME.R'],\n",
    "               'RankEncoder__estimator__n_estimators': [50,60,70,80,90],\n",
    "               'RankEncoder__estimator__base_estimator__max_depth' : randint(1, 9),\n",
    "               'RankEncoder__extractor__size' : randint(1, 8),\n",
    "               'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC3 = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid3, \n",
    "                                                 verbose= 1, cv=3, random_state= 0, n_iter=50, n_jobs=-1)\n",
    "RSC3.fit(train)\n",
    "print('best parameter combination is: ', RSC3.best_params_)\n",
    "print('best validation score is: ', RSC3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6477XYVy94TR",
    "outputId": "b9b6f2d7-bab7-4c97-a70f-f256738a6f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-Aboost.joblib']"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC3, \"a1q4-Aboost.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "twTyXYYp9_u1",
    "outputId": "c71c4f8f-068b-44b4-8cb5-dd32b596808d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator</th>\n",
       "      <th>param_RankEncoder__estimator__algorithm</th>\n",
       "      <th>param_RankEncoder__estimator__base_estimator__max_depth</th>\n",
       "      <th>param_RankEncoder__estimator__n_estimators</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.405952</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>2.840161</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>2.066970</td>\n",
       "      <td>2.199736</td>\n",
       "      <td>2.256318</td>\n",
       "      <td>2.174341</td>\n",
       "      <td>0.079359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.444724</td>\n",
       "      <td>0.130121</td>\n",
       "      <td>2.816847</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>2.055921</td>\n",
       "      <td>2.154708</td>\n",
       "      <td>2.198769</td>\n",
       "      <td>2.136466</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9.181072</td>\n",
       "      <td>0.042072</td>\n",
       "      <td>2.893280</td>\n",
       "      <td>0.032588</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>2.039984</td>\n",
       "      <td>2.112379</td>\n",
       "      <td>2.193945</td>\n",
       "      <td>2.115436</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.709785</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>2.173834</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.977066</td>\n",
       "      <td>2.015723</td>\n",
       "      <td>2.190581</td>\n",
       "      <td>2.061123</td>\n",
       "      <td>0.092891</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.272066</td>\n",
       "      <td>0.083788</td>\n",
       "      <td>3.223599</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.979806</td>\n",
       "      <td>2.114165</td>\n",
       "      <td>2.082899</td>\n",
       "      <td>2.058957</td>\n",
       "      <td>0.057405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.024069</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>2.295468</td>\n",
       "      <td>0.038837</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.971998</td>\n",
       "      <td>2.064836</td>\n",
       "      <td>2.103049</td>\n",
       "      <td>2.046628</td>\n",
       "      <td>0.055029</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.711489</td>\n",
       "      <td>0.035518</td>\n",
       "      <td>3.257464</td>\n",
       "      <td>0.045875</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>2.015723</td>\n",
       "      <td>2.055921</td>\n",
       "      <td>2.059732</td>\n",
       "      <td>2.043792</td>\n",
       "      <td>0.019909</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.676673</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>2.182199</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.935734</td>\n",
       "      <td>2.004008</td>\n",
       "      <td>2.079434</td>\n",
       "      <td>2.006392</td>\n",
       "      <td>0.058690</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9.757597</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>3.006130</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.920861</td>\n",
       "      <td>1.990050</td>\n",
       "      <td>2.045408</td>\n",
       "      <td>1.985439</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.847323</td>\n",
       "      <td>0.091111</td>\n",
       "      <td>2.373703</td>\n",
       "      <td>0.030871</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.945904</td>\n",
       "      <td>1.954652</td>\n",
       "      <td>2.043318</td>\n",
       "      <td>1.981291</td>\n",
       "      <td>0.044005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.761581</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>2.298298</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.945904</td>\n",
       "      <td>1.954652</td>\n",
       "      <td>2.043318</td>\n",
       "      <td>1.981291</td>\n",
       "      <td>0.044005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.263646</td>\n",
       "      <td>0.068245</td>\n",
       "      <td>3.223462</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.953507</td>\n",
       "      <td>2.005616</td>\n",
       "      <td>1.974724</td>\n",
       "      <td>1.977949</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.858495</td>\n",
       "      <td>0.107014</td>\n",
       "      <td>2.991727</td>\n",
       "      <td>0.035262</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.922707</td>\n",
       "      <td>1.942879</td>\n",
       "      <td>2.055076</td>\n",
       "      <td>1.973554</td>\n",
       "      <td>0.058230</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.426092</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>2.796148</td>\n",
       "      <td>0.068554</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.923447</td>\n",
       "      <td>1.941748</td>\n",
       "      <td>2.039568</td>\n",
       "      <td>1.968254</td>\n",
       "      <td>0.050977</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10.274413</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>3.013500</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.897173</td>\n",
       "      <td>1.941748</td>\n",
       "      <td>2.041233</td>\n",
       "      <td>1.960051</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.720831</td>\n",
       "      <td>0.178632</td>\n",
       "      <td>3.126809</td>\n",
       "      <td>0.059133</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.909855</td>\n",
       "      <td>1.956564</td>\n",
       "      <td>2.011263</td>\n",
       "      <td>1.959227</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.871893</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>3.329272</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.839926</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>2.035002</td>\n",
       "      <td>1.942684</td>\n",
       "      <td>0.079981</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.502021</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>2.749823</td>\n",
       "      <td>0.047418</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.907669</td>\n",
       "      <td>1.913509</td>\n",
       "      <td>1.943635</td>\n",
       "      <td>1.921604</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.820001</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>3.043234</td>\n",
       "      <td>0.078762</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.873712</td>\n",
       "      <td>1.883594</td>\n",
       "      <td>2.006823</td>\n",
       "      <td>1.921376</td>\n",
       "      <td>0.060555</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.473414</td>\n",
       "      <td>0.058006</td>\n",
       "      <td>2.428142</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.874063</td>\n",
       "      <td>1.893581</td>\n",
       "      <td>1.992429</td>\n",
       "      <td>1.920024</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.295370</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>2.159343</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.897893</td>\n",
       "      <td>1.886437</td>\n",
       "      <td>1.944012</td>\n",
       "      <td>1.909447</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.564499</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>3.840339</td>\n",
       "      <td>0.057299</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.896454</td>\n",
       "      <td>1.883239</td>\n",
       "      <td>1.926040</td>\n",
       "      <td>1.901911</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19.095849</td>\n",
       "      <td>2.845157</td>\n",
       "      <td>3.841346</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.933114</td>\n",
       "      <td>1.895735</td>\n",
       "      <td>1.873712</td>\n",
       "      <td>1.900854</td>\n",
       "      <td>0.024520</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.092703</td>\n",
       "      <td>0.057809</td>\n",
       "      <td>2.736872</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.858391</td>\n",
       "      <td>1.943635</td>\n",
       "      <td>1.896866</td>\n",
       "      <td>0.035291</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8.168683</td>\n",
       "      <td>0.119474</td>\n",
       "      <td>2.927177</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.841282</td>\n",
       "      <td>1.867065</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>1.887157</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.243621</td>\n",
       "      <td>0.097825</td>\n",
       "      <td>3.432983</td>\n",
       "      <td>0.055898</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.910950</td>\n",
       "      <td>1.879699</td>\n",
       "      <td>1.868111</td>\n",
       "      <td>1.886253</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>17.256604</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>3.755593</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.868111</td>\n",
       "      <td>1.847404</td>\n",
       "      <td>1.858045</td>\n",
       "      <td>1.857854</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.349592</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>2.674947</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.870557</td>\n",
       "      <td>1.827151</td>\n",
       "      <td>1.865324</td>\n",
       "      <td>1.854344</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.290012</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>2.163645</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.868810</td>\n",
       "      <td>1.784121</td>\n",
       "      <td>1.892864</td>\n",
       "      <td>1.848598</td>\n",
       "      <td>0.046638</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.714542</td>\n",
       "      <td>0.076448</td>\n",
       "      <td>2.888983</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.852881</td>\n",
       "      <td>1.825151</td>\n",
       "      <td>1.864628</td>\n",
       "      <td>1.847553</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.433092</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>2.387171</td>\n",
       "      <td>0.037080</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.845700</td>\n",
       "      <td>1.817521</td>\n",
       "      <td>1.868810</td>\n",
       "      <td>1.844010</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.137668</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>2.649095</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.828154</td>\n",
       "      <td>1.813237</td>\n",
       "      <td>1.851852</td>\n",
       "      <td>1.831081</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.582608</td>\n",
       "      <td>0.043770</td>\n",
       "      <td>3.679757</td>\n",
       "      <td>0.024707</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.871958</td>\n",
       "      <td>1.783485</td>\n",
       "      <td>1.836210</td>\n",
       "      <td>1.830551</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16.769895</td>\n",
       "      <td>0.151907</td>\n",
       "      <td>3.666500</td>\n",
       "      <td>0.049201</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.841282</td>\n",
       "      <td>1.815211</td>\n",
       "      <td>1.799532</td>\n",
       "      <td>1.818675</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.484638</td>\n",
       "      <td>0.062711</td>\n",
       "      <td>3.450772</td>\n",
       "      <td>0.059728</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.864280</td>\n",
       "      <td>1.744592</td>\n",
       "      <td>1.790831</td>\n",
       "      <td>1.799901</td>\n",
       "      <td>0.049282</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.873235</td>\n",
       "      <td>0.075108</td>\n",
       "      <td>2.974194</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.836547</td>\n",
       "      <td>1.758706</td>\n",
       "      <td>1.792436</td>\n",
       "      <td>1.795896</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.754309</td>\n",
       "      <td>0.067790</td>\n",
       "      <td>2.837881</td>\n",
       "      <td>0.065905</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.829157</td>\n",
       "      <td>1.742464</td>\n",
       "      <td>1.811922</td>\n",
       "      <td>1.794514</td>\n",
       "      <td>0.037472</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.775869</td>\n",
       "      <td>0.107996</td>\n",
       "      <td>3.177598</td>\n",
       "      <td>0.059921</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.822490</td>\n",
       "      <td>1.755310</td>\n",
       "      <td>1.803427</td>\n",
       "      <td>1.793742</td>\n",
       "      <td>0.028268</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.135790</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>2.790683</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.818512</td>\n",
       "      <td>1.758706</td>\n",
       "      <td>1.792436</td>\n",
       "      <td>1.789885</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.205673</td>\n",
       "      <td>0.052204</td>\n",
       "      <td>2.348247</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.819505</td>\n",
       "      <td>1.743679</td>\n",
       "      <td>1.783485</td>\n",
       "      <td>1.782223</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.929929</td>\n",
       "      <td>0.166086</td>\n",
       "      <td>4.655113</td>\n",
       "      <td>0.094245</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.837222</td>\n",
       "      <td>1.721763</td>\n",
       "      <td>1.768034</td>\n",
       "      <td>1.775673</td>\n",
       "      <td>0.047444</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21.486098</td>\n",
       "      <td>0.156681</td>\n",
       "      <td>4.594896</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.835536</td>\n",
       "      <td>1.722060</td>\n",
       "      <td>1.766784</td>\n",
       "      <td>1.774793</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.458617</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>2.483972</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.756852</td>\n",
       "      <td>1.752541</td>\n",
       "      <td>1.811922</td>\n",
       "      <td>1.773772</td>\n",
       "      <td>0.027034</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.253360</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>3.453242</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.849797</td>\n",
       "      <td>1.726221</td>\n",
       "      <td>1.738828</td>\n",
       "      <td>1.771615</td>\n",
       "      <td>0.055522</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.231177</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>4.988705</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.745810</td>\n",
       "      <td>1.822157</td>\n",
       "      <td>1.769436</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.949792</td>\n",
       "      <td>0.035723</td>\n",
       "      <td>4.381710</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.781896</td>\n",
       "      <td>1.715266</td>\n",
       "      <td>1.788909</td>\n",
       "      <td>1.762024</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.196711</td>\n",
       "      <td>0.150014</td>\n",
       "      <td>3.610806</td>\n",
       "      <td>0.034402</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.816860</td>\n",
       "      <td>1.721763</td>\n",
       "      <td>1.743071</td>\n",
       "      <td>1.760565</td>\n",
       "      <td>0.040746</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.981935</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>3.547205</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.813565</td>\n",
       "      <td>1.723841</td>\n",
       "      <td>1.741553</td>\n",
       "      <td>1.759653</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>23.919840</td>\n",
       "      <td>0.113156</td>\n",
       "      <td>5.051685</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.607200</td>\n",
       "      <td>1.635323</td>\n",
       "      <td>1.707067</td>\n",
       "      <td>1.649863</td>\n",
       "      <td>0.042047</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24.081006</td>\n",
       "      <td>0.176584</td>\n",
       "      <td>4.953098</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME',\\n       ...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': AdaBoostClassifier(...</td>\n",
       "      <td>1.582278</td>\n",
       "      <td>1.603592</td>\n",
       "      <td>1.520681</td>\n",
       "      <td>1.568851</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "10       9.405952      0.117293  ...        0.079359                1\n",
       "32       8.444724      0.130121  ...        0.059727                2\n",
       "30       9.181072      0.042072  ...        0.062891                3\n",
       "44       5.709785      0.040935  ...        0.092891                4\n",
       "36      14.272066      0.083788  ...        0.057405                5\n",
       "0        7.024069      0.062188  ...        0.055029                6\n",
       "6       14.711489      0.035518  ...        0.019909                7\n",
       "12       5.676673      0.008939  ...        0.058690                8\n",
       "37       9.757597      0.127050  ...        0.050951                9\n",
       "2        6.847323      0.091111  ...        0.044005               10\n",
       "19       6.761581      0.038742  ...        0.044005               10\n",
       "8       14.263646      0.068245  ...        0.021395               12\n",
       "11       7.858495      0.107014  ...        0.058230               13\n",
       "43       7.426092      0.033666  ...        0.050977               14\n",
       "48      10.274413      0.042568  ...        0.060219               15\n",
       "18       9.720831      0.178632  ...        0.041443               16\n",
       "9       14.871893      0.158850  ...        0.079981               17\n",
       "47       7.502021      0.081055  ...        0.015759               18\n",
       "27       9.820001      0.005237  ...        0.060555               19\n",
       "31       7.473414      0.058006  ...        0.051814               20\n",
       "35       5.295370      0.026854  ...        0.024885               21\n",
       "1       18.564499      0.017571  ...        0.017894               22\n",
       "49      19.095849      2.845157  ...        0.024520               23\n",
       "42       7.092703      0.057809  ...        0.035291               24\n",
       "25       8.168683      0.119474  ...        0.047819               25\n",
       "4       15.243621      0.097825  ...        0.018092               26\n",
       "39      17.256604      0.146200  ...        0.008455               27\n",
       "29       7.349592      0.015448  ...        0.019346               28\n",
       "41       5.290012      0.039888  ...        0.046638               29\n",
       "7        7.714542      0.076448  ...        0.016551               30\n",
       "3        6.433092      0.029940  ...        0.020973               31\n",
       "26       7.137668      0.109235  ...        0.015900               32\n",
       "13      16.582608      0.043770  ...        0.036340               33\n",
       "28      16.769895      0.151907  ...        0.017219               34\n",
       "21      15.484638      0.062711  ...        0.049282               35\n",
       "45       7.873235      0.075108  ...        0.031873               36\n",
       "34       7.754309      0.067790  ...        0.037472               37\n",
       "38       8.775869      0.107996  ...        0.028268               38\n",
       "23       7.135790      0.024289  ...        0.024483               39\n",
       "40       6.205673      0.052204  ...        0.030969               40\n",
       "5       21.929929      0.166086  ...        0.047444               41\n",
       "16      21.486098      0.156681  ...        0.046671               42\n",
       "22       6.458617      0.036313  ...        0.027034               43\n",
       "20      15.253360      0.116707  ...        0.055522               44\n",
       "17      24.231177      0.094577  ...        0.037346               45\n",
       "15      20.949792      0.035723  ...        0.033186               46\n",
       "14      16.196711      0.150014  ...        0.040746               47\n",
       "24      15.981935      0.036999  ...        0.038801               48\n",
       "33      23.919840      0.113156  ...        0.042047               49\n",
       "46      24.081006      0.176584  ...        0.035155               50\n",
       "\n",
       "[50 rows x 17 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(RSC3.cv_results_)\n",
    "df3 = df3.sort_values(by ='rank_test_score')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ4_MrtjJYfi"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4e &mdash; Maximize compression with a HistGradientBoostingClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *HistGradientBoostingClassifier*.** *HistGradientBoostingClassifier* is scikit-learn's implementation of gradient boosting that is inspired by speedups implemented in the popular [*LightGBM*](https://lightgbm.readthedocs.io/en/latest/) software library. It typically trains faster than *GradientBoostingClassifier*.\n",
    "\n",
    "Some tips:\n",
    "\n",
    "* Note that this classifier is still considered \"experimental\". See its scikit-learn documentation for how to enable importing an experimental estimator.\n",
    "* If you receive an error about, may need to disable \"early stopping\" so that the estimator does not try to further split the training data internally. See the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxoXYueeJYfj",
    "outputId": "933b7c20-b6b9-463e-9e70-bdb78adbc5d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator': HistGradientBoostingClassifier(early_stopping=False, max_depth=1, max_iter=30,\n",
      "                               random_state=0), 'RankEncoder__estimator__max_depth': 1, 'RankEncoder__estimator__max_iter': 30, 'RankEncoder__extractor__encoder': OrdinalEncoder(), 'RankEncoder__extractor__size': 4}\n",
      "best validation score is:  1.8527577187734767\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "param_grid4 = {'RankEncoder__estimator':[sklearn.ensemble.HistGradientBoostingClassifier(random_state=0, early_stopping=False)],\n",
    "               'RankEncoder__estimator__max_iter': [10,20,30,40,50],\n",
    "               'RankEncoder__estimator__max_depth' : randint(1, 10),\n",
    "               'RankEncoder__extractor__size' : randint(1, 8),\n",
    "               'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC4 = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid4, \n",
    "                                                 verbose= 1, cv=3, random_state= 0, n_iter=50, n_jobs=-1)\n",
    "RSC4.fit(train)\n",
    "print('best parameter combination is: ', RSC4.best_params_)\n",
    "print('best validation score is: ', RSC4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMK1ZRGNLzez",
    "outputId": "8ef2926a-ad75-4214-f1ff-8e6dfd22e575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-HGoost.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC4, \"a1q4-HGoost.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zNXx1BLfMBTN",
    "outputId": "34c88906-9b54-464b-d57d-8498fa0cfac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator</th>\n",
       "      <th>param_RankEncoder__estimator__max_depth</th>\n",
       "      <th>param_RankEncoder__estimator__max_iter</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.464967</td>\n",
       "      <td>0.137487</td>\n",
       "      <td>1.723175</td>\n",
       "      <td>0.057185</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.874766</td>\n",
       "      <td>1.803101</td>\n",
       "      <td>1.880406</td>\n",
       "      <td>1.852758</td>\n",
       "      <td>0.035188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.967218</td>\n",
       "      <td>0.071625</td>\n",
       "      <td>1.687833</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.870907</td>\n",
       "      <td>1.817851</td>\n",
       "      <td>1.853912</td>\n",
       "      <td>1.847557</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.078615</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>1.260796</td>\n",
       "      <td>0.043911</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.848087</td>\n",
       "      <td>1.766160</td>\n",
       "      <td>1.786033</td>\n",
       "      <td>1.800094</td>\n",
       "      <td>0.034893</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.626328</td>\n",
       "      <td>0.059890</td>\n",
       "      <td>1.509588</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.839250</td>\n",
       "      <td>1.723247</td>\n",
       "      <td>1.783167</td>\n",
       "      <td>1.781888</td>\n",
       "      <td>0.047367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.080538</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>1.680258</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.717328</td>\n",
       "      <td>1.767721</td>\n",
       "      <td>1.803101</td>\n",
       "      <td>1.762717</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.857313</td>\n",
       "      <td>0.089447</td>\n",
       "      <td>1.376158</td>\n",
       "      <td>0.296572</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.717328</td>\n",
       "      <td>1.767721</td>\n",
       "      <td>1.803101</td>\n",
       "      <td>1.762717</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.328425</td>\n",
       "      <td>0.098472</td>\n",
       "      <td>1.953690</td>\n",
       "      <td>0.041172</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.704158</td>\n",
       "      <td>1.681237</td>\n",
       "      <td>1.786671</td>\n",
       "      <td>1.724022</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.238566</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>1.611783</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.714384</td>\n",
       "      <td>1.623640</td>\n",
       "      <td>1.762425</td>\n",
       "      <td>1.700150</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8.227232</td>\n",
       "      <td>0.075101</td>\n",
       "      <td>1.654917</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.714384</td>\n",
       "      <td>1.623640</td>\n",
       "      <td>1.762425</td>\n",
       "      <td>1.700150</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.943985</td>\n",
       "      <td>0.087934</td>\n",
       "      <td>1.703868</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.694628</td>\n",
       "      <td>1.684920</td>\n",
       "      <td>1.705030</td>\n",
       "      <td>1.694859</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.722816</td>\n",
       "      <td>0.393844</td>\n",
       "      <td>2.182825</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.691761</td>\n",
       "      <td>1.608493</td>\n",
       "      <td>1.678134</td>\n",
       "      <td>1.659463</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.567257</td>\n",
       "      <td>0.271089</td>\n",
       "      <td>2.303727</td>\n",
       "      <td>0.067270</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.662234</td>\n",
       "      <td>1.582779</td>\n",
       "      <td>1.722060</td>\n",
       "      <td>1.655691</td>\n",
       "      <td>0.057049</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.391359</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>2.221148</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.662234</td>\n",
       "      <td>1.582779</td>\n",
       "      <td>1.722060</td>\n",
       "      <td>1.655691</td>\n",
       "      <td>0.057049</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.742023</td>\n",
       "      <td>0.244677</td>\n",
       "      <td>1.912535</td>\n",
       "      <td>0.045819</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.712622</td>\n",
       "      <td>1.592103</td>\n",
       "      <td>1.642576</td>\n",
       "      <td>1.649100</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.666678</td>\n",
       "      <td>0.220039</td>\n",
       "      <td>1.879035</td>\n",
       "      <td>0.031091</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.712622</td>\n",
       "      <td>1.590584</td>\n",
       "      <td>1.639613</td>\n",
       "      <td>1.647606</td>\n",
       "      <td>0.050141</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.495986</td>\n",
       "      <td>0.932665</td>\n",
       "      <td>2.254209</td>\n",
       "      <td>0.083435</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.669449</td>\n",
       "      <td>1.584535</td>\n",
       "      <td>1.647718</td>\n",
       "      <td>1.633901</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15.611901</td>\n",
       "      <td>0.915742</td>\n",
       "      <td>2.080369</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.739130</td>\n",
       "      <td>1.554968</td>\n",
       "      <td>1.597955</td>\n",
       "      <td>1.630684</td>\n",
       "      <td>0.078665</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.673863</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>1.860928</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.647446</td>\n",
       "      <td>1.530456</td>\n",
       "      <td>1.705321</td>\n",
       "      <td>1.627741</td>\n",
       "      <td>0.072735</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.371665</td>\n",
       "      <td>0.066566</td>\n",
       "      <td>2.251439</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.647175</td>\n",
       "      <td>1.553760</td>\n",
       "      <td>1.663617</td>\n",
       "      <td>1.621517</td>\n",
       "      <td>0.048379</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.349669</td>\n",
       "      <td>0.519784</td>\n",
       "      <td>1.974933</td>\n",
       "      <td>0.084198</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.559089</td>\n",
       "      <td>1.579779</td>\n",
       "      <td>1.692620</td>\n",
       "      <td>1.610496</td>\n",
       "      <td>0.058681</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.756193</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>2.081585</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.649077</td>\n",
       "      <td>1.576293</td>\n",
       "      <td>1.560549</td>\n",
       "      <td>1.595306</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.782412</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>2.022426</td>\n",
       "      <td>0.045961</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.670844</td>\n",
       "      <td>1.520913</td>\n",
       "      <td>1.569120</td>\n",
       "      <td>1.586959</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.020340</td>\n",
       "      <td>0.217979</td>\n",
       "      <td>1.886392</td>\n",
       "      <td>0.048285</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>1.638807</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>1.539883</td>\n",
       "      <td>1.580397</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.492711</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.357848</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.092211</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.339830</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.592397</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.262466</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345703</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511850</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608054</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.559677</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.110511</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.344376</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.192946</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.467572</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.179671</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.415676</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.409203</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.469448</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.469145</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.386986</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.268618</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.574255</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>HistGradientBoostingClassifier(early_stopping=...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': HistGradientBoostin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "10       8.464967      0.137487  ...        0.035188                1\n",
       "24       6.967218      0.071625  ...        0.022121                2\n",
       "34       4.078615      0.003782  ...        0.034893                3\n",
       "36       5.626328      0.059890  ...        0.047367                4\n",
       "40       6.080538      0.230952  ...        0.035195                5\n",
       "48       5.857313      0.089447  ...        0.035195                5\n",
       "43      10.328425      0.098472  ...        0.045277                7\n",
       "13       8.238566      0.038305  ...        0.057546                8\n",
       "47       8.227232      0.075101  ...        0.057546                8\n",
       "3        8.943985      0.087934  ...        0.008211               10\n",
       "21      14.722816      0.393844  ...        0.036468               11\n",
       "20      15.567257      0.271089  ...        0.057049               12\n",
       "18      14.391359      0.226800  ...        0.057049               12\n",
       "28      10.742023      0.244677  ...        0.049417               14\n",
       "16      11.666678      0.220039  ...        0.050141               15\n",
       "33      17.495986      0.932665  ...        0.036017               16\n",
       "35      15.611901      0.915742  ...        0.078665               17\n",
       "11      11.673863      0.181972  ...        0.072735               18\n",
       "32      13.371665      0.066566  ...        0.048379               19\n",
       "29       9.349669      0.519784  ...        0.058681               20\n",
       "44      13.756193      0.136789  ...        0.038561               21\n",
       "5       14.782412      0.546839  ...        0.062495               22\n",
       "14      11.020340      0.217979  ...        0.042322               23\n",
       "39       0.113638      0.004856  ...             NaN               24\n",
       "38       0.111583      0.001573  ...             NaN               25\n",
       "41       0.492711      0.011179  ...             NaN               26\n",
       "42       0.357848      0.002065  ...             NaN               27\n",
       "45       0.092211      0.001268  ...             NaN               28\n",
       "46       0.339830      0.004699  ...             NaN               29\n",
       "37       0.592397      0.010376  ...             NaN               30\n",
       "31       0.262466      0.003166  ...             NaN               31\n",
       "0        0.345703      0.008618  ...             NaN               32\n",
       "27       0.118694      0.013521  ...             NaN               33\n",
       "1        0.511850      0.013958  ...             NaN               34\n",
       "2        0.608054      0.005450  ...             NaN               35\n",
       "4        0.491146      0.012814  ...             NaN               36\n",
       "6        0.559677      0.015845  ...             NaN               37\n",
       "7        0.110511      0.003485  ...             NaN               38\n",
       "8        0.344376      0.003998  ...             NaN               39\n",
       "9        0.192946      0.005913  ...             NaN               40\n",
       "12       0.467572      0.006083  ...             NaN               41\n",
       "15       0.179671      0.005781  ...             NaN               42\n",
       "17       0.415676      0.004712  ...             NaN               43\n",
       "19       0.409203      0.013019  ...             NaN               44\n",
       "22       0.469448      0.011546  ...             NaN               45\n",
       "23       0.469145      0.002541  ...             NaN               46\n",
       "25       0.386986      0.024889  ...             NaN               47\n",
       "26       0.094021      0.000362  ...             NaN               48\n",
       "30       0.268618      0.004899  ...             NaN               49\n",
       "49       0.574255      0.002790  ...             NaN               50\n",
       "\n",
       "[50 rows x 16 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(RSC4.cv_results_)\n",
    "df4 = df4.sort_values(by ='rank_test_score')\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoZR-GszJYfj"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4f &mdash; Maximize compression with an SVC [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with an *SVC*.** Some tips:\n",
    "\n",
    "* Training an SVM to predict many classes is extremely slow (one-vs-rest). Depending on how powerful your computer is, you may need to limit the number of  training examples and/or the SVC's training iterations.\n",
    "* Remember that your rank encoder ultimately needs *predict_proba*. This is not enabled by default on *SVC* classifiers, because it takes extra time to 'calibrate'. Check the *SVC* documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_R343CtJYfj",
    "outputId": "3ca2f14e-c2eb-4a4c-8e34-772591132d07",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 12.2min finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter combination is:  {'RankEncoder__estimator': SVC(C=100, gamma=0.1, max_iter=1, probability=True, random_state=0), 'RankEncoder__estimator__C': 100, 'RankEncoder__estimator__gamma': 0.1, 'RankEncoder__extractor__encoder': OneHotEncoder(), 'RankEncoder__extractor__size': 1}\n",
      "best validation score is:  1.7735309809422006\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "param_grid5 = {'RankEncoder__estimator':[sklearn.svm.SVC(random_state=0,  probability=True, max_iter=1)],\n",
    "               'RankEncoder__estimator__C': [1,10,100,1000],\n",
    "               'RankEncoder__estimator__gamma': [0.001,0.01,0.1,1],\n",
    "               'RankEncoder__extractor__size' : randint(1, 8),\n",
    "               'RankEncoder__extractor__encoder': [sklearn.preprocessing.OrdinalEncoder(), sklearn.preprocessing.OneHotEncoder()]}\n",
    "RSC5 = sklearn.model_selection.RandomizedSearchCV(estimator=compress, \n",
    "                                                 param_distributions=param_grid5, \n",
    "                                                 verbose= 1, cv=2, random_state= 0, n_iter=40, n_jobs=-1)\n",
    "RSC5.fit(train[0:2])\n",
    "print('best parameter combination is: ', RSC5.best_params_)\n",
    "print('best validation score is: ', RSC5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9G6cRjtVD9_0",
    "outputId": "8eb8f6bd-b63a-4e31-f0f4-574b5dc22aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1q4-SVM.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RSC5, \"a1q4-SVM.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pRBgHU7_EKIV",
    "outputId": "5263cffb-e928-4f22-fd51-3b06ea9f309b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_RankEncoder__estimator</th>\n",
       "      <th>param_RankEncoder__estimator__C</th>\n",
       "      <th>param_RankEncoder__estimator__gamma</th>\n",
       "      <th>param_RankEncoder__extractor__encoder</th>\n",
       "      <th>param_RankEncoder__extractor__size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.469282</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>6.611572</td>\n",
       "      <td>0.214228</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.831502</td>\n",
       "      <td>1.715560</td>\n",
       "      <td>1.773531</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.409626</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>7.254898</td>\n",
       "      <td>0.195674</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.827819</td>\n",
       "      <td>1.716149</td>\n",
       "      <td>1.771984</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.036431</td>\n",
       "      <td>0.191749</td>\n",
       "      <td>7.184427</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.817851</td>\n",
       "      <td>1.721170</td>\n",
       "      <td>1.769511</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.415875</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>7.258508</td>\n",
       "      <td>0.164626</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.818512</td>\n",
       "      <td>1.719099</td>\n",
       "      <td>1.768806</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.014184</td>\n",
       "      <td>0.221012</td>\n",
       "      <td>7.242903</td>\n",
       "      <td>0.168665</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.813237</td>\n",
       "      <td>1.720578</td>\n",
       "      <td>1.766907</td>\n",
       "      <td>0.046329</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.490270</td>\n",
       "      <td>0.199394</td>\n",
       "      <td>6.556243</td>\n",
       "      <td>0.216206</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.816530</td>\n",
       "      <td>1.714972</td>\n",
       "      <td>1.765751</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8.639768</td>\n",
       "      <td>0.240894</td>\n",
       "      <td>6.696035</td>\n",
       "      <td>0.207213</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.816201</td>\n",
       "      <td>1.714972</td>\n",
       "      <td>1.765586</td>\n",
       "      <td>0.050614</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9.149130</td>\n",
       "      <td>0.119742</td>\n",
       "      <td>7.290592</td>\n",
       "      <td>0.228015</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.809627</td>\n",
       "      <td>1.717328</td>\n",
       "      <td>1.763478</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.387043</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>7.438749</td>\n",
       "      <td>0.076343</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.812579</td>\n",
       "      <td>1.714090</td>\n",
       "      <td>1.763335</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.231069</td>\n",
       "      <td>0.233167</td>\n",
       "      <td>7.459030</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.805380</td>\n",
       "      <td>1.715266</td>\n",
       "      <td>1.760323</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.392139</td>\n",
       "      <td>0.210024</td>\n",
       "      <td>7.365717</td>\n",
       "      <td>0.228056</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.805706</td>\n",
       "      <td>1.707359</td>\n",
       "      <td>1.756532</td>\n",
       "      <td>0.049174</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.429417</td>\n",
       "      <td>0.228543</td>\n",
       "      <td>9.077552</td>\n",
       "      <td>0.246969</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.800828</td>\n",
       "      <td>1.709402</td>\n",
       "      <td>1.755115</td>\n",
       "      <td>0.045713</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.090877</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>8.018589</td>\n",
       "      <td>0.119889</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>2</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.792115</td>\n",
       "      <td>1.712622</td>\n",
       "      <td>1.752368</td>\n",
       "      <td>0.039746</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.084664</td>\n",
       "      <td>0.158211</td>\n",
       "      <td>7.920265</td>\n",
       "      <td>0.129765</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.799856</td>\n",
       "      <td>1.703868</td>\n",
       "      <td>1.751862</td>\n",
       "      <td>0.047994</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.541211</td>\n",
       "      <td>0.233475</td>\n",
       "      <td>8.742120</td>\n",
       "      <td>0.308684</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.792436</td>\n",
       "      <td>1.709986</td>\n",
       "      <td>1.751211</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.544156</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>7.337643</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.813237</td>\n",
       "      <td>1.686341</td>\n",
       "      <td>1.749789</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.685523</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>7.386046</td>\n",
       "      <td>0.209683</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.813237</td>\n",
       "      <td>1.686341</td>\n",
       "      <td>1.749789</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.443700</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>7.246517</td>\n",
       "      <td>0.196129</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.813237</td>\n",
       "      <td>1.686341</td>\n",
       "      <td>1.749789</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.937626</td>\n",
       "      <td>0.144047</td>\n",
       "      <td>8.400482</td>\n",
       "      <td>0.198730</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.777146</td>\n",
       "      <td>1.706485</td>\n",
       "      <td>1.741815</td>\n",
       "      <td>0.035331</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.084211</td>\n",
       "      <td>0.232608</td>\n",
       "      <td>8.495040</td>\n",
       "      <td>0.164986</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.780310</td>\n",
       "      <td>1.701838</td>\n",
       "      <td>1.741074</td>\n",
       "      <td>0.039236</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.033435</td>\n",
       "      <td>0.034099</td>\n",
       "      <td>9.033109</td>\n",
       "      <td>0.096234</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.757469</td>\n",
       "      <td>1.704449</td>\n",
       "      <td>1.730959</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.856207</td>\n",
       "      <td>0.105376</td>\n",
       "      <td>8.920334</td>\n",
       "      <td>0.104954</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.757469</td>\n",
       "      <td>1.704449</td>\n",
       "      <td>1.730959</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.503096</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>8.301688</td>\n",
       "      <td>0.231307</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>3</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.761184</td>\n",
       "      <td>1.699524</td>\n",
       "      <td>1.730354</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11.416318</td>\n",
       "      <td>0.119541</td>\n",
       "      <td>8.622069</td>\n",
       "      <td>0.145590</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.739433</td>\n",
       "      <td>1.717033</td>\n",
       "      <td>1.728233</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9.424881</td>\n",
       "      <td>1.385099</td>\n",
       "      <td>6.921454</td>\n",
       "      <td>1.306350</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.738526</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>1.726161</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.841273</td>\n",
       "      <td>0.167346</td>\n",
       "      <td>8.395280</td>\n",
       "      <td>0.259684</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.738526</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>1.726161</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.524885</td>\n",
       "      <td>0.245417</td>\n",
       "      <td>8.040516</td>\n",
       "      <td>0.091891</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.731302</td>\n",
       "      <td>1.715854</td>\n",
       "      <td>1.723578</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.462886</td>\n",
       "      <td>0.115238</td>\n",
       "      <td>8.159246</td>\n",
       "      <td>0.142879</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.740341</td>\n",
       "      <td>1.696065</td>\n",
       "      <td>1.718203</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.497959</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>8.109732</td>\n",
       "      <td>0.163140</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.722060</td>\n",
       "      <td>1.713502</td>\n",
       "      <td>1.717781</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.750230</td>\n",
       "      <td>0.193769</td>\n",
       "      <td>8.488848</td>\n",
       "      <td>0.140334</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.715560</td>\n",
       "      <td>1.705321</td>\n",
       "      <td>1.710440</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.402859</td>\n",
       "      <td>0.199935</td>\n",
       "      <td>7.970694</td>\n",
       "      <td>0.238214</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.712915</td>\n",
       "      <td>1.706485</td>\n",
       "      <td>1.709700</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.446686</td>\n",
       "      <td>0.241512</td>\n",
       "      <td>8.080004</td>\n",
       "      <td>0.369990</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.708234</td>\n",
       "      <td>1.702997</td>\n",
       "      <td>1.705615</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.073973</td>\n",
       "      <td>0.199038</td>\n",
       "      <td>8.376348</td>\n",
       "      <td>0.190846</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.699235</td>\n",
       "      <td>1.697217</td>\n",
       "      <td>1.698226</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.271547</td>\n",
       "      <td>0.185027</td>\n",
       "      <td>6.974447</td>\n",
       "      <td>0.117077</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.707067</td>\n",
       "      <td>1.681237</td>\n",
       "      <td>1.694152</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9.472895</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>7.058905</td>\n",
       "      <td>0.050156</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>4</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.707067</td>\n",
       "      <td>1.681237</td>\n",
       "      <td>1.694152</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.858025</td>\n",
       "      <td>0.216007</td>\n",
       "      <td>8.906548</td>\n",
       "      <td>0.212456</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>OneHotEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.672800</td>\n",
       "      <td>1.707942</td>\n",
       "      <td>1.690371</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.952279</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>8.391951</td>\n",
       "      <td>0.136147</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>7</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.710864</td>\n",
       "      <td>1.667779</td>\n",
       "      <td>1.689321</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.776619</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>8.601207</td>\n",
       "      <td>0.252093</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.714384</td>\n",
       "      <td>1.662787</td>\n",
       "      <td>1.688585</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.905238</td>\n",
       "      <td>0.072094</td>\n",
       "      <td>8.459917</td>\n",
       "      <td>0.162633</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>6</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.688904</td>\n",
       "      <td>1.642845</td>\n",
       "      <td>1.665875</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.333133</td>\n",
       "      <td>0.197664</td>\n",
       "      <td>8.265946</td>\n",
       "      <td>0.171206</td>\n",
       "      <td>SVC(C=100, gamma=0.1, max_iter=1, probability=...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>OrdinalEncoder()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'RankEncoder__estimator': SVC(C=100, gamma=0....</td>\n",
       "      <td>1.681803</td>\n",
       "      <td>1.643385</td>\n",
       "      <td>1.662594</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "22       8.469282      0.195784  ...        0.057971                1\n",
       "1        9.409626      0.204258  ...        0.055835                2\n",
       "5        9.036431      0.191749  ...        0.048340                3\n",
       "12       9.415875      0.036277  ...        0.049707                4\n",
       "17       9.014184      0.221012  ...        0.046329                5\n",
       "0        8.490270      0.199394  ...        0.050779                6\n",
       "30       8.639768      0.240894  ...        0.050614                7\n",
       "31       9.149130      0.119742  ...        0.046150                8\n",
       "19       9.387043      0.173035  ...        0.049245                9\n",
       "3        9.231069      0.233167  ...        0.045057               10\n",
       "20       9.392139      0.210024  ...        0.049174               11\n",
       "6       11.429417      0.228543  ...        0.045713               12\n",
       "29      10.090877      0.135116  ...        0.039746               13\n",
       "33      10.084664      0.158211  ...        0.047994               14\n",
       "4       11.541211      0.233475  ...        0.041225               15\n",
       "9        9.544156      0.198668  ...        0.063448               16\n",
       "35       9.685523      0.207372  ...        0.063448               16\n",
       "13       9.443700      0.156064  ...        0.063448               16\n",
       "18      10.937626      0.144047  ...        0.035331               19\n",
       "27      11.084211      0.232608  ...        0.039236               20\n",
       "14      12.033435      0.034099  ...        0.026510               21\n",
       "8       11.856207      0.105376  ...        0.026510               21\n",
       "32      10.503096      0.233200  ...        0.030830               23\n",
       "28      11.416318      0.119541  ...        0.011200               24\n",
       "39       9.424881      1.385099  ...        0.012365               25\n",
       "15      10.841273      0.167346  ...        0.012365               25\n",
       "10      10.524885      0.245417  ...        0.007724               27\n",
       "7       10.462886      0.115238  ...        0.022138               28\n",
       "38      10.497959      0.111965  ...        0.004279               29\n",
       "16      10.750230      0.193769  ...        0.005120               30\n",
       "25      10.402859      0.199935  ...        0.003215               31\n",
       "24      10.446686      0.241512  ...        0.002618               32\n",
       "23      11.073973      0.199038  ...        0.001009               33\n",
       "21       9.271547      0.185027  ...        0.012915               34\n",
       "36       9.472895      0.024136  ...        0.012915               34\n",
       "11      11.858025      0.216007  ...        0.017571               36\n",
       "37      10.952279      0.105356  ...        0.021543               37\n",
       "26      10.776619      0.158400  ...        0.025798               38\n",
       "34      10.905238      0.072094  ...        0.023029               39\n",
       "2       10.333133      0.197664  ...        0.019209               40\n",
       "\n",
       "[40 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(RSC5.cv_results_)\n",
    "df5 = df5.sort_values(by ='rank_test_score')\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rn3Dfh3mJYfk"
   },
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4g &mdash; Compare the success of hyperparameter search [6 marks]*\n",
    "\n",
    "The idea here is to generate a plot that answers the following question:\n",
    "\n",
    "<img src=\"img/tortoise_and_hare.jpg\" style=\"float:right\" width=150/>\n",
    "\n",
    "> If each hyperparameter is chosen sequentially, and takes a certain amount of time to cross-validate, what would be the best score \"so far\" for each classifier at any given point in time? D some classifiers \"win the short race\" but others \"win the long race\", like the Tortoise and the Hare?\n",
    "\n",
    "Use the appropriate entries from the *cv_results_* arrays for each search you did. If you ran your jobs in parallel, then you should still compute cumulative times as if they were run serially. Your plot should look something like the one below, where an example *DecisionTreeClassifier* and *RandomForestClassifier* curve are given as a guide. However, the curves and even the peak scores will vary depending on how you performed your hyperparameter search, so you do not need to reproduce the curves below.\n",
    "\n",
    "<img src=\"img/search-curves-example.png\" width=450/>\n",
    "\n",
    "If you did not complete all of Q4a-Q4f then that is OK, just make a plot showing the classifiers that you did manage to train.\n",
    "\n",
    "**Load your saved search objects from Q4a-Q4f.** This is so that the TA can reproduce your plot without having to wait for your Q4a-Q4f to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "agu6ynC6JYfl"
   },
   "outputs": [],
   "source": [
    "# Your code to load the pre-fitted search objects here\n",
    "decision_tree       = load('a1q4-dtree.joblib')\n",
    "random_forest       = load('a1q4-RandomForest.joblib')\n",
    "logistic_regression = load('a1q4-lr.joblib')\n",
    "Aboost              = load('a1q4-ABoost.joblib')\n",
    "HGboost             = load('a1q4-HGoost.joblib')\n",
    "SVM                 = load('a1q4-SVM.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QfoicthJYfl"
   },
   "source": [
    "**Plot the best cross-validation score found over CPU time.** Use the search objects that you loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "a4pZikHfJYfl",
    "outputId": "97722fee-937c-4a97-80a6-485f82efb0b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your plotting code here, which should use the LOADED search results\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#sorting based on the mean fit time colomn in cv_result_\n",
    "#Decisio Tree\n",
    "df = pd.DataFrame(decision_tree.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df['cum'] = df['mean_fit_time'].cumsum()\n",
    "plt.plot(df['cum'], df['mean_test_score'], label = 'Decision Tree')\n",
    "#Random Forest\n",
    "df1 = pd.DataFrame(random_forest.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df1['cum'] = df1['mean_fit_time'].cumsum()\n",
    "plt.plot(df1['cum'], df1['mean_test_score'], label = 'Random Forest')\n",
    "#Logistic Regression\n",
    "df2 = pd.DataFrame(logistic_regression.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df2['cum'] = df2['mean_fit_time'].cumsum()\n",
    "plt.plot(df2['cum'], df2['mean_test_score'], label = 'Logisitic Regression')\n",
    "#Aboost\n",
    "df3 = pd.DataFrame(Aboost.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df3['cum'] = df3['mean_fit_time'].cumsum()\n",
    "plt.plot(df3['cum'], df3['mean_test_score'], label = 'AdaBoost')\n",
    "#HGboost\n",
    "df4 = pd.DataFrame(HGboost.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df4['cum'] = df4['mean_fit_time'].cumsum()\n",
    "plt.plot(df4['cum'], df4['mean_test_score'], label = 'HGboost')\n",
    "#SVM\n",
    "df5 = pd.DataFrame(SVM.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']].sort_values(by ='rank_test_score', ascending=False)\n",
    "df5['cum'] = df5['mean_fit_time'].cumsum()\n",
    "plt.plot(df5['cum'], df5['mean_test_score'], label = 'HGboost')\n",
    "\n",
    "\n",
    "plt.ylabel('Compression Ratio')\n",
    "plt.xlabel('Second')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI_Z8f3rJYfm"
   },
   "source": [
    "**Question.** Based on *YOUR* plot:\n",
    "* If the \"short race\" was a 5 minute compute budget, which classifier(s) would win?\n",
    "* If the \"long race\" was the longest budget you trained for, which classifier(s) would win?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTQWIKKUJYfn"
   },
   "source": [
    "For a short race random forest.\n",
    "For a long race logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxpJBgmtJYfn"
   },
   "source": [
    "**Print the compression ratios on training and testing data.** Use the pipeline that had best cross-validation compression ratio for each type of classifier. Also print the total time it took to score each pipeline. Your output should look something like this:\n",
    "```\n",
    "dummy: trn=?.???? tst=?.???? time=?.??? sec\n",
    "dtree: trn=?.???? tst=?.???? time=?.??? sec\n",
    "rf:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "lr:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "ab:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "hgb:   trn=?.???? tst=?.???? time=?.??? sec\n",
    "svm:   trn=?.???? tst=?.???? time=?.??? sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c5TAhJJmQe5",
    "outputId": "1f12fe88-82d4-42ac-8453-7069b71899cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\x7fm~4\\x03\\x15+\\x13\\xafLl\\xd2\\x94h\\x8bJ\\xbd\\xd8\\xa3\\x04\\x89\\xf1\\xbb\\x80D\\x85)\\xc5B\\xf3\\xd8$E\\x82\\x13\\xc8\\xe0\\xea\\xab{\\xc4\\xed\\x97\\x88\\x04\\xa8Y\\xbe\\x15\\xd3n\\t\\xf3t\\xf1\\xd8\\x1eVf\\xec\\xafab\\xa1\\x9bEU\\xe1P\\x0c-E\\xda\\xf0\\xc8\\x19\\x1a\\xe6\\xd8L\\xd66\\xbb \\xd9\\xf79-R\\x9f\\xb3\\x84\\xb9\\xc0\\xbd\\xb6-\\xff\\x95g\\xef\\xde?\\xeeq`GL\\'\\xa6;\\x05\\xf4mM*\\x15=\\x91\\x94\\xff*\\x06\\xde\\xcbSed\\xb1vp\\x96\\xdb^\\x0c\\xdf\\xab\\xe2}\\x04-8\\xeb\\xc5R\\xee\\xc5\\n6\\x0f\\x90\\xdb\\xb0\\t\\xabR\\xa9\\xd8\\x95x\\xacM\\xd6\\x1dS\\xd8W\\xa4\\xfb`\\xb1\\xd9\\xcb8\\xc9\\x1a\\xbeT!;~X.(\\xce\\x99\\xc8\\xe0\\xc4\\xac\\xb2f\\xb1J\\xb3,\\x18O\\xce\\x9e^zU\\x0cT?\\x11\\xb8\\xa8f\\xad\\xee\\xcb\\xd9g\\x88,T,O+,\\xa6\\xed\\xa1TVL\\x8e\\x13\\xbc\\xeb\\xe2D\\xb6\\xd4\\xd5\\x94\\x90\\xa7\\xed\\xccv\\xe1\\xc2\\xc6\\xd4\\x0c\\xb1\\xb4q\\xc382\\xa4kR\\xaa\\xde\\'\\x81j8L\\x07\\xa0ks\\x1cH\\xe9h\\xaaFI\\xbd\\x81S\\xc85\\x1c[\\x00X\\x8b\\xb13\\xaf\\x06p\\xaa\\xff:e\\x16<u\\x9fcs\\x83\\x17b\\x91\\xd4\\xb7\\x10$\\xe1Li\\xc0\\xb5\\x9c\\xb3\\x8c\\xbd\\x17\\xe5&!\\xe11\\xc5\\x85\"\\xc4\\xb3#\\x0c{F\\xd8t\\tbv\\xf9\\xbaS\\x87\\x82sn4\\xbe\\t\\x83\\x95[\\x8e\\xc9b\\xd6N\\xa3j\\x86B/@\\xe8\\xe2a`\\x99\\n\\xee\\xca\\x91\\xd4\\x91\\xae\\xdc\\xc7j:X\\x95H\\xc3\\t\\xacJ\\xba,\\xd2\\x9eEr)\\xec\\x96\\x08\\xb9\\xd3\\xb0\\x1d\\xfa\\xeb\\r\\x81?k\\xe5Ai\\xe1\\xb3\\xca3#\\xe6\\xd8 xLS\\xb8S,K00D\\xe7M`\\xb9\\r\\xcfds\\x84\\xfc1J\\xde\\x8aMl\\xe0\\xca\\x91\\xc2\\x95\\xc9{k\\xf7\\xf7\\xbb\\xfe\\xcb\\xe9\\xc2\\x897\\xed\\x8a\\x96\\xf5\\x18\\x15,B\\xce\\xc8\\x91\\xb2\\x8a\\xbej\\xb3y\\xbdhU}\\xc6r8Y\\x92:,\\xab\\x18\\xda\\x95r\\x10E_ol\\xd6\\x9c*\\x9b7\\xd9q\\x80a\\xf7\\xa7\\xd8\\xb2Q\\xa1^\\xf6\\xfb4\\xe8d\\xa1\\xce\\x10K\\xe7B\\x8f2\\xf0N\\x87\\x8aU\\xbb&xU\\x1c\\xb6\\x08\\xbb\\x139\\xb6\\x1e \\x92\\xa5f\\xd6\\x93\\xc7f\\xed\\x17\\xddl\\xba\\xe4\\xec.W\\xb7\\xfb\\xf7\\xeft\\x98\\x88\\x12\\xe1\\x92\\xf7\\x0cR\\xbeLO\\xb0\\xcd\\xd4\\xc1\\xf6]\\xe8\\x89\\x99\\x1215\\xc4\\xc2\\x1e\\x8as\\xcc\\x8d\\xba\\x16\\xaf\\x87g\\xe7\\xa5\\x96\\x14\\xe6\\xb555j\\xba\\x98?QfDq\\xba\\xcd\\xbc*\\xe7`\\xfeb8\\\\1J\\xf5\\xaa\\x8e\\t\\xcfV\\xab\\x9d\\x83\\xe8\\xb2\\xf5\\x91\\xc7\\x82\\xbd\\xe1\\x9b\\xa9\\x83\\xf5\\x8f7L\\xd1\\'\\xa2\\x9b\\x86)^s\\xc3fd\\xd5 \\xc2\\xd2\\xb3\\xc37Q\\x0f\\xc43\\x8b\\xeb\\xca\\xb9\\x8a\\xe1\\x87W\\xa4\\xeb)\\x98\\xaa)\\x91\\xad+2O\\x049Vp\\xf0\\xcdM\\x10\\xfb\\xa7\\x82\\x1bZ\\xc1,\\x86\\xd6\\xa6#\\x16\\x00)\\x8c\\xefu\\xf1L\\xfe\\xab\\x98\\x1e!:dp\\xa0\\x99P@\\xf0\\xab\\xa9\\x83\\xee\\x941\\x95\\x04\\'\\xd1\\x05\\x8a\\x86iu\\xf1L\\xfeEd-\\x0f\\xb9\\xba\\x98\\xde\\xc6{P\\xba\\xf8\\xa6z\\xaeH\\xce\\x16nFb\\xce\\x05#\\x85+\\xd6\\xab\\x9d\\x83\\xef\\xa9\\x1ec\\xa4\\xb3S\\x99%\\xef\\n\\xba\\x88{\\x94$\\xac*\\xda]|S;\\xa4E\\x85,W!\\r\\xceN8R\\x89\\xabUM0~&\\xa5Y\\xee\\x1b\\r\\x9c\\xa6\\x84\\xb6\\xb0\\xa3w\\xbd\\xe7 \\xd1\\xe7\\x80O\\x10>\\x95[=\\x1c\\xd8\\x15\\x81i\\x92\\xd7\\xb0\\xaa\\xb9\\xb6\\xf9\\'\\x16d\\xf2n\\xff\\xef\\xcc*\\xb9\\xc1\\xf2O+\\x03f\\xbe\\xae\\xc8\\x8ac en]\\x81U\\xcd\\xb7\\xdb<\\xb3\\'\\x99$g1\\xdb\\x96\\xben\\xd3\\xb5\\x7f\\xfe\\xc1\\x7fG+B[;V\\x15[8\\x0e\\x8c\\x0b2\\xb5\\xe2M{\\xcd\\xdf\\xed\\xff\\xff\\xe2P@\\xf3Cl\\x8c\\xad\\x961D\\xb5m\\xb0*\\xb9\\xb6:O,\\xcb\\xcf*\\xd6\\x87\\xd8\\xdd\\xa0r\\x86eD\\x85)\\xad\\xe0\\x04e\\x8em\\xca\\x9a\\xf7~\\xf3w\\xee\\xc1\\x7fWd\\xa1-\\x9d\\xac\\xca\\xab\\x9c\\x07F%a<\\xf3X\\xae\\xf7\\xb8\\xa8]\\x93\\x91\\x1b\\x93\\x88d\\xf7Q=\\xb6k\\xec\\xda6p\\x1d\\x18\\x15\\x81\\x91!\\'\\x10\\xc9\\xec\\xa2M\\xdf\\xff}\\xfb\\xf1(!^h\\n\\xc8\\xca\\xd9&)\\x8bV\\xd7\\xadH&\\xee(\\xe5\\x98\\xf6\\x16*\\x16nq\\xa1\\xf6\\xc4\\xcc\\xbe\\xb6]\\x05R\\xf5\\x8f6\\x03\\x1bE\\xf5\\xfd\\xff\\xff\\xfb\\xff\\xef\\xff\\xfb\\xbf\\xff\\xff\\xf6\\xd2[2\\xaaB\\x9a\\x9a$\\xe5#\\x97\\xb4\\xa2\\x95\\xb6)E\\'\\x8f\\xef\\xbf\\xff\\xf7w\\xff\\xff\\xff\\xfd\\xff\\xfe\\xa2\\xfbV\\x15\\x178\\x0e\\x93\\xca\\xc2\\xc8\\x90\\x13\\x81G{\\rb\\xfb\\'\"BN!\\x93\\xd8j\\xf2\\xd5\\xff\\xdd\\xc0\\x1cx\\xa6\\xe9QsltbV\\x15\\xef\\xb3\\xe6$MQ\\x93\\x1cXp\\x90Y\\x81\\x92e\\xd7s\\x028\\xddaZ\\xcbQ\\x93\\x1cXt\\xb0*\\x81\\x862\\xe2\\xef\\xfe\\xdf\\xfd\\xbf\\xdf\\xfe\\xee\\xfd\\xbf\\xff\\xfb\\xff\\xff\\xdfk.\\xa2\\xcc\\xb2\\xe2\\xfe[9Y\\x18\\x0es\\x1c\\x0fS_.T\\x8e\\xa4\\x8fSW\\xff\\xff\\xbfw\\xef\\xdf\\xf7\\xef\\xff\\xee\\xef\\xff}\\xf7\\xbdZ\\xf8,,\\xcbM\\x1e\\xa6\\xbb\\xd4\\x0b\\r\\x84\\xf9v\\x9eZ\\x9b\\xbf\\xdf\\xed\\xb6\\xd7\\xef[\\xc4\\x16(Vl&)\\x0c:X\\x96`a\\x8c\\xb3\\xba)\\x06\\x16\\x080#\\x83\\xab\\xb0\\xaf^\\x98\\xcf\\xd1}\\x16\\xd6Y\\x84\\xe7\\x1b\\xb3\\x0c\\x97\\xbf\\xff\\xe4W\\xb3\\x0c\"\\xce\\xac\\xa7\\x9c\\xa7P\\x9b\\xec\\x82\\xafy\\xa2\\xaf\\x7f\\xbf^\\xb1\\x9aBQ\\xe9%\\xf7\\xefU\\xa5UU]UV\\xaf\\xbf}EP\\xba\\x87M\\xc5\\xff\\xff\\xef\\xe3\\x16\\xcb\\xe8\\xb3-\\xd0\\xe6\\xd9v\\xe6;p\\xe1bU\\x03\\x0c+\\xe6\\x9b\\x8c\\xb9\\xb6#\\xe2\\xdb\\x03\\x15+<h\\xb5\\x1b\\xe2\\xbf\\xffww\\xb71Ia\\xd2\\xc0\\xb3#\\xd4\\xdc\\xad8z\\x8b2\\xd7\\xe3o\\xfeq\\xa6\\xf8I\\x99sl\\xbc\\x8c\\xf1\\tF`\\x9d\\x02\\xc5\\xf2\\r\\xdcU+\\xff\\xbf\\xff\\xd0,]Q\\xb1\\xd8\\xa4zI{\\xff\\xbd\\x98\\xac\\x8c\\x079\\x8e\\x0f7\\xd3q}\\xff\\xff\\xf4c\\x02\\xe71\\xdb\\xb4^\\xe7\\x02\\xed\\xccv\\xe1\\xc2M\\xa8\\x18c\\'\\x89\\x99\\xe3\\x05S\\xb2c^\\x95\\xcef\\xbf\\xacy\\x82Bw\\xf7\\xfb\\xf7\\xed\\xfbs\\x1d\\xb8\\xd9`Y\\x81\\x86\\x13\\xcb\\x01\\xd27:\\x88a>K\\xdf\\xfd\\xecR:\\xce\\x9dC\\xbaKc\\xd1~\\x16RF\\x9b\\x12M{!\\xe8\\x9d\\xf8@l\\x89\\xfd\\xf7\\xff\\xbf\\xf8\\x9e\\x05\\xb9\\xd3(1\\xe5R\\xf1\\xb9Hc\\xca\\x91\\xd4\\xbd)\\xcd\\xb0\\xeae\\x89f\\x06\\x18W\\xa8\\xd0\\xf5\\x1c,\\xdc\\xc2\\x86\\x91#\\xdd\\xad\\xde\\xe9C\\x17\\xff\\xff\\xbb\\xdc\\x1d\\xee[,bS>V\\x9b{Q\\xca\\xc2\\xa8T\\xd3\\x90\\x98o\\xe7\\xb3;\\x01\\xad\\xc1\\x9e\\xd7w3\\x0cTQ\\xad\\xa1d\\xc5z\\x8c^\\xff\\xff\\xff\\xe7\\x02\\xd4<B\\xbb\\xb6\\xd5\\xe06\\x13\\xbf\\xf0N\\xe1\"\\x14\\xfa$\\xec::\\x92E\\xdc\\xe0\\x1e\\x13\\x1cH\\xe9bY\\x81\\x92e\\xeff,\\xe3+\\xef\\xff\\xef\\xf3\\x8a\\xb5\\xa1\\xf9\\x06\\xce\\xdc\\xa8\\xd8N\\xad\\xef\\xff\\xf4\\x1c\\xac,\\xf6\\xa6\\x9eo\\xadC\\x8b\\xf3\\xea\\xf2\\x8f3\\x8a{\\xdf\\xff\\xbb\\xf7\\x8ca\\xbe\\xb1\\xe7\"\\xc7pp\\xb0+\\xb43\\xf4\\x0em\\x96\\xc2c\\x83],\\n\\xa1\\x19c\\xb3\\x16q\\x96M\\x89\\x80%\\x1d\\x86\\x9c\\xe9\\xde\\xed_\\xdf\\xff\\xfe\\xe57\\x06!\\xd8\\xa60H\\xeaP\\x92\\xe6\\xed\\x17I\\xe5d\\xb1\\xdb\\x98\\xe0\\xc2\\x99bY\\x91\\x86\\x15\\xf5\\x1c\\xac\\x0c\\xcbM<W{_\\xff\\xbf\\xff>\\xa6\\t\\x1dJ\\x92s\\xa7\\x17\\x84\\xc7\\x16\\xa9\\xdcK20O\\x94\\xda\\xcc7\\xb0>\\xcc\\x98:a\\xa6r\\xb22\\x9d\\xab\\xfd\\xfb\\xf7y\\xc7;~H\\xd7,\\x8d\\xe4\\x8b\\xf2\\xa4\\x12\\x87\\x8a9f>aU\\xce\\n\\xa4\\xf2\\xb0\\x93%\\xef\\xef\\xfa\\xeb\\r\\x94\\xfeoX\\xa6\\xd8\\xd7\\x9c\\x80Q\\xd8qL\\x8b\\xb4\\xaf\\xbf\\xff\\xbf\\xb2\\xd0\\xd3l\\xb1\\xe3\\x80vr\\xb20\\xf4_\\xec \\x9e\\x13\\x1c\\x18t\\x90Y\\x81\\xee>\\xa6\\x82\\xc3a<_\\x86B\\xc9\\x17\\xacJ\\xb5\\xa1\\xf6\\n\\xff\\xfd\\xbf\\xfd\\x88\\n\\xab\\xec\\xfex\\xf0\\xb5\\x1b\\xed\\xccpaH\\x92Y\\x81\\x969\\xedaU\\xf2u\\x18\\x17di@\\xeb\\'t\\x91\\x08\\x9a\\xe7\\x00\\xef\\xc2\\x03`O\\xfa\\xc9\\x7f\\xbb\\xf7\\xfd \\xc2\\xcc\\xc8\\xbb\\x12B\\x9f\\xd2\\xbam\\x87^\\x0c\\xc2\\xbeT\\x8e\\xa4\\x99/\\x7f\\xff\\xb6Cr\\xab\\xac\\xd4\\xbe\\xee\\xea\\xaa\\xaa\\xd3J\\xb4\\xd5\\xf7\\xff\\x15\\x12D\\x9a\\xbe)\\x9fH\\x8b\\nX\\xaa\\xab\\xca4HJ\\x83\\xa9\\xc5\\x18\\x04L\\x91\\x05\\x8a\\x95\\x87\\xe1WS\\x07\\xafE(\\x87*\\x98\\xd0,T3\\xbf\\xdd\\xf1$TI\\xab\\xe2\\x95\\xd4\\xb32\\xdcW$\\xf21 \\x1axf\\xa5\\xd8?\\x9c\\xa2\\x01\\xf0b\\x00Y\\x8a\\x8f{\\xef\\xfb\\xb1$W\\x0cS>\\x91\\x16\\x14\\x92\\x99\\x17\\x94h\\x90\\x15\\x1f;\\x0e`\\x13z\\xd5u0~iJ4HJ\\xb1/\\x14\\x9c\\x91\\x06\\x00_\\x00\\x89L_\\xff\\xe2H\\x92$\\xeb\\xe2\\x99\\xee\\xc4XB\\xc52/(\\xd1\\x16\\x95\\x1f;\\x14`\\x112D\\x164\\xacO\\x0c\\xdc\\xed=\\x9aS\\x1cXt\\xb1*\\x81\\xee/\\xff\\xf1$I\\x12vK^g\\x8a\\xdc\\xe5\\x10C\\xaf\\x85\\x82|\\xc5W\\xa7j\\xaf\\x92Y\\xa9\\xcc\\x12j0\\x8c\\x83^\\x8e\\x82lS\\xd9\\xaf\\x81T\\xa9\\x98\\xe8z{\\x14\\xf6y}\\xdf\\xe2\\xa2H\\x93b\\x0b\\x14\\x0b<W\\x89\\xa9D9T\\xc6\\x81b\\xa5\\x9d\\xa9\\xe9S9T\\xc7g,\\xe3(\\xa7\\xb6G\\xb3W\\xdf\\xfeL\\x99>\\xff>\\xd5\\x0cU1\\xd9\\xca\\xc8\\xc1\\xf4\\x9d\\x1e\\xce\\x93[Ol\\x8ff\\xbb\\xd9\\xed\\x91\\xec\\xf1\\xe5\\xef\\xef\\xfb,\\x1d\\x89V\\xe2\\x9erD\\xe1)\\xdb\\xf0\\x98\\xe0\\xc3\\x85\\x81f\\x06\\x18\\x9b\\xdb\\xfd\\xfe*$\\x89:\\xf4\\xc7\\x84\\xc7\\x16\\x1d,\\x0b00\\xdb\\xc2\\xbe \\xb1P\\xcf$&8\\xb0\\xe1`Y\\x81\\x96\\x12n\\xfe\\xfb\\xd5\\xc9\\x93\\xfd\\xee\\xd8T\\xed71Ia\\xc2\\xc4\\xb3#\\x0c<\\xbf\\xff\\xa8\\xc9\\x8aw\\x0e\\x16%\\x99\\x19b\\xd5%P\\x8a\\xcbb\\x95C\\x15Lvb\\xb20\\xcbk\\xb3\\x15\\x91\\x93\\xe3\\x98\\xa4&\\xafUc\\xcc1\\x06\\x1e\\xa6\\xaf\\xfe\\xf6)\\x1dgH\\xa9c\\x02\\x99hd2\\xefmk\\xbd\\xd9\\x05TE\\x11\\xe4_\\xa8\\xe5af\\x153\\x9a\\xbd\\xe2\\xf8@l\\n)\\xe9\\x0b4\\x0bW\\xbf\\xdf\\xe2\\xa2H\\x93\\xbaZ*\\xa7\\x8a\\xd8\\x82\\xc5B\\xc5W\\x03|\\xe1csKO/\\xf6\\xfb\\x12ED\\x9a\\x14\\xc6\\xd8\\x13:\\xdb\\xd2\\x980\\x9e\\xd3\\xa5\\xa2\\xcd\\x1eM\\xeb\\xb0\\xb5O-w\\xef^ &D\\xaf7\\xde\\xbb\\x85\\x89U\\x14{\\n`\\xd6%?y{\\xff\\xb3\\xd2\\xbar\\xa9\\x8e\\xceVF]C\\xbd\\xf22\\x17\\xffu\\x8d\\xa2h\\xaac\\xb3\\x95\\x91\\x93\\xe9R:\\xce\\x9dC\\xe5\\xb2\\x19\\x1e\\xcdw\\xb3\\xdb#\\xd9\\xe5\\xff\\xfd\\xfb\\xf7\\xf7\\xbe\\xdf\\xfb~\\xcb\\xee%\\x95\\xea,\\xcas\\x8d\\xd9\\x87\\x82ve\\x89\\x9e\\xa1\\x9b\\xb13@\\x02\\x0c@\\xaa~G\\xe0}\\xdb>\\xa7\\x8e\\x05\\xe4g\\x85\\xa5\\xa6I}\\xff\\xdb\\xf8W\\x8b\\xa1\\xe29\\xcfN\\x9d\\xb2?\\x88O\\xb4\\x0ep\\xdd\\x1cr\\x83\\x068\\xfe\\x8b\\xf9\\x19\\xec%\\x19\\x92xW\\xa9\\x96\\rf#\\xb0I\\xe0w\\xff\\xfb}\\'\\x12z\\xd0\\xf6z)\\x99\\xce\\x05\\xa8x\\x85W\\xeb\\xd3\\x1c\\xdb\\x0f`LOM\\xe5\\xb3\\xc3\\xc2\\xa8r\\xac\\xe5\\x92\\xfe\\xff\\xdb\\xeb\\xd13g,,\\xcdj\\xaf\\xa2\\xf5\\xda\\x84\\xe7\\x1b\\xb3\\x0f=\\x82D\\xebF\\x87\\xa7MZ\\x87\\x87\\x14s\\x876\\xc3G}\\n\\xe9\\x8e\\xfbj\\x07\\n\\x17\\xca+\\xff\\xba\\xff\\xe5R;\\n\\xf2\\xb1)\\xf0\\x10\\xae\\xe2\\x85\\x1b\\x05\\xcd\\xb2\\xe3\\xbe\\x9df\\r\\xf0\\xfd\\xd5\\xe6\\xd8l*g*\\xce\\x19;\\xd13\\x9e\\xd9\\x9a\\xd5o\\x9be\\x7f\\xff\\xb7\\xf1.a\\xb7Jj\\xd52\\xd7 \\x19c\\x9c$|\\xe0\\xb2t\\x8d\\x86,\\x12\\'\\x8d\\x00\\xfa\\x18\\x8e\\x13\\xf1\\xc7K\\x1ch\\xf8}\\x85\\x10\\xc2E\\xe8\\x17\\xfe\\xfe\\xdfJe%\\x9c\\x18\\xe23\\xc2\\xd2\\x8c\\xc1\\x15\\xd7\\xa5\\x1e\\r\\xb0\\xc5]\\x82\\xf9Ey\\xe9G\\xa8\\xf6\\x80\\x05\\xa2\\xac\\xcf\"\\x9e\\x06\\xb5+,\\xfaYC\\xebW\\x9be\\x7f\\xfe\\xbf\\xd4\\x8d\\x89\\xec\\x12&\\xa57(\\xba\\x11\\xf1\\xc7L\\xe8h>\\xf3v\\x9c\\x03\\x86n9\\x9c\\xe3u\\x85\\x92\\xffo\\xc7\\x1d,q\\xa3\\xe1\\xfcW\\xcb\\xb5{\\xef\\xfc\\x884q\\xeaYC\\x8fj{\\x11\\xafQfQ}\\x98\\xb3\\x8c\\x1f\\x1c\\xc5 \\xd6\\xb1H\\xeb:5\\xb5|V\\x16aS\\xd8\\xa7\\xb3\\\\\\x16\\x1b\"\\x8a\\x9at\\xa8<P\\xbf\\xdf\\xf7\\xff\\xa1\\xe9C\\xeb$*\\x87*NV\\x98\\xa4u$k\\xa1\\xa3\\xce\\xecv)\\x1dK\\x7f\\x9a\\xfbh@l\\x8a\\xdb7}\\xdd\\xfb\\xf7\\xff\\xfb\\x14\\x8e\\x84\\x9e+\\xd5\\xd9$vl\\x90\\xc7{\\x95\\xa6\\x1d\\x1dI-_\\xfd\\xfb\\xef\\xff\\xfe\\x0b\\xfa\\x8e\\x16\\x05B\\x9a\\x9e+\\xbd\\xf7\\xf7\\xfd\\x9e\\xb0t\\xc3L\\xc5de?t\\xb1,\\xc8\\xc1/\\xff\\xff\\xef\\xff\\xff\\xbbx\\x07b\\x91\\xd0\\x93\"BN\\x05\\x1d\\xec5\\xf1Q]\\xed7\\x7f\\xff\\xfe\\xff\\xfd\\xff\\xff\\xbf\\xf6)\\x1dgO\\x15\\xea\\xec\\x98\\'\\x10\\x8f-\\x8aGI\\xd1\\xafQ\\xca\\xc0\\xa8T\\xd2/\\xbd\\x9e_\\xff\\xfe\\xff\\xf7wo\\xf9g\\x05\\xfb\\x14\\x8e\\xb3\\xa6DlN%\\x1d\\xec5\\xf6\\xd8\\xafW\\xc1aT(i7\\x7f\\xbb\\x7f\\xf7\\xff\\xff\\xdd\\xff\\xff\\x89A\\x03\\xcd\\tY\\x1e\\xdb,%1\\x96\\xfd\\xe8\\xa4u\\x9d=+\\xd4T\\xe8\\xdd#\\xcc\\xb6\\x02f\\x1c m\\xee;\\xdf]\\x8e\\xfe\\xff\\xff\\xf6\\xff\\xef\\xff\\xee\\xff\\xfe\\xff\\xbf\\xff\\xff\\xdf\\xff\\xef\\xe6\\x89\\xbc\\xa1\\x98U\\x16u\\x11_4\\xa0\\xcc+\\xf7\\x05\\xd4Y\\xdf\\xef\\xff\\xff\\xff\\xdf\\xbf\\x7f\\xf7\\xff\\xdf\\xfd\\xfb\\x7f\\xff\\xffw\\xcd\\x13\\xda\\xac\\xb3(\\xbfQ\\xca\\xc2\\xcfji\\x17\\xd8\\xa4u$\\xc8\\x8d\\xc9\\xc02{\\r^<\\xbd\\xef\\xff\\xff\\xf8/\\xc1a\\xb0.\\xb1\\xf9\\xa7J\\x12\\x85\\xff\\xdf\\xff\\xff\\xfe\\x0b\\r\\xec\\xfek\\xd6\\xd8U\\x0cT`\\xb2\\xe4\\xe8\\xeaI\\x17\\xd0\\xf0\\xf3\\x8a\\xa5\\xe5H\\xe9:y\\xacW\\xb6\\xaf\\x01\\xb2\\'\\xf7\\xfb\\xff\\xff\\xa0\\x1cx\\xae\\xa4n\\x0cZ\\x9aS\\x1c\\x18t\\xb1,\\xc8\\xcb\\rv,G\\x99\\x1f>\\xa9e>\\x1f.\\xff\\xff\\xff\\xbe\\xff\\xe7\\xb1\\x1a\\xf5\\x96`\\xd7g+#!\\xcec\\x89\\xae\\xc5#\\xac\\xe8\\xd7\\xab\\xe2\\xb0\\xaaU4k\\xaf\\xa3e;\\xcd\\xbf\\xdf\\xb6\\xfcc\\x08\\'Y>b\\x85s\\x99\\xa2\\xe6Hp\\xaa\\xfe3\\x85\\x909\\x9c\\xe9\\xe7\\x80Of\\x9bzzyT\\xd6\\xe680\\xe1`Y\\xe9\\x96\\x12\\xfb\\xff\\xb7\\xe2\\xc0i)\\x8eVd\\xbe\\xff\\xe7\\x05\\xf4q\\xc9H\\xe3\\xdaM\\xb0\"\\xfd\\r\\xb2\\xc3\\xc9\\xbb\\xed\\xef\\xff\\xdf\\x828\\xf1_\\x96\\x85\\x9a\\xea\\xd6U+\\xc5E}8\\x062VY\\x97\\x95\\'\\xbf\\xff\\xff\\xff\\xff\\xfd\\xfa\\x85b\\xf9\\x19\\x8a\\xc8\\xc0s\\x98\\xe0\\xf1Q^\\x86\\xde\\xa6Fb\\xce0\\x1c\\xe6il\\xa8W\\xff\\x7f\\xdd\\xff\\xff\\xfe\\xfa\\xbb$\\xac\\xcf-\\x030\\xc9*G]O\\x15\\x15\\xe8{\\xb8\\xc9\\'GRK^U\\x9e\\xfb\\xff\\xff\\x7f\\xff\\x7f\\xfd\\x02\\xc0\\xc9W\\xc5\\x98f\\x154\\xf3X\\xad\\xa1\\xc01\\x92\\xa3\\x85\\x85R\\xa9\\xa7\\x95g\\xbf\\xff\\xff\\xfe\\xff\\xff\\xfa\\x81`*\\x10\\x1b)\\xfcT\\xd7hm\\xee\\x15]a\\xb2\\'\\x97\\xbd\\xe7\\xceF\\x9e\\xd8\\xa0\\xda\\x16v\\xb3#\\x94\\xf6j$\\xd5\\x97z\\x1e\\x8bfG\\'\\x9b}\\xff_\\xbf~\\xcb\\xcbw\\xb1d\\x915zcEe\\x9e \\xb1R\\xcd2^\\xff\\xee\\xaa\\xaffX5\\xa9Q\\x14\\xe0Sj\\x17d2=\\xa6\\x8a\\xbe\\xef\\xd7\\xef\\xdf\\xde\\xff\\xdf\\x90\\x06\\xae\\x07\\xae\\x16\\x05\\x9aZB\\xb1v\\xbc\\xe4N\\x9a\\x8cq\\x19<\\x9b\\xbf\\xff\\xff\\xf5\\xfd\\xb5\\xfb\\xd2\\x03\\xee\\x16%\\x98\\x1e\\xe1=\\x17\\xd3md\\xf1\\x05\\x8a\\x85\\x99/\\x7f\\xf7\\xfd\\xfe\\xd8K\\x12\\xcfL0\\x97\\xdd\\xdf\\xff\\xed4\\xabM4\\xaa\\xad+\\x7f\\xff\\xff\\xf2\"wP\\xd6\\x1dL\\xda\\xe4@(\\xec8\\xa1\\x8e#+\\xff\\xf7\\xff\\xbf\\xfe\\xa3C\\x8cq\\x185\\xf2\\xa1e\\x9f\\x04q\\xe2\\x9am\\x86\\xbaX\\x16`a\\x84\\xeb\\xd3\\x1c\\xdb\\x82rC\\x86b:ceY\\xef\\xef\\xff\\xfb{\\xef\\xf3\\xd2\\x86(T\\x8b\\xa4r\\xa4\\x96\\x06\\r4\\xe0#\\xf2\\xc0}C\\xdc\\xe5\\x1d0\\x99/\\x7f\\xff\\xff\\xf1\\xa7N4\\xaa_\\xff\\xf7\\x7fiV\\x95U\\xa6\\xaf\\xff\\xdf\\xbf],mS\\xcd\\xf9\\xe19\\xdf\\xff\\xef\\xff\\xfb\\xfcK\\x96%R0\\xc6\\xd6U$\\xf5\\x93\\x9c\\x13\\xf3\\xa78\\x141\\xd9\\xca\\xc8\\xc8\\xf2_\\x7f\\xffw\\xdbm\\xaf\\xef\\xff\\xff}\\xdd,\\x0b4\\xf1^x0v\\x9e^\\xff\\xef\\xff\\xf7\\xfa\\xb5\\x0f\\x1a\\x8e\\t\\xcf\\x9be\\xb3\\xd2\\xa8x\\x8d\\x88\\xe9\\x8f,/\\x1eaSNt\\xe0\\xb5g\\xe6\\xd9z\\xd2}\\xb3\\xbaX\\x96za\\x84\\xbf\\xffw\\xffo\\xce\\x97\\xc0)\\xc6\\xa1T\\xef\\xfe\\xef\\xff\\xcf\\x9ax\\xaee\\x98d\\x1cv3\\x91\\xa3\\xe1\\xef\\xbf\\xff\\xfd\\xd6\\xac\\x0f\\xc5j\\xe4b3\\xc5\\xa9\\xec\\xdc\\x8f\\x87\\x85`c\\xbek\\xe5\\xce\\x0e\\xc1N#\\x02}LAu\\xaa,\\xde\\xa6\\xb6{\\x13 \\xef\\xa1X\\x18\\xfbj\\xfb\\xbf\\xee\\xff\\n\\xc0\\xdf\\x1c\\x1b\\xae\\xc5t\\x82\\xfb#\\x8f\\x1b\\x97\\n\\xc0\\xde_\\xfd\\xff\\xfe,6\\x91}\\x9c\\xb1,.\\x9ek\\xd4q\\xac_Q\\xc6\\xb7\\xff\\x7f\\xff\\x851\\xdd,KH\\xc3\\x1e\\x14\\xf0\\xa4#\\x1d5z\\xe4p\\xb1,\\xf4\\xcb\\x08\\xab9Y\\x19&]\\xa5\\x0b\\xff\\xf7v\\xff\\xfd\\xf0\\xdfi\\xd2\\xc0\\xaa\\x06\\x18V!j\\x96\\xf8\\xae\\xa4X\\x96de\\x85f\\x83.0\\x0e4-\\x90\\xd1\\xcd\\x0ba\\xa3\\x0fEY\\xef\\xbf\\xff\\xbf\\xff\\xbf\\xef\\xf7\\xff\\xbbp,\\xc0\\xcb\\x19(,\\xcb\\xdbf\\xbf/B\\xc0z\\x9eM\\xdf\\xff\\xff\\xdf\\x7f\\xff\\xdf\\xe4\\x8b\\xa6I9\\xc1R\\xb4\\xe1 \\xb3#\\x0cd\\xac\\xb3\\x07\\x97\\xffo\\xb7\\xff\\xff\\xe0\\x1a\\xa6Z*\\x91\\x962DB\\x85\\xe2\\xa2\\xbb\\x85\\x89f\\x06I\\x92h2\\xe3\\x06\\xc4\\xb9\\xa7\\x13\\xa8\\xc1\\x8a\\x8d\\xb6\\x13M\\x97\\xb6sw\\xfb\\xfd\\xff\\xff\\xfb\\xfd\\xfd\\x98\\xb1,.\\x99$\\xed\\n\\xcfi\\xc2\\xc0\\xaa\\x06X\\xc9IT\\xad^\\xff\\xee\\xff\\xfc\\x03\\xd8U\\xb4\\xccX\\x16\\x177\\x9e\\xdb\\x15\\xac\\x82\\x85\\xf7\\xff\\xfd\\xff\\xdf\\xb8\\x94\\x108\\xc1\\x1e\\x9c3+e\\x84\\xa2Z~\\x93\\xc2\\xc8\\x1bV\\x14\\xb1]\\x88\\xdchf\\x9d\\x1btv\\x17\\x95\\x99B\\x98\\x9a\\xfe\\xff~\\xff\\xf7\\xfd\\xdd\\xbf\\xff\\xff\\xff\\xfb\\xef\\xfe\\xfbj8\\xa7\\x80L\\xd3l \\x9d\\xd2AfFH\\x9dj\\xf8\\xe0]\\x16^\\xa28\\xf0O\\xef\\xf7\\x7f\\xff\\xdf\\xff\\xff\\xffw\\xee\\xff\\xf7\\xfd\\xfd\\xff\\xa0sl!\\x8e;\\xe8R\\x068\\xfe\\xd5i\\xac\\xc5\\x89aty\\x92\\xdb}\\xff\\xdf\\xff\\xff\\xfe\\xfb\\xbf\\xff\\xbf\\xfd\\xdf\\xff\\xef\\xfa\\x8a\\x9ez\\x02S,\\xf8R\\xcb)\\x95\\xce\\x10O=(\\xcc\\xaak:\\x8a\\xbf\\xbf\\xdf\\xbf\\xff\\xbf\\xff\\xff\\xdd\\xff\\xff\\xfe\\xee\\xef\\xd5\\x17\\xdacQ\\xab\\xday}\\xff\\xff\\xfa\\xee\\xc7\\x96\\x17\\xf0\\xae\\x8b\\x0b\\xa2\\x85\\xff\\xff\\xef\\xff\\xfe\\xe1bY\\xa2\\x8e,.\\xa2y\\xae\\xaeG#<e\\xa6\\xd8\\x11|X]\\xe5\\xef\\xff\\xff\\xfe\\x84q\\xe2\\xbd\\xc2\\xc0\\xaa\\x97\\xbf\\xdf\\xb3\\x92\\xffH\\xdf8X\\x15R\\xd2\\x06k\\xc5\\xf7\\x837K\\x12\\xcc\\xde(_\\xff\\xff\\xfe\\xda\\xfd\\xfcN\\x07\\xcd\\xb2\\xd7K\\x1b\\x99\\x18a=\\x17\\xe6\\xdc\\x13\\xc4\\x06*\\x19\\xe4\\xbd\\xff\\xff\\xff\\xc6-\\xef\\xa9\\x1bn\\x9f\\xe5S\\x11\\t\\xe9_\\xb0\\xcd\\xd6\\x07\\xb01M\\xb1<\\x93\\xe5\\x05\\x96h\\x92\\xf4\\xaf\\xa1!\\x91{\\x03\\x15\\x0b\\x0f%\\xf7\\xee\\xfd\\xde1l\\xbd\\x923,v\\xc4\\xcf{\\xa5\\x81fF\\x18OE\\xf9\\xb6Z\\x14\\xc6|qMX\\xa6nuJ\\x87\\x148\\xf3E\\xbaX\\x16d`\\x91B\\x1e\\xff\\xff\\xf7\\xf4\\xa76\\xe4~\\x07\\x96\\x9dM\\x10\\xd6\\x95\\x85\\xcd\\xde7\\x10\\x8c\\xb9I\\x86\\xfc\\xf4\\xab\\xa9@\\xa1\\xfa\\x07\\x97\\xa9!\\x91zJ \\'<\\x97\\xbe\\xdf\\xff\\xbf\\x8d$q\\xe2\\xbb\\x7f\\xfe\\xff~\\xaa\\xaa\\xaa\\xabJ\\xdf\\xfd\\xdd\\xfb\\xd0\\xac\\x0b\\xdf\\xff}\\xdd\\xb6\\xdb_\\xdf\\x7f\\xff\\xff\\x05\\xfd\\\\}\\xc2M\\xcd&\\xef\\xbf\\xef\\xff~\\xef\\xb7\\xf1<3u\\x81\\xb4q\\xadU\\x90F\\xb5+\\xce\\x9dyB\\x9d\\x1cD^\\xd2\\xd4G\\x13\\x07\\xab\\'K)\\x95k\\x7f\\xbd\\xff\\xff\\xff\\xb8#\\x8f\\x15\\xd4+\\x17\\xbf\\xff\\x7f\\xfd\\x9c\\xac\\x81\\x0e\\xe9`Y\\xa7\\x8a\\xe8\\x1a\\x19\\x17#\\x1d\\xc2\\xc4\\xb3KD\\x04\\xa6(c\\x88\\xc9\\xe5\\xff\\xdf\\xff\\xd5\\xe9\\x8d\\xb0&5\\xba+#.\\xb5u\\xd2IU2,a\\x9aZ\\xb57\\x7f\\xbf\\xfd\\xff\\xfd\\xd4vk\\x1e\\xcd|@L\\xc8\\x8alX\\xede\\xbe\\x1f-\\xae\\xf7y\\x7f\\xbf\\xff\\xf7\\xff\\xf4=\\x81[H\\xeb v\\xbcW{M\\xdf\\x7f\\xff\\xff\\xfe\\xff\\xf7\\xbf\\xf5$2/F\\x16&\\r5\\x89 _~\\xdf\\xff\\xfe\\xfd\\xfb\\xfdE\\xa1\\x17\\xf66\\x07\\xa4\\xb3/\\x15\\xd1\\xd9\\xacw\\xff\\xef\\xdf\\xff\\xff\\xdf\\xf5\\x83k*\\x97\\xad\\x0e\\xebS\\xb3\\xdb!8\\xeaE\\x89fj\\x17\\xfb}\\xfb\\xbf\\xff\\xbb\\xef\\xbf\\xef\\xc4\\x96B\\xf6\\xc4\\x95\\x91\\x95\\xb2\\xc6)\\x8bYj2\\xac\\xe5b\\xdb\\xae\\x16%\\x98\\x19&\\xcd\\x118S\\x1e\\xcd\\xda\\x15\\x9dEE~]\\xff\\xff\\xfd\\xfb\\xf7~\\xef\\xff\\xff\\xff\\xff\\x7f\\xdf\\xff\\xdd\\xf9q4\\n{9\\xb6^\\xc5\\x93~\\x85\\xe4\\xceP\\xceR\\xb0;\\xa5\\x89T\\x0c1\\xbb\\x97\\x7f\\xfe\\xfd\\xdd\\xff\\x7f\\xff\\xff\\xfe\\xff\\xff\\xff\\x7f\\xff\\xff\\xf2\\xf2\\x966\\xf4x\\x8d\\xc5\\x02\\xcc\\x8b\\x84o\\x9c,J\\xa9\\x97iX\\x80\\x98\\x96\\xad\\x0b&_Qo\\xbb\\xff\\xff\\xff\\xbf~\\xff\\xff\\xff\\x7f\\xff\\xff\\xbf\\xff\\xb7\\xcb\\xae\\xe6\\rt\\x0b\\x17yj\\xff\\xff\\xff\\xff\\xff\\xbf\\xeak\\x03\\xd1\\x88\\x82\\x9c\\xfc\\xd7Y\\x8a\\xc8\\x10\\xee\\x96\\x05\\x9a\\x0c\\xab,\\xc8k\\x7f\\xff\\xfb\\xf7\\xfd\\xff\\xfe\\x91\\xb0\\xf9\\xd2\\x88&\\rS\\x03|\\xe1`Y\\xa6X\\xcd\\xe3\\xd7M`z\\xcb2P\\xec\\xe5da\\x12\\xad_\\x7f\\xffw\\xee\\xff\\xb9\\xa0(_\\xfd\\xff\\xdf\\xef\\xdf\\xff\\xf6\\xfa\\x90\\xcd\\xd9\\x87\\xa3\\x11\\x059\\xa7\\x9cF\\x1b\\xff\\xff~\\xef\\xff\\xfd\\xfa\\xbf\\xb0&zP\\xfa\\xd5\\xd6r\\xce\\x04;\\xa5\\x89f\\x93w\\xffw\\xff\\xbb\\xbf\\x7f\\xff\\x7f\\xdcJ\\x08^hJ\\xc8\\xc8a\\xa6\\x1d\\x8bYj6\\xac\\xe5b\\xd3\\xf7K\\x12\\xa8\\x18c\\xa8\\xa7\\xc2\\x89\\xe2\\x03\\x15\\xdb5EL\\x9f.\\xfb\\xb7\\xdf\\xbb\\xef\\xf7\\xfd\\xff\\xfd\\xff\\xfb\\xff\\xbf\\xff\\xf7\\xff\\xb9q4\\x02x\\x8d6\\xc3l\\x82\\x1e\\xd1\\x7f&r\\xdb$\\xc5\\x81\\xdd,K0\\x8c0\\x9f.\\xff\\xff\\xbf\\xee\\xef\\xfb\\xfe\\xff\\xff\\xdf\\xbf\\xff\\xff\\xbe\\xff\\xf5\\xea\\xca\\x81\\xb7\\xc7\\x88,T\\xb3Ur7\\xce\\x96%T\\xcby\\x92 \\xa6%\\xabB\\xc9\\x97\\xaa-\\xf7\\xff\\xbf\\xff\\xff\\xdd\\xff\\xfd\\xdb\\xff\\xbf\\xfb\\xff\\xf7\\xff\\xf6\\xd5\\x852/P\\xac\\x0c\\x83\\xbeb\\xc1n\\x8e\\xf9Q\\xdfVU\\x07\\xcf\\x9eZ\\xbf\\xdf\\x7f\\xff\\xff\\xfd\\xff\\x98\\x1c\\x8c\\xf1\\x96\\x9bb\\xedm\\x84\\xca\\x8b\\xd6b\\xb22y\\x7f\\xef\\xbf\\xef\\xc0\\x1cx\\xaf@\\xb0/\\x7f\\xfe\\xce\\x0b\\xee\\xe7J\\xe8\\xe3p8>6\\xc8\\xc5\\x96\\x85`5\\xcd\\xb21<\\x9b\\xbf\\xff\\xfd\\xfd\\xfb\\xfbh\\xd2G\\x1e*\\x9c^{)P\\xd7\\x07@\\xcc>T\\r\\xbe\\xbc\\x19\\x85{s\\x1c\\x18v\\xe2ZG\\xa8\\x9c\\xdb\\x08\\xe4\\xad\\xef\\xff\\xfb\\xff\\xb6\\x02\\xc4\\xaaF\\x18K\\xfd\\xff\\xff\\xad+\\xad*\\xabM4\\xd5\\xff\\xff\\xff\\xce\\x00b\\xf3~\\x93\\x890)\\x9d\\xc1\\xd2\\x1a\\xe0\\xdbU|P\\xaa5j\\xfb\\xbf\\x7f\\xdd\\xfb\\xf8\\xc6\\x1b\\xdb\\x98\\xa4\\xb0\\xa6X\\x96`e\\x84\\xbf\\xfb\\xbb\\xff~\\xfd\\xfd\\xf7w\\xef\\xfb=\\x94\\xa8O\\xb1]\\x8b)B\\xb5\\xa5b\\xef/\\xf7\\xff\\xffb\\xcaP\\x0b!\\xb6G/5\\xe6\\xde\\x98\\xaf\\xff\\xff\\xef\\xc0\\x1c{^\\xc5\\x94\\xa9O\\xb7\\xff\\xdd\\xeb;\\x0eq!\\xcc\\xbf\\xff\\x91\\x06\\xd5\\xf1B\\xa9i\\x02\\xc5\\xedM\\xdf\\xef\\xff\\xfe\\xfd\\xfb\\xf1\\xa4\\x0e<Q9\\xc06\\xb1\\xe6\\xc6\\xe3\\xd1}\\xa3\\xb5\\xa0\\x80\\xd9O\\xe11\\xc5\\x87K\\x12\\xcc\\x0c0\\x9e\\x81\\xcd\\xb2\\xf6\\x16*V*\\xfd\\xfb\\xfb\\xff\\xfe\\xef\\xf8\\x03\\x8fi\\xcc\\xac\\x0c\\x86\\xde\\x9c\\xb2\\x1c$\\xe0\\x192\\x03[\\xdf\\xff\\xc6\\x8bv\\x8aK\\x072\\xfb\\xbf\\xce\\x01\\xe11Ia\\xc2M\\xcc\\x0c1\\xb6\\x90,\\x07\\x8a\\x17\\xdf\\xf7\\xff\\xaf\\xdf\\xbf\\x1aH\\xe3\\xc5\\x13\\xcb\\xe7\\x03=\\xa2\\xfcY\\xe7\\xe11Ia\\xc2\\xc0\\xb3#,tpO\\x00\\x84\\xf28R\\xa7\\x91\\xfd\\xb5\\xfd\\xf7\\xfd\\xffw\\x1e+\\xa8\\xeb\\x91\\x88\\xcf\\x19fY\\x83Z#<<\\xe0\\xe4\\xe23\\xde\\xb5t\\xa1\\x8bFY\\x83\\xcb\\xef\\xff\\xff\\xff\\xff\\xc0<\\x8e<dH\\xc5\\x83L\\xa8\\x1byv\\xd6\\xe680\\xe9`Y\\x81\\x86\\x07\\xb6\\xda\\x1a\\xdf\\xff\\xff\\xff\\x1aq\\xe2\\x9b\\xb7\\xbe\\xef\\xe3D\\xa7\\x0ep!\\xcc\\xbf\\xff\\x91/\\xce\\x00r\\xb4\\x85`Z\\x9b\\xbe\\xff\\xff\\xfe\\xdbm~0\\x11\\xc7\\x8a\\xa6\\x9c\\x0bm\\x05\\x823\\n\\x14\\xed{(\\xbbF\\x92\\xaa\\x03\\x92\\xa1;\\xcfJUU\\xe06E\\xdb\\x98\\xa40\\xe9bY\\x91\\x96\\x13%\\xef\\xff\\xff\\xff4\\xe8a\\xce\\x02>p#\\x17\\x96\\x0b\\x9c\\xcd\\x84\\xe2\\xb2\\xc9\\x9e6\\xc3\\xd8\\xe6\\xd5<J\\x88\\x14\\xc6a>\\xb3\\x15\\x91\\x82z/\\xce\\x05}\\xdf\\xff\\xdb\\xd9',\n",
       " b'\\x7fm\\x7f{gE\\xe0\\x87\\t\\xf8\\xd2M\\xe9\",\\xea\\xdd\\xfb\\xf7\\xf7\\xbd\\xbfe\\xe36\\xe9\\x85\\x0e\\xf4\\x84\\x1b\\xe6\\x84\\xb1E1\\xca1\\xbf5nAfFb\\xc5\\x14\\xc6(\\xc6\\xde\\xb5)\\x8c\\xe5\\x98$nV\\x98n*\\xef\\xfe\\xff\\xff\\xfd\\xe9JP\\xda\\xfb`S\\xe0\\x97\\xd4\\x17\\x9a\\x83\\xd6b\\x12\\xa6\\xe4\\xae\\x9cIw\\xf7\\xffw\\xdf\\xf7\\xad`\\r\\xca\\xb3\\xe0\\xbc\\xd2\\xc4\\xb3^\\x98?5\\xdb\\x00lU$%W\\xc6\\xe6\\x14\\xc1\\xbdc\\x0b\\nzU\\xa7K\\x10C\\x06\\x1bT1\\x12]\\xff\\xdd\\xff\\x7f\\xf6\\xccT\\xa2\\xda4#\\xccX\\xf3\\\\\\xf6\\xaeZ\\xc8\\xf3\\x96\\x12\\x0c\\xc5\\x89,\\xf4\\xed\\x8eh\\xde\\xb2\\xf9\\xc9l\\xf21J\\xc4\\x97\\xb7\\xff\\x7f\\xfb\\xfd\\xb3\\x96\\x13\\xbd\\x11\\xacp\\xab\\x16^\\xdf\\xfd\\xdf\\xbf\\xecO\\x0c\\xe9^\\xcbG\\xb3T\\xb6-\\x95\\x18\\xd1G\\x95#\\x0cYJdbQ%\\xdf\\xfd\\xff\\xff\\xf5\\x97\\xc1\\xc2<k\"U\\xd9\\xdb\\xf3Y`\\xdb\\x8f\\n\\xe6\\x15I\\xdb\\x1a,\\xe6\\x8cmZa{\\xde\\x15u0{X\\xea\\xc6\\xe1/\\n\\xba\\x98=\\xca\\x16+\\n\\xae\\x97\\xba\\xd9\\xed0~\\xb1\\xe6\\xa6f\\xc9/W]|S=F\\x16t\\xcd\\x86n\\xa67\\xb9I\\xad\\x9c\\x19@\\xd7GI\\x10.\\x18\\xa6z\\x93\\xc1L\\xcc\\x88\\xa4\\x98\\x80\\xac\\xebU\\xd4\\xc1\\xf2\\x1bt\\r\\xaf\\x9d\\x17H\\xf3!\\xb7\\\\1L\\xf5jJ\\xc5\\xa5\\xabUM1\\x1e\\xc4\\xb9bVf\\x19\\xb5\\xa4\\x0b\\x94\\xf1\\xc1\\x98\\x0fQ\\xd6\\xa4\\x92\\xf7_\\x14\\xcfr\\x0f) xU\\xd4\\xc1\\xed\\xb3\\x85HX\\x89\\xac\\x92$\\x03K\\x16\\xce\\x03p\\xab\\\\`t\\xb0\\x84\\xf4P\\x97d`7\\n\\xb5\\xac\\xbc\\x90-\\x92\\x1c3\\x91\\xd3\\x17_\\x14\\xaf\\xc8\\xf9$\\xbe\\xc2\\xae\\xa6\\x0fRK\\x8e\\x94\\xb1\\x98b\\xe1\\xae\\xaf\\xc9\\x91N\\x01\\xc9I\\xc1\\rj\\xaf\\xe1\\x9a\\x9a!\\xfbg)\\x06v\\xca\\xb3\\xd2pH\\xbfl\\xe4\\xc0f\\xcb\\xc2\\xb2\\xc2\\xcc\\xa0\\xc5\\xc3\\x0e\\xcf\\xab\\x91\\x19\\xe7\\x91\\xf3\\x12@\\xd8f\\xa6\\x98=\\x1dxF>p\\x95\\x90\\xa0K\\x17_\\x0e\\xcf\\xe4\\xc9\\x19\\xadbxf\\xea!\\xeb\\x10&\"\\x07\\x961)\\x91~v\\xc2{\\x07\\x9d\\xd4H!\\xedL{\\n\\xab\\x9c\\x1a\\xecS7Fd;\\x16\\t\\x10|\\xa2\\x83p;\\xaf\\x8d\\xcfrd\\xd3Z\\xc4\\xfb\\x9a\\x9a`\\xfc\\xed\\x93\\x11\\x0f\\xb4U*f\\xf9\\x0cF\\x17_\\x0e\\xae\\xe4\\xc9\\x19\\xadb*Cg\\x98\\x8d\\xbd\\x85\\\\\\xec\\x1f\\xb5c\\x9b\\x1e\\xca7\\x048O\\x17\\xd2@O\\x91\\xd2\\xc2\\x13\\xe2\\xd3k\\xa5\\x00\\xf3\\x90\\xdbW\\xff\\xfd\\xff\\xff\\xff\\xfb\\xfe\\xed\\xff\\xf7\\xff\\xefE1\\x8b\\x00C\\xd6\\x98\\xcd\\xe5\\xc3\\x14\\xcf\\xe4V3Z\\xc4\\xc8Cg\\x9c\\x8e\\x1e\\x19\\xba\\x98?\\x8ae\\x0fWc4\\xba\\xf8\\xa5~L\\x91\\x9c3L\\x94Rp\\xce\\x0c\\xa0\\xf0\\xcd\\xd4\\xc1\\xf1\\xeaYGJ\\x8f;mk\\xe6 S\\xeb\\xe78\\xd6\\xaa\\xcc\\xa0\\x1f\\x00\\x91\\xd8w_\\x14\\xcfrd\\x8c\\xe1bk9g\\t\\xe5\\xabR\\xbdl\\xddD>\\xc3`\\xc4@\\xf0G\\xc1\\x030\\x9d\\xad}<\\x02x\\x87\\xc9,\\xdd\\x99>\\xd0\\x82\\xf0;\\x86\\x1d\\xbf\"\\xb1\\x9c,L\\x8c\\xe5b\\xc5#\\x85)\\xe1\\x9b\\xa9\\x83\\xd1\\xc8\\x1d\\x80`FO\\x9dD\\x81\\xc2\\x94\\xdc\\xc7\\x96\\x17K\\x86)_\\x93$f\\xb5\\x87\\x938\\xf35\\x98\\xceH\\x9b\\x0c\\xddL\\x1f\\x9d\\xb2\\x9e y\\xec\\x92\"\\xcb\\xad<\\x8e\\x14\\xa8\\xe6,h\\x1e\\xdc1L\\xf7&H\\xf6\\x16\"\\xab\\xac6I\\xe1WS\\x07\\xdf-F,\\x83\\x0f\\x9d,\\n\\xcb\\x0b7\\xc2F\\xf6\\xe1\\x8d\\xcf\\xe4V3[4\\xc8\\x10\\x1b\\x04\\xebU\\xce\\xc1\\xe9\\x16r\\x98\\x05p\\xc53\\xea\\xe4\\xab\\xa7+\\x070\\xb0\\x188R\\xbe\\x19\\xba\\x98>\\xc4\\x01\\x88\\x81\\xe7\\xca\\xb8a\\xd9\\xeeL\\x99\\x81\\xe1i\\xd3\\xc2\\xae\\xa2\\x1f\\\\\\x8d\\xf2m0\\x18\\xbd\\xee\\xfa\\xd9\\xdb\\t\\xa4\\xa3bq\\x8a\\x8dz\\x07\\x89\\xed\\x85\\xb3\\x9a\\x03\\x0ci|\\xf4M6Fh[!\\x82i\\x0c6F&\\xb6C\\xb21;\\xd2\\xf1_.\\xff\\xfd\\x7fl,) yX\\x94\\xf8%\\xc3\\x1c\\xdd\\xce\\x05\\xa5I\\xe3\\xcc(b5\\xa9[\\x851\\xe5\\x99\\x96+#\\x830\\xe9K\\x19\\x966\\x8e\\x8fiTPQ*\\xfe\\xff\\x7f\\x7f\\xbf\\xebfnI\\xbc\\x99\\x12xD@\\xd5\\xb0%\\x8a+L.\\xc8!\\xeb\\x16\\x13!\\x9d\\n<\\xc9\\x19\\x0b!P\\x16\\x07\\xad\\x08,\\xc9\\x03\\xce\\xc7\\xf7\\xf7\\xfd\\xfd\\xbd\\x94md=\\x9d\\\\j\\xf8\\x04HR\\xaf\\xed^\\xf7\\x7f\\xaa\\xab\\xd2\\x99\\x97\\x81X\\xe2\\xc6\\xaf\\x1dg\\xd8R\\xa7\\xa1\\xb8\\xf6Qx!\\xad8\\xf8%\\xf0F\\x90\\xa5\\x1f8F\\xdf\\xc9\\x92\\xf3\\x90w\\xcbT\\xcb\\x0c\\x13\\x8crq\\xda\\xcak\\xb2\\xd1~c\\xc5\\x0b\\xff\\xee\\xfd\\xfb\\xf7\\xa2\\x99\\xba3\\xd4\\xf38\\xcf\\xd5\\xca\\x95\\x0e\\xd3%\\xaf\\x94\\xf3%\\xef\\xff\\xea0\\xf4\\xe5\\x10I\\xd6\\xa1\\xd3guSg,\\x08\\xd6\\xa5z\\xc1\\xcd\\xb2\\xebP\\xc9\\x18\\x07\\x1fF\\xe9\\x1es\\xeb\\x05\\xc2\\x07\\xe9\\x8d\\xad\\x0f%\\xef\\xbf\\xfb`,K22\\xc1\\xde\\xff\\xf5ZiV\\x9aUV\\x95\\xbf\\xdf\\xb9]Ck<\\xb1\\x89L\\xf4_\\x9bbp{T|\\xb8H\\xe3\\xc1#O6\\x9b\\xf2\\xea8\\x00\\x8e<\\x12h\\xcf\\xbd\\xday{\\xff\\xff\\xdf\\x138\\x81xO\\x00\\xa1\\xf6e9\\xd3\\x19/\\x7f\\xffe\\xbc\\xdfz\\xe2\\xc6%1\\\\\\xe1\\x10Qz\\x8e\\xdc mE\\x1a,7\\x12\\xb6\\x81\\xd1\\xb98\\xbe^\\xbeIf\\xeb\\x01\\x1a\\xda\\x0e\\x05#\\x8f\\x00\\x8f/\\xf7\\xef\\xfb\\xa3\\x1cJ\\x15\\x85\\x17\\xf3\\xc8\\xe5\\x92\\xf7\\xfb\\xfc\\xcf7\\xb5!a%3\\xd05\\x1b\\x12\\x92\\xdbU\\x1d\\x05\\x9b\\xac\\xd3\\x8b\\xb5\\x7f\\xf7\\xfb\\xfe\\xcb\\xee6g\\xa0|\\xc4\\xc1f\\x8a\\xde\\xff\\xfe4\\x91\\xc7\\x8a\\xa5\\xfe\\xfe\\xd2\\xad4\\xaa\\xaa\\xdf\\x7f\\xf9Z\\xa1\\xeaR\\xc6%3\\xd1~\\x8d\\x89\\xc5\\xf2\\xea>\\x90\\x8e4$i\\xe5\\xff\\xdf\\xfe\\xecMB\\x00\\x84\\xf0\\n\\x9ffL\\x1d1\\xf2\\xa0p\\xa4g\\xcd\\xb0\\xf0\\xa9\\x86\\x18\\'\\x1e\\xe5\\x04\\x17l\\xfd\\xac\\xa1\\x92\\xafq\\xad\\xaf\\x00\\xe6\\xd9_\\xfb\\xff\\xf7\\xc2\\xa6X\\x9c\\x1c}!H\\xec\\x9fd\\x1c y6\\xd8\\x94\\x9e\\x12\\xaa\\xe5?\\xa6\\xc3q\\x95\\x04,\\x97\\xbf\\xff\\xcf\\xaa\\x1a\\x16RQ\\xdf\\xff\\xfe\\xfd\\x18\\xb6^\\x150I\\xc9\\xc7\\x92\\xf7\\xdf\\xbec+\\xcd\\xea\\xf6RG\\x7f\\xf7\\xff\\xfc\\xcd\\x19\\xfa\\xea\\xa5C\\xcbd\\xb5|\\xa7\\x8a\\xdf\\xff\\xdf\\xbf\\xb6\\xdf\\xff\\xb3\\xf8\\xae\\xf6\\xc9}\\xff\\xc1\\x7f\\x95\\x91\\x16e\\x17\\x9a\\xc5vND\\x84\\x9cJ;\\xddD\\xe3;\\xbd\\xe6\\xef\\xbf\\xff\\xff\\x9fb\\xb7(d\\xab\\xdck\\x7f\\xf7\\xff\\xfeW\\x9a\\xeeP\\xc9AW\\xba\\x89{\\xef\\xfa\\xca\\xf1]4\\x00tp\\xb0\\x84\\xf8\\xa8yl\\x98\\xbf\\x94\\xf3\\x8c\\xf5\\x8b\\xfd\\xdf1\\x95\\xb1^g\\x19\\xf6U\\xff\\xfd\\x00\\xe3\\xc5~S^x\\xbd\\x98\\xca\\xbd\\xee@\\x1c|\\xdc\\xda\\xc8k0=\\x94D}*\\xce:\\xf8\\x91Z\\xca\\x8b\\xec\\x96\\xb6c[+\\x1c\\xd8\\x9a\\xfa,\\xdd`\\x0f\\x94\\x0b.\\xd9\\xcdf\\x9d(\\x0f\\x14/\\xbb\\xf6\\xdbm\\x7f\\x13S7i\\x92i\\xc0\\xbetn\\x08p\\x9fl\\xa1\\xa7\\x95g\\xed\\xa4\\x89b\\xa9\\xe4\\xbd\\xff\\xfe%\\xcb\\x02\\xa9\\x18a/\\xfe\\xddUUU\\xa5UiUo\\xfd\\xfeV\\xa8z\\x94\\xb1\\x89L\\xf4_\\xa4$\\xe2\\xf6\\xa88\\x00\\x8e<\\x024\\xf3\\xd1>]_.R8\\xf0I\\xb1z\\xf7i\\xe5\\xfe\\xff\\xff\\xefE\\tu\\xe1<\\x02\\x87\\xac\\xc2s\\xa62^\\xff\\xfdd\\xf9\\xbe\\xf5\\xc5\\x8cJb\\xb6-aE\\xf4t\\x91\\x03s\\x91\\xe2\\x03q+\\xb9~\\x90\\x92\\x90\\xf6\\xaa:\\x0b7X\\x08\\xd7\\xa3\\xe5\\xc8[\\x1a\\x12<\\xbf\\xfb\\xfe\\xef\\x89\\xd0[E\\xa8\\xdf)\\x18\\xb2m\\xff\\xfegP\\xf5)c\\x12\\x99\\xe8\\xbf\\xd6\\xe4\\xe0\\xf9u\\x1d%\\x9b\\xb4\\x92.\\xd5\\xff\\xff\\xffw\\xad\\x8c\\ng\\xa0{\\x05 \\xb12^\\xff\\xff+\\x14\\xb7/7\\xd7\\xb2\\x92;\\xff\\xbf\\xff\\xc6\\x90^;$\\x90eH\\xe1J\\xf52\\xc4\\xb3#$\\xc9\\xc5b\\x96\\xe5\\xb0M%1\\xca\\xcet\\xd7\\xbe\\xe4\\xf16K\\xef\\xff\\xa4\\xb3S\\x99\\x0f\\x94\\x10]\\xb3\\xf3~X\\xc4\\xa65d,/E\\xfa@N/\\x97W\\xc7*\\xba\\xc0H\\xb7\\x8dr\\x00\\x14v\\x1cT\\xd3\\xa5J\\xfe\\xff\\x7f\\xfd\\xeba6g\\xa0nP,\\xdc\\r9\\xc2G\\xb2@\\xfa\\x88\\xb3u\\t\\xf4\\xdd\\xb0\\xd2\\x835\\x8a1Y\\xd2Y\\xbb2Eo\\xbb\\xfe\\xef\\xea5}\\xad#\\xee\\xc5\\x19\\xec\\xe1;\\\\\\xdb\\n\\xf2\\x94\\xf0\\xe8,\\xdd`j\\xdb\\xdbY\\x9e\\xd7v\\xb0?\\x94\\x10]\\xb3\\xc9{\\xff\\xf8\\xc0\\x07\\x1e)\\xb7\\xdf\\xfa\\xaa\\xb4\\xaa\\xaa\\xab\\x7f\\xff\\xa4g\\xaa\\x1c,p\\xa3\\xbe\\xff\\xff\\xdd\\xb6tn\\x08k1\\xec\\xa2&K\\xdfo\\xfbx\\x11u\\x0fI\\xe5\\x8cJg\\xa0j7\\'\\x17\\xcb\\xd7\\xc0B8\\xf0H\\xd5\\xafLm\\xaa\\x8e\\x05#\\x8f\\x04\\x9cg\\xde\\xcd<\\xbf\\xdf\\xff\\xfe\\xd9\\xd1x!\\xac\\xc5\\xdb\\xc0\\xa7\\x81T\\xf2_}\\xfb\\xf7\\xef\\xef\\xff\\xf5|\\x92\\xcdM\\x80\\x91~\\xa3\\xae\\x128\\xf0\\t\\xe2\\xb5\\x93\\x91\\x1b\\x93\\x8a\\xff\\xfe\\xbaiy\\xae\\xd5\\xd9\\x0b5\\'1\\xf5\\x90\\x88+YO/}\\xdf\\xf2\\x9a\\xd9\\xda\\xf3\\x19^k\\xc7\\x85L\\xb188\\xc7*\\x1d\\xac\\xa6\\xbb%\\xaf1\\xe5\\xef\\xff\\xf0\\x0e\\x92\\xcd\\xd9\\x93\\xec\\xa2\\x82\\xed\\x9f\\x82y\\xa6\\xea\\x04\\xdd\\xef\\xf7\\xff\\xf5%WXO\\xb2\\x81f\\xdb?5\\xf4vJT\\x92\\xd5_ \\xb3u\\x80\\x8f/\\x7f\\xbb\\xb6\\xfe\\xd9\\xd1\\xb5\\x90\\xe0\\xc7\\xce\\x88\\x9e\\t\\xce\\x05\\xe8K\\xc8\\xe0\\xcc5\\xcb\\xdc\\xdb/\\x9d\\x17\\xee\\x0ep-\\xb2\\x8d\\xe9\\x9c\\x18\\xeb\\xc7F\\x0e\\x14\\xa6K\\xfd\\xfe\\x91\\x9f\\x8a\\xedUNDg\\x9eZ\\x0b59\\x90\\xf9A\\x05\\xe0|g\\xb9\\xd1q\\xec\\xa3k!\\xc2|\\xb9\\x8c\\xa7\\x8f<_Ta8\\xcf\\xcb5-\\xcb\\x8c\\xfd\\x1d\\x92w\\x1d\\xac\\xa6\\xbeU\\xab\\xdf\\xff\\xd9^k\\xc0m\\xd0<\\xb9\\x8c\\xa7\\x97\\xff{)\\xed\\xe2\\xbaK7X\\x03\\xe5\\x12\\xda\\xd9\\xf1\\x9f\\xcbeu{\\xde\\xd7\\x19\\xf9\\x97\\xbf\\xdf\\xab\\xa0\\x88e7W\\xc0R8\\xf0\\x085\\xd9\\xaf\\xd9\\x01\\x0e\\x8aE\\x84\\x07\\xc4\\xe3\\xb4\\xc9\\xc9\\x13\\xc5\\xf6S\\xd9\\xe7\\x8b\\xe2\\xb1\\xcd\\x8b\\xbc\\xfb{\\xdf\\xffow\\xa2H_*\\x05\\x80\\xf9A\\xab\\xc0\\xf9\\xb6^\\x152\\xc4\\xfa\\xe3\\xc9\\x7f\\xffX;x\\xd2U\\x1b\\x13\\x88d\\xf6\\x1a\\xf8\\x93\\xd4p)\\x1cx$P\\xbf\\xff\\xfd\\xdd_\\x02\\x9dGU\\xee\\xa2l\\xd6\\xec\\xa7\\xb2\\xa9\\x1ev\\x9e_\\xef\\xf8#\\x8f\\x15\\xf4\\x8c\\xe2\\xfbx\\x94\\xf7\\xbd\\xe7 \\xef\\xac\\xa3pC\\x83\\x03\\xe7M<\\xbc\\xa8\\xbe\\xcbE\\xec\\xc6\\xbc\\xacR\\xdc\\xa2\\xfaK7XC\\xe5\\x04\\x1b\\x81\\xc5M:P\\x9eM\\xdf\\xfd\\xd7\\xef\\xdf\\xbd\\x14\\xcd\\xd1\\x99\\'\\xd8\\x15\\xec\\xa2\\xf0C\\x84\\xfb\\x9b\\x90\\xf2^\\xff\\xfd\\x89b\\xc0\\xb3\\x03,%\\xf7\\x7fUV\\x95U\\xa6\\x95U[\\xff\\xfeW\\x9b\\xfb<\\xb1\\x89L\\xee^\\xe9\\x018\\xb6\\xd5G\\x00\\x91\\xc7\\x82F\\xadwcmS@\\x84l\\xf0\\tx\\xbe\\xf7j\\xd5\\xff\\xbf\\xffv&\\xa0\\x00Bu\\xb6\\xa7\\xd9\\xeb\\x07L+{\\xfd\\xdde\\xbc\\xdfz\\xf2\\xc6%1\\xab!\\x10Mtt\\xb0\\x85\\xf3\\x11\\xe2\\x03q+\\xd1~\\x8d\\xc9\\xc5\\xb6\\xaa\\xf9\\x05\\x9b\\xb3\\x04k\\xd4p\\t\\x1e\\xe9\\x1b\\xcb\\xfd\\xff\\xff\\xc68\\x12\\xd5Z\\x8b\\xf9\\xc5\\x1c\\xb2^\\xff\\xef\\x99\\xe6\\xfdHX\\xc0\\xa6m\\x17\\xe8\\xdc\\x9c\\x1f.\\xa3\\xa4\\xb3S\\x9e\\xa3O/\\xbb\\xff\\xffYt\\xc4\\xa6z\\x06\\xd9&\\n\\xc4\\xc9{\\xff\\xbeV:\\x02\\xbc\\xde\\xafc\\xa4w\\xff\\x7f\\xfb\\xc6\\x92n<\\xe5\\x882\\xa5\\x1a\\xd4\\xaft\\x90Y\\x81\\x86\\x15\\xe2\\xcd\\xd0\\x17\\x82\\\\\\x94\\xc6+9\\xd3^\\xdf\\'\\x89\\x95\\xbd\\xfe\\xfe\\x82\\xcd\\xd6\\x00\\xf9E\\x05\\xf4\\xfa\\x86\\xc91)\\x8df\\xb4Az/\\xd2\\x12pm\\xaa\\xbeIg\\xb6\\x124\\xf3\\x96\\xaf(\\xf38\\xa6F\\x95\\x0b\\xfd\\xfe\\xff\\xeb/\\x8cJf\\xb87( \\xbbf\\x9c\\xdb\\x11\\xf1`\\xb8\\x8d\\x16n\\xa1>\\x9b\\xb6\\x15-g\\x02\\x8cVt\\x95]\\x98\"\\xb7\\xff\\xff\\xffQ\\xa1\\xea\\xe3\\xeeJ3\\x81\\x01E\\xf3l+\\xba)\\xe1\\xa9*\\xa9\\xb0\\xb6\\t\\xdb\\x830\\xaf\\x8e\\xba\\x7f( \\xdb{\\x92\\xf7\\xfb\\xf8\\xd3\\xa7\\x1e*\\x97\\xdf\\xee\\xaa\\xad*\\xaa\\xaa\\xdfo\\xfb\\xa3>\\xa1\\xd7\\xce\\x82;\\xff\\xf7\\xff\\xc6\\x85\\x1b\\xd481\\xec\\xa2&K\\xfd\\xfe\\xda\\xfd\\xfd\\xfd\\xff\\xca\\x8b\\xf3\\xb5\\xe62\\xaf\\x15\\xc7\\x85L\\x92rq\\xbe\\x9d\\xc7k*/Yf\\xb6f\\xde\\xff\\xff\\x05\\xfaJ\\xae\\xb0\\x07\\xca\\x05\\x9bl\\xfe\\xa7diR\\x9b\\xbf\\xdf\\xff\\xfa\\x92\\xab\\xb3!\\xf2\\x8a\\x0b\\xb6~k\\xb5R\\xae\\xd4\\x13.b\\xa9\\rp\\x0c\\x9e\\xc3W\\x97\\xbf\\xff\\xbf\\xe3A\\xcb\\xc0\\xcdf>nC\\xd8\\'6\\xcb\\xd4\\x97\\x11\\xc1\\x98z/\\xce\\x01\\xb9\\xb9\\x7fE\\xf9\\xc06\\xca.\\xb2\\x1c\\'\\xeb\\xc7I\\xcdgS%\\xf7\\xfe\\xe8\\xcf\\xc5uj\\xa5T\\x8e\\xb9{,\\xd4\\xe6\\x03\\xe5\\x16\\xb7\\x03\\xd7\\x9e\\xca.\\xfa\\xc7/\\x0481jc*\\xd3\\xcf\\x17\\xd5\\x18N3\\xf2\\xb1\\xd0\\x17\\x19\\xfa\\xeeB\\xa1\\xe5\\xe5E\\xfc\\xa7\\x97\\xdd\\xff\\x00q\\xe2\\xbbH\\xe3\\xbd\\xef9/\\xc7\\xcd\\xcb\\xacq\\xad8\\xed\\xe2D\\xfa\\x04\\x89\\x97\\x95\\x17\\xac\\x96\\xb6d^\\xed\\x8e\\x80\\x9a\\xe9,\\xdd\\x98>\\xca\\x05\\x97\\x84sVE\\xd5\\x07\\x93w\\xdb\\xfe\\xfd\\xfb\\xf8\\x99\\xd5tf\\t\\xa6\\xd8v\\xf1\\xb3\\xc0(|U.m\\x87\\x9aZ\\x89\\x01V/\\xadNm\\x97bH]\\xc1\\xc5\\xb6Q}CY\\x8d\\xcfQ\\x15\\xbd\\xff\\xfe\\xd8\\x0b\\x02\\xcc\\x0c0\\x97\\xdf\\xfbM4\\xd3J\\xb4\\xd2\\xad_\\xfd\\xf9Z\\xa1\\xeb8\\xb1\\x81L\\xee\\x0em\\x89Im\\xaa\\x0e\\xb8H\\xe3\\xc1#O6\\x89\\xedPp)\\x1cx\\xd4\\xe3>\\xf7i\\xe5\\xff\\xff\\xfd\\xefE\\x08\\x17\\x83\\x10*\\x9ffS\\x9d1\\x92\\xf7\\xdf\\xbd\\x93\\xe6\\xf5\\xeb\\x8b\\x18\\x94\\xc6\\xb3\\x85\\x80\\xd77I\\x10\\xbdDx\\x80\\xdcJ\\xda\\x07F\\xe4\\xe2\\xf6\\xaa:J\\xae\\xb0\\x91\\xafW\\xc0\\x128\\xf4\\x91\\xe5\\xff\\xdf\\xef\\xbcc\\x8d\\x85aU\\xfc\\xe2\\x8cY/\\x7f\\xfe\\xcc\\xd9\\xbd\\xa9K\\x18\\x94\\xcb\\xe8j6-\\x0fj\\xaf\\x90Y\\xba\\xc2F\\x9e_\\xff\\xf7\\xfe\\xcb\\xe3\\x02\\x99\\xe8\\x1bd\\xa4V&K\\xdf\\xff\\xc5f\\xb7/7\\xd7\\xb2\\x9aw\\xff\\xff\\xff\\x18\\x01x\\xec\\x165\\x94#Y\\xdb\\xdd,K0=\\xc6M\\x96j[\\x17Y9)\\x8cY\\xf3\\xa6\\xbd\\xbeO\\x13d\\xbd\\xff\\xfa\\x82\\xab\\xac\\x07\\xd9E\\rl\\xfc\\xdf\\x92bS\\x15\\xce\\x16\\x07ptnN\\x0f\\x97W\\xc9*\\xba\\xcdF\\xady\\xc8%\\x1d\\x875\\x9at\\xa9_\\xff\\xf7\\xfe\\xcb\\xe3\\x02\\x99z\\x07\\xca\\x08/\\x03Np\\x11\\xf9`\\xb7Q\\x16^\\xa0\\\\\\xe9\\xb0\\xa9,\\xce\\x13\\xc7+:nn\\xcc5[\\xfb\\xff\\xbfz\\x8d_\\xd6\\x87\\xdd\\x8a3\\x84\\xe1<_8\\x15~\\xec\\xed\\xf4\\x96n\\xb3|\\x13\\xb6\\xb6PSc\\xac\\x0fr\\x8a\\x0b\\xb6y/\\x7f\\xbf\\x8d:q\\xe2\\x89\\x7f\\xffU\\xa5Ui\\xa5o\\xff\\xeb\\xe2S\\xf9\\xbfY\\xf7\\x18\\xd9\\x9e\\x81\\xd1\\xb986\\xd5G\\\\\\x84q\\xe0\\x12-\\xe7\\xa6>]G\\x02\\xd3\\x8f\\x00\\x9cgw\\xbbO/\\xbf\\xef\\xffF\\x85\\x17Y\\ri\\xfa\\xf8\\x91@\\xa8{{\\xfd\\xfei\\x1f\\x9b\\xbc\\xfb\\x9e{+\\x02\\xff\\xff\\xff\\xefJ:\\xcez\\xed\\xd3lG\\xccQ\\x04\\x9c\\xdb.\\xde$KmO\\x898\\xbb\\x85\\x89fFX\\xf2\\xa9}#\\x8f\\x15Np+\\xff\\x7f\\xf7~r<,7\\xae\\xc5\\n6\\x0f\\xd1~m\\x87\\x9aD\\x89\\tW\\xca\\xb3\\xf5\\xf0\"X*y/\\xff\\xd7\\xef\\xdf\\xdf\\xef\\xda\\x8e\\x92\\xaa\\x9c\\xf5\\x1a\\xf4|\\xb9\\x08\\xe3\\xc1\\'\\x8a\\xd6J\\xa9\\x018\\xaf\\xff\\xd6\\xd0S\\xf8\\xad\\xa3\\xb2\\x06jNc\\xec\\xd6\\xb0\\xade<\\xbf\\xff\\x84\\r\\xf2\\xd42\\xc3\\x00\\xe3\\xf3^\\xbe\\x04Y\\x12\\x12p(\\xefa\\xaf\\x8a\\xda>\\x02\\x11\\xc7\\x82M\\xbe\\xff\\xf2\\x9a\\xecE\\xec\\xc6W\\x9a\\xe8\\xebP\\xcb\\x13\\x92\\x93\\x1ez\\x1d\\xac\\xa6\\xbb-\\x17\\xe6<\\xbd\\xff\\xfe\\x01\\xd3su\\x85\\xb9E\\x05\\xdb>\\xb2y\\xa7J\\x92\\x85\\xfe\\xff\\xf7\\xf4\\x96n\\xb0\\x07\\xca%\\x97\\x81\\xf8\\xafWduA-LU\\x1b\\x93\\x88d\\xf6Q\\x1e^\\xff\\x7fex\\xae\\x03nX\\xedLe<\\xbf\\xdfvS\\xdbb\\xb5\\x05\\x9a\\x9c\\xc8|\\xa2Yv\\xcf\\x8c\\xf6\\xd3+\\xab\\xde\\xef8\\xcf\\xcc\\xbd\\xf7\\xee\\xae\\x92!\\x94\\xdd_\\x01\\x08\\xe3\\xc0 \\xd7b\\xbaH\\x00tv\\xe1\\x00y\\xe8v\\x999\\x06-vS\\xda\\xd7\\x19\\xf1X\\xe8\\x0bF\\x7f*\\xf7\\xff\\xfb~\\xf4I\\x03\\xe56X/\\x94]x\\x1e\\x9be\\xabT\\xf7X\\x07\\x1a\\xb7\\xbd\\xf7\\xc1~\\xbc\\r\\xf4*e\\x86\\t\\xc77}\\xdd\\xdf\\xf7[\\xc6\\x90\\xc9W\\xb8\\xd7\\xcd{)\\x90U#\\xdc\\xb7\\x97\\xbf\\xff\\xdb\\xe8\\xc5\\xb0\\xf9\\x88\\xd5f\\x13\\xeb\\x92\\x93\\xc6\\xc1\\xfa\\x07\\xd6\\xcbTa\"BU\\xbf\\xdf\\xcb\\xcdz\\x0b56\\x13\\xec\\xadYv\\xcf\\x8c\\xfb+\\x8c\\xfe[\\xdfZ\\xec\\xa7\\x97\\xdf\\xfc\\x03\\xa2\\x99a7$\\x116H\\x85i\\x92\\xf2n\\xff\\xff\\xbb\\xf6vO\\x8a\\xe7%\\xc8tt\\xb0\\x84\\xf8\\xa8v\\x91\\xd2D,\\x84\\xb0\\x87\\xac\\x8f\\x10\\x1b\\xb5jv\\xbb\\xd9\\xe3W\\xff\\xff\\xbf\\xfb\\xff\\xff\\xff\\xfd\\xfb\\xff\\xdf\\xfal\\x94\\x94U\\xaa\\xbeIU\\xd6jE\\xed_\\x1c\\xb3v`\\x96\\x9e5\\xd9kW\\xff\\xfd\\xb1\\x02n\\xff\\xfb\\xfd\\xfe\\xdfm\\x86\\x02zULf\\x1eI\\xf3\\x8exl\\x8f\\xba\\x88pb\\xc2\\xbf\\xf7\\xfb\\xbf\\xce\\xcbx\\xad\\x9cd\\xa0\\xd7\\xa3\\xb2T\\x86\\xe47\\x04\\x1a\\xe8\\xcf\\xb2o}\\xdd\\xf0_\\xaf\\x03}\\n\\x99brq\\xcd\\xdf\\xff\\xbf\\xef\\xb7\\xefF\\xd8\\xc4v\\x08\\xc3\\x9be\\xe7tlX^r\\xc4\\x19\\xc8\\xe0\\xcfw*\\x07\\x0f\\x8d7\\x16\\x9f:u\\xaaa\\x89\\xc1\\xc7\\x7f\\xf7\\xef\\xdfo\\xd4my\\xc0<\\xf2B\\xee\\x0e\\x8e\\x96\\x10=dx\\x84\\xe0|\\xe1\\x04\\xf8#\\x8f\\x15N-\\xccG\\x88\\r\\xfaIb\\x9c\\xf2_v\\xff\\xfd\\xf3\\x90\\xebT\\xc3\\x13\\x83\\xa3\\xf3_WdE1\\x802\\x8a\\xd5]\\x90X\\xc4\\xa6Z&ND\\x8f;R\\x1b\\x82M^\\xd6\\x9e<\\xbd\\xf7\\xfeD\\xbf\\x9aIi\\x1eM\\xdf\\x7f\\xdf\\xff\\xc6\\x9e\\xc5m\\\\\\xa8f\\xa4\\xe6>\\xb2\\x11\\x05i\\x1e_\\xfd\\xf7\\xff\\xa1\\x18\\xcan\\x8f\\x80$q\\xe0\\x90k\\xe6\\xbd\\x96\\xc9\\x13\\xaaT;D\\xc9\\xc8T;H\\xa3\\xa8U\\xf0\\x00\\x8e<\\x12\\r^<\\xbf\\xff\\x7f\\xdd@1\\x94\\xddG\\x00\\x91\\xc7\\x821\\xaf\\x8b\\x8a\\xf2\\xb1\\xcd\\xcb\\x8c\\xfa\\x0c\\xa6\\xea\\xf8\\x08G\\x1a\\x02\\ro\\xbf\\x7f\\xff\\xfb~\\xf4\\xa9\\x8ep.\\xbc\\x0faC,N\\x1b\\xbd\\x81 d\\xbe\\xef\\xff\\xef\\x80p\\x81\\xbeZ\\xa6I98\\xd4/\\xbf\\x7f\\xff\\xdf\\xfd\\xc1\\x18\\xcan\\xa3\\xae\\x028\\xf0H5\\xf1q]\\x06J\\xbd\\xd4N3\\xf3\\xce\\xf9j\\x99bpv\\xdf\\x7f\\xffw\\xff\\x7f\\x805\\x1dW\\xb0\\xd7b\\xb4\\xa7\\x1e\\x152\\xc3\\x04\\xa4\\xf2\\x15\\x0e\\xd2(\\xf3u\\x1c\\x02G\\x1e\\x01\\x14G\\x97\\xbf\\xdf\\x7f\\xbf\\xff\\xf1\\xa62U\\xee\\xa2x\\xb9\\xaf,\\x89\\x1ev\\x9ew\\x9a\\x8a;Ou\\x12\\xfb\\xbf\\xff\\xef\\x808\\xd2\\xbf\\x04w\\xbe\\xff\\xf0\\x07\\x1e+\\xd7\\xc0\\x8a/\\xa8\\xc4\\xbd\\xef9/\\xa3\\xe7\\x1d\\x87\\n\\xd38\\x0b7\\xd6Q\\x13/*/\\xb2Z\\xb8\\xd1\\xb5\\xe5\\x9b\\x9b\\x94^\\xa0\\xb3Sa\\x0f\\x94\\x10^\\x06\\xf2n\\xff\\xfe\\xfe\\xda\\xfe&\\xa5T\\xc7\\x19\\'\\xce==\\xa53\\x84\\xac\\xf9\\xd1\\x13\\xca\\x93\\xf63\\x12\\'v\\xd2Ral\\xd6\\xd8\\x12d\\xbd\\xff\\xfe\\xd8\\x0b\\x02\\xcc\\x8c\\xb0\\x97\\xfe\\xfa\\xabM*\\xabJ\\xaa\\xaa\\xb7\\xfb\\xfeV\\xcd\\xfa\\xce,`S=\\x03\\xebbq{T|\\xc5\\x92D$\\xd7\\x9bW\\xc0B8\\xf1\\xa8\\xd5\\xafL_\\x7f\\xfb\\xff\\xda\\x8f>rD\\x04\\xd7\\x9f/G\\x00\\x11\\xc7\\x82M\\x8b\\xd7\\xb5\\xa6\\x9e_o\\xbf~\\xf8\\x9a\\x84\\xba\\xeb0\\xb1T\\xfb=ci\\x8c\\x97\\xbf\\xff\\xb2z\\x87z\\xf2\\xc6%1[!`5\\xd1\\xc2D/\\x9c\\x8f\\x10\\x1b\\x89^\\x8b\\xf4\\x84\\x9c[j\\xa3\\xe8\\xb5\\xd6\\x025\\xe8\\xf8\\nG\\x1a\\x12<\\xbf\\xfb\\xff\\xfb\\x13\\xe0KQj/\\xe7\\x16\\x8b%\\xef\\xfe\\xe8\\xd1\\xdeo\\xd4\\xb7\\x18\\x14\\xcf\\xab\\xdd %%\\xf2\\xea\\xf9%\\x9b\\xb3\\x04\\x8b\\xf5\\x1e{54\\x91\\xe5\\xff\\xff~\\xf1\\x8e%\\xa8\\xbd1\\x99O\\xec\\xdd\\x0b\\x13\\x89\\x86(\\x93\\xc2\\x8d\\xe9\\xee\\x9c\\x02\\xf4\\x8c\\xd4\\xc6~\\x8b\\xf1\\xa1&\\x02\\xc7\\xa1j\\x8b\\x0b2\\x83\\x19/\\x7f\\xff\\x95\\x8a`/7\\xc3:H\\xef\\xfd\\xfe\\xff\\xc6\\x00^;%\\x8deH\\xd6\\xa5{\\xb7\\x02\\xcc\\x8c0\\xaf\\x95\\x8el^\\t\\xc9Lr\\xcf\\x9d;\\xdfY\\r\\x89\\xb2^\\xff\\xdf\\xa4\\xaa\\xa6\\xc2\\x1f( \\xbbg\\xd4<\\xb1\\x81Lj\\xc8D\\x16\\xd05!\\'\\x17\\xb5G\\xc9,\\xdda\\x1c[\\xcb\\xef\\xff\\x7f\\xd6_\\x18\\x94\\xcf@\\xdc\\xa2\\x83p4\\xd3lG\\xc4\\x81\\xe4\\x88\\xb2\\xf5\\t\\xf4\\xe9\\xe1I\\xd6g\\t\\xe3\\x95\\x9c\\xe5\\x9b\\xac\\x04\\xc9{\\xdf\\xfe4\\x91\\xc7\\x8a\\xa5\\xff\\xfdV\\x95iV\\x9a\\xbe\\xff\\xf5\\xc8\\x9dC\\x85\\x94\\x11\\xef\\xff\\xfd\\xdfl\\xe3\\xcc\\xd6\\xa53\\x80\\xac\\xdc\\xe8\\x89\\x92\\xf7\\xff\\xea\\x9f7\\xeb<\\xb1\\x89L\\xee\\x0e\\x90\\x13\\x8b\\xda\\xa8\\xe9,\\xdd\\x99#^\\xa3\\xcf\\x9c\\x8d\\x03m_\\xff\\xbf~\\xdb$8VF\\x13\\xeb\\x16KS]\\x8a1&!\\x9e\\x9a\\xc4\\x8a\\xde\\xff\\xff\\x95\\xd4=\\'\\x161-\\xf4_\\xec$\\xe2\\xdc\\xba\\x8f=\\x92D$\\x8b\\xda\\x0e\\xb8H\\xe3BG\\x97\\xfb\\xef\\xff\\xe3I$$\\xa4\\xb7\\xbaX\\x15{0`\\xe9\\x8e\\x03s\\xe7\\x19B\\x8b\\xf8T\\xc3\\x0c\\x12\\x93\\xe6\\x18\\xcd2^\\xff\\xfe4\\x82\\xe1\\x82\\xa3\\x05\\x7f\\xffU\\xa5UU\\xa6\\x9aV\\xfb\\xf7Yxl\\x1c\\xa5\\xad\\x89\\x95\\xec\\x8a\\xbe\\xd3\\xdd\\xec\\xc8\\x0c+\\xc5ol$f\\x18\\xaf\\xc11E\\xeb\\x03Z\\x95\\xe2\\xa9nb\\x9d\\xb5\\xaa^\\xc0\\x96+\\n\\xaf\\x92\\xfb\\xf7\\xc4\\xee\\xd5\\xaa\\xd9c\\'\\xd8\\x99\\xb9)0M\\xb6<\\x8fM[cy\\x7f\\xff~\\xfd\\xfd\\xfe\\xfd\\xa8\\xecY$2O\\x15\\xc6\\x8f\"6\\'\\x10\\xc9\\xee\\xa2_w\\xfa\\x8e\\x01#\\x8f\\x04{\\x15\\xd99\\x11\\xb18\\x06Oq\\xad\\xf7\\x7f\\x08\\x18\\xebP\\xc3\\x13\\x93\\xb7\\xc5|\\xac\\x89\\x06Py\\xacW\\xb5Q\\xd8\\xceH\\x80\\x9cg\\xedQ\\xf0\\x04\\xb6<\\x02x\\xbe\\xf7yj\\xfb\\xff\\xca\\xf1_+&\\t\\x1b\\x92\\x92\\xcb\\xab\\xe9\\xf6H\\x84\\x8du^\\xef/\\xbf\\xfd\\xda\\xbb2\\x1f+`\\xdbg\\xe2\\xba\\n\\xae\\xcc\\x87\\xca\\x08/\\x03\\x19(E\\xed]\\x92\\xa1\\x95)\\x90\\xd1\\xad\\xff\\xfe\\x0b\\xf5\\xd61\\xe1S,0JNn\\xff\\xef\\xff\\xea\\xd52\\xc4\\xe0\\xe3\\xf1_(e6\\xd6\\xaa\\xf7Q/\\xff\\xdf\\xbf\\xe5x\\xaf\\x94\\xa3\\xcd\\xb5\\xd4\\x15{\\x8do\\xf7xX\\x84\\xa1}\\xff~\\xfdZ\\x87\\xa8\\xc18\\xfcWd/\\xf7\\xeb\\xbcWA\\x01>GI\\x10\\x1fOC\\xcbd\\xb5\\xf2\\xb2D\\xef/\\xff\\xee\\xe38\\xaf\\n\\x98bpRw\\xdd\\xfd\\xddY\\xaf\\xce\\x8d\\xa4y\\x90\\xdb\\xad9\\xae!\\xbdI\\xab\\xdd\\xe0\\xcam\\xafGd\\xa9eHn\\x085\\xbf\\xffl\\xa2\\'\\x9a\\xea\\xb6\\x90Y\\xba\\xc2\\x1f(\\xa0\\xbbg\\xaf;\\'\\xbc\\xeey\\x91#\\xce\\xd3\\xcb\\xef\\xff:\"q\\x9cV\\xbd\\xb4a8\\xcf\\xca\\xc7l\\xbb\\xcex\\x8eX\\x02}Wb\\xb6\\xb2\\x9e_o\\xbd\\xdb\\x15z\\xb9P\\x1bv\\xa9k\\\\\\xf2\\xfe\\xff\\xe3N<Ws\\xa1\\xa3]\\xcd|\\xab\\xde\\xe4A\\xdfg\\x1ez\\xb5)\\x9e\\xed\\x83\\xd9DA\\xdb\\xc4\\x8a\\xd6S]\\x92\\xd6\\x8d\\x1b^V:\\x02\\x8b\\xd4\\x96jl!\\xf2\\x81f\\xdb;Sw\\xff\\xf7\\xf6\\xdblMJ\\xba3$\\xe6\\xde\\xfc\\xe3\\xb3aZg\\x01g\\xb9\\xb9\\x11\\xae\\xbe\\x04P*\\x9f\\x15g\\xd9\\xf3\\xd4>\\xecQ\\x81J\\x16,k\\x12+{\\xef\\xfe\\xd8\\x0b\\x12\\xcfL\\x91/\\xff\\xd6\\x95U\\xa6\\x95U\\xa6\\x9a\\xbf\\xffr\\xba\\x86\\xd0\\xa5\\x8cl\\xcdpt\\x84\\x9c\\x1e\\xd5Gb\\xc9!\\x82q\\x9e\\xd5\\xf0h\\x8e<\\x025k]\\x8b\\xee\\xfd\\xfe\\xfbj\\x8f\\x98\\xb2H`\\x9cg\\xf2\\xea\\xf8\\x02G\\x1e\\x016/\\xbd\\xde4\\xf2\\xfb\\xff\\xfb\\xba\\xf4P\\x00!\\xb0*\\x9ff\\x0c\\x1b\\xb7%\\xef\\xbf\\xf6N\\xa8k\\xd7\\x960)\\x8dX\\xb4@5\\xd1H\\xb0\\x81\\xf3\\x11\\xe2\\x03q+\\xd1~\\x8d\\x89\\xc5\\xedTt\\x96\\xba\\xcd\\xd8\\xbfQ\\xd7\\t\\x1cx\\x03y}\\xff\\xff\\xf8\\xc7\\x12Z\\xabU}!\\x1e\\xe4\\xbd\\xff\\xbf\\x1a=P\\xbdg\\x960)\\x9e\\x8b\\xf4\\x84\\x9c\\x1fh\\xf9%\\x9b\\xb3$\\x8b\\xf4\\x1d\\x8b$\\x88H\\xf3\\x7f\\xfb\\xbb\\xbe\\'AU\\x02\\x98\\xcc\\x8b\\xd8&\\x02\\xc4\\xf2bz`\\xa1V\\xfct\\xd3l\\xbd#7F{M\\xd1\\xa1)\\x05\\x8c\\xbc(,,\\xca,d\\xbe\\xff\\xfc\\xacsb\\xf3|3\\xa0\\x8e\\xff\\xff\\xf7\\xe8\\xc0\\x0b\\xed\\x82\\xc6\\xb2\\x85\\x1a\\xdb^\\xa4X\\x95H\\xc3\\x1b\\xa2\\xb1\\xcd\\x8a\\xf0N\\nc\\x95\\x9c\\xe9\\xde\\xdd\\x90\\xf16K\\xdf\\xfd\\xd4\\x96jl\\'\\xd9@\\xb2\\xf0>\\xa1\\xe5\\x8cJb\\xb9\\xc2 6\\x81\\xd1\\xb187.\\xa3\\xa4\\xb3v`\\x8d<\\xbe\\xef\\xff\\x7fz\\xd8\\xc4\\xa6z/\\xf2\\x83[l\\xd3\\xc6\\xd8\\x8f\\xcb\\x05\\xc4\\x88\\xb3u\\x02\\xe7M\\x85g\\x835\\xa7\\x8eVt\\x16jl$\\xc9{\\xff\\xf8\\xc0\\x07\\x1e*\\x97\\xff\\xf5UUV\\x95V\\xfb\\xbf\\xd8\\xe4O7\\xc2\\xca\\x08\\xef\\xbf\\x7f\\xffY\\x18\\xec8V\\x99\\xac,\\xfe\\xd1\\x13%\\xef\\xff\\xeb\\xa4\\x8b\\xcd\\xfa\\xce$\\xc0\\xa6z/\\xd1\\xb98\\xbe]_1`\\x91\\x018\\xcf\\xd4u\\xc8G\\x1a\\x01\\xc5\\xbc\\xf4\\xc7\\x19_\\xee\\xff\\xfe\\xed\\xff\\xb5W\\xccf$@N3\\xf6\\xaa8\\x04\\x8e<jx\\xbe\\xf6y\\x16\\xf2\\xff\\x7f\\xffx\\xd3\\xac\\xc3;\\x00\\xba\\xf8\\x14\\xf0\\n\\xc7\\xe8\\x1c\\xdb/\\x9cv\\x1c+L\\xd6\\x96~\\xca\"d\\xbd\\xef\\xf7T\\xf9\\xbf]\\x961)\\x9e\\x81\\xd1\\xb98\\xb7.\\x8f\\x92Y\\xa9\\xb0\\x0e/\\xd5\\xf3\\x16\\x08\\xd0\\x11\\xe5\\xfe\\xff\\xf6\\xfca\\xa1\\xc39\\x18O\\xe7\\xb0H\\x9d\\xd8\\xa4\\xa5(g\\x03\\x86\\xa5\\xef\\x7f\\xf4i%\\xcb\\x05Y\\xc2\\xffw\\xaa\\xaa\\xad*\\xd2\\xaa\\xb5\\x7f\\xbb\\xafB\\xc8\\xdb\\x9d\\x17\\xe2l\\x9e\\xd9\\xab\\xb9oM\\x90{\\x0c+\\xc5|K\\x91\\x98b\\xbf\\x00\\xc5\\x1b\\xac\\rgW\\x8a\\x85\\xf3\\x93\\x10Z\\xa1\\xec)b\\x90\\xaa\\xf9/\\xff\\xd8\\x9dN!U\\xcb\\x196\\xd3\\xd0\\xd8\\x9ca\\x8f4j\\xdb\\x1a\\xb3Gj\\xff\\xffm\\xb6\\xbf',\n",
       " b'\\x7fm\\x7f4\\xa5\\x1a$%^\\xc8\\xc0l\\xe3\\xc0vE\\xd3\\x85\\x99\\x1f\\xed\\xb6\\xf7\\xb7\\xec\\xbcf\\xdd0\\xa1\\xd9`\\x87d\\xc6[4X\\xdca\\x94P\\x9a2\\x1a&\\xf3\\x14,U\\x8ag\\x15{~\\xc8\\xd0\\x96^\\x05>\\xcag\\x89\\xe1\\x00\\xc6&y\\xa5\\x1a\\xd9\\xe6\\x19\\xd0\\xfc\\xd4\\xdb\\x86\\xe3\\x132/\\x1a\\xd6X\\x19\\xd0\\xf2eS\\x11\\x0fY\\xbc\\xc5\\x0b\\x15a\\xd9\\xc4\\x97\\xb7\\xdbg\\xb3\\x95P\\xa6\\xfb/\\x13\\xc4\\xdd\\xe9\\xf9\\xec\\x94h\\x17\\xbc3SL\\x1f\\xacy\\xbag\\x92z\\xba\\xf7_\\x14\\xad\\xd2x:f\\xc37S\\x07\\xec\\x85ecw\\xb8a\\xd9\\xddQ\\xd8\\x12\\x17[7Q\\x0f\\xbd\\x02Md`6q\\xa1E\\xf1\\xe7l\\xa7\\xb0snZ\\x17_\\x0e\\xcf\\xe4\\xc9\\x19\\xadbxf\\xea`\\xf5\\x86\\xc2{\\x07\\x961)\\x97_\\x0e\\xcf\\xe4\\xc9\\x19\\xc2\\xc4T\\x86\\xcf1\\x1e\\xf5\\xb3u0\\x7f\\x1b\\x94\\xfa\\xb4\\xc6iu\\xf1L\\xfa\\xb9#8X\\x99\\x19\\xca\\xcd\\x9eG\\nW\\xc3=\\xa6\\x0f\\xbe S\\x82cO_)\\xa2@\\xe1M\\x96c\\xcb\\x0b\\xa5\\xef{{w\\xf6\\xef\\xed\\xed\\xed\\xdf\\xdb\\xdb\\xdb\\xdb\\xdb\\xbf\\xb7~\\xfe\\xde\\xdd\\xfd\\xbd\\xbd\\xbd\\xbb\\xfb{w\\xef\\xed\\xdf\\xdb\\xdb\\xbf\\xb7\\x7fooon\\xfd\\xfb\\xfbw\\xef\\xed\\xed\\xed\\xed\\xed\\xdf\\xdb\\xbf\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\x7fon\\xfe\\xdd\\xfb\\xf7\\xf6\\xf6\\xef\\xdf\\xdb\\xbf\\xb7\\xb7\\xb7\\xb7\\xbd\\xbfzB\\x8d\\x11iW\\xd5a\\xb3\\x8f\\x01\\xd2\\x02pv\\x1b\\x06\"\\x0b\\t\\xe3B\\x9fX\\x99\\xb1\\xc0/4\\xa5\\x1a$%VEa\\xb3\\x8f\\x05\\xd8\\xceH\\x97\\xbc\\xe0\\x1b\\xb3\\xb6S\\xc4\\x0f\\x94K6\\xd9\\xa5\\xac\\xa2Yv\\xcd\"\\xfd_1L\\xddJmM\\x1eM\\xdfwv\\xda\\xfd\\xfb\\xd0\\xd81\\x11\\xa7\\x02\\xf1\\xa0c]\\x8a3\\x81\\x14\\xff/( \\xbbq\\xa3\\xd4\\xad\\xef\\xf7|K\\x16%\\x9e\\x99a/\\xff\\xedj\\xaa\\xaa\\xd2\\xaa\\xaa\\xad\\xff\\xdf\\x94\\x10^\\x06~oe\\x8cJb\\xb6B 5\\xcb\\xf4\\x84\\x9c\\x1f.\\x83\\xce\\xea\\xa9\\xa5J\\xa6\\x8d<\\xbf\\xfb\\xff\\xfe\\'o{\\xb0\\xe7;\\x07\\x07U/E\\xfb\\x0e\\xcdM+\\xb5\\x8d=\\x17\\xe1)\\xe1\\xf3Xl\\xe3\\xc0d\\xbd\\xff\\xdd\\xa8\\xecS54\\xa8P\\xd3\\xcd\\xf5\\xa8w\\xff\\xef\\xff\\xcd8\\xeb\"\\xc5\\xe8\\xbf\\x9e\\x99\\xba\\x95*\\x9a+{\\xef\\xfci\\x03\\x8f\\x14K\\xfd\\xfd]U\\xa5ZV\\xff~\\xe5\\x04\\x17l\\xd3\\xa8l\\xb1\\x81LkSd\\xa4=\\xaa\\x8f=3SJ\\x95M\"\\xed_\\xef\\xf6\\xd7\\xfb\\x7f\\xf7\\xe5\\x14\\x1b\\x81\\xa7\\x9a\\xf6\\x1b)\\xe2\\x1f\\x0b\\x18\\x94\\xcbYD\\xb3p4kg9\\x8e\\t\\xa8\\xcbT\\xe4^\\xca\\x08\\xc6\\x16\\xd8\\xda\\xf4R\\xaa\\xf6PGloLk\\x17\\x7f\\xf7\\xff\\xf6\\xff\\xff\\xfe\\xff}\\xff\\xff\\xca\\xa9\\x1e\\x08w\\xbc\\xf1OJV!<\\xdf\\xff\\x1d\\x88l\\xf1\\x0f\\x91\\xb98\\xadej\\xcb\\xb6h\\xd7\\xcb\\xa3\\xe6)\\x9b\\xa9R\\xa9\\xa4[\\xcd\\xf9yE\\x05\\xdb4\\xcby{\\xef\\xfe\\xdfgog\\xb3\\xe2T\\\\/\\xbfz\\xcb\\xeeX\\xb6e\\xadr\\xb6\\x12m\\xac\\xa2Y\\xb8\\x1a5\\xde\\xca\\xbcy\\xe9\\x8b\\xff\\xff\\xff\\x7f\\xde*\\xcc\\xcb\\xaa\\x9c\\x8d\\xe0\\xa4{\\x8bYD\\xb3m\\x99\\xc5\\xf7\\xb2\\xaf\\x1e<\\x9b\\xbf\\xff\\x7f\\xff\\x12\\x81\\x96\\xcd\\tY\\x19[,a\\xd8\\xb4\\xfcb\\xd9w\\x0b\\x02\\xcc\\x8c\\xb1\\xf2\\xf2\\x82\\r\\xb6h\\xf5tn\\x91\\xe6]\\x80\\xebW\\x9ba\\xf1*\\xb6]\\xfd\\xf7\\xff\\xff\\xff\\x7f\\xfe\\xff\\xff\\xff\\xff\\xbfQ\\xde\\xcdk\\xdcj\\xd6\\xb1\\x19\\xf5\\xe8~\\xb2\\x1b\\xec\\xe5da\\xd4\\\\\\x83\\x08\\rnp\\xafg\\xb6FZ\\xa2\\xab4k\\xdbo\\xbb\\xfe\\xef\\xff\\xff\\xff\\xfb\\xff\\xff\\xfdQ}\\xaa\\xa9\\xc9\\x9a\\xd5\\xcb\\xca\\xd87\\x03G\\x91~\\xaeV\\xa2\\x1b\\xb5\\x94P^\\x1a\\x8f\\x1eZ\\xbd\\xf6\\xffm\\xfb\\x10)\\xe2=i\\x8a\\xcb82\\xa4p\\xa5/\\xbfu`\\xdaP\\xfdT\\xe4\\x95\\x96Oe\\x10\\xb2\\xe8\\xec\\x92\\x92Z{\\xe4\\xea\\xfa\\xbb&\\xc7\\x9d\\xac\\xa2\\x82\\xed\\x9a<x\\xd6\\xb2\\x19\\x1eM\\xdf\\xff\\xfe\\xff\\x81A\\x0bm\\x89+#+e\\x8cS\\x16\\x9f\\x8ca\\xbd\\xd2\\xd9T\\x8c1\\xde\\xac\\xa0Y\\xb6\\xcd\\x1e\\xadF\\xe9\\x1d\\x93\\xf9\\x17\\xad1\\x98\\xb6\\x0c\\xa2&\\xbb\\xfb\\xef\\xfe\\xff\\xef\\xdf\\xbf\\x7f\\xfb\\xfe\\xff\\xefmb3\\xed\\xd0\\xf5#\\xce\\xd6P,\\xbc\\r\\x1ey\\xafQU\\x9a0\\x7f\\xaa/\\xd7*q\\xe7k(\\xa0\\xdc\\x0c\\xdeZ\\xbf\\xbf\\xdc\\x06\\xc7\\x8a|\\xa2\\x83p4\\xbd\\xeeZ\\x1cv LD\\x0f\\x98\\n\\x89\\x97\\x99\\n\\xa8\\xd7\\xa8\\xfbL\\xddJ\\x85M\\x1a\\xda\\x8e\\xb9i\\xc7\\x82KJ\\x17\\xdf\\xfd\\xb5\\xfd\\xb6h\\x0b8N#.p.\\xe4s8N\\x13\\xf7\\xab2\\xda\\xa6Z\\xb7\\xbf\\xbf\\xf1.X\\x16`e\\x84\\xbf\\xbf\\xea\\xb4\\xd3J\\xb4\\xaa\\xad+\\x7f\\xfe\\xe6R\\xaay\\xbf$\\xc4\\xa6+d\"\\x0bh\\x1d\\x1b\\x13\\x8b\\xda\\xa0\\xecR\\xae\\xa5J\\xa6\\x8dz\\xbe\\\\\\x04q\\xe0\\x91\\xe5\\xff\\xfb\\xfe\\xf1\\x8ba\\xe7*\\xe9a6\\x81\\xcd\\xb2\\xecG\\x8c\\x15O\\xb1L\\xd4\\xd2\\xa1S5v\\xff\\xffQ\\xd8\\xa6n\\xa5B\\xa6\\x9a\\xa1\\xe1S\\xbf\\xfb\\xf7\\xef\\x9al\\xf3\\x91c\\xd1}\\x9d\\xda\\xa6\\x95*\\x9a+\\xb7\\xfb\\x7fQ\\xc3Dq\\xe0\\x93\\xcd\\xf5\\xaaw\\xff\\xfd\\xff\\xb21\\xe7 \\xc7r\\xfc\\nG\\x1e\\x01\\x15\\xbd\\xff\\xde0\\x01\\xc7\\x8a\\xa5\\xff\\xfa\\xabM*\\xd2\\xad_\\xef\\xda\\x84\\xa8\\x9a\\xa1\\xe5\\x8cJd_\\xcb\\xd7\\xd3\\xd37SJ\\xa6\\x8dmG\\x00\\x11\\xc7\\x82KW\\xdf\\xf6\\xda\\xfe\\xdb}\\xff\\xe6B\\xa2x\\xad\\x9e\\x05<@\\xf2\\xc6\\x053/0\\x95R/g9\\x8e\\x08\\xa5\\x1e\\xae\\xc8\\xbd\\x94\\xd3\\x18Y\\xa3\\x8b\\xda\\xbb YA\\x1d\\xb1\\xbd1\\xab\\\\*\\x91\\xe0\\x1f=9\\xe2\\xad\\x90\\xb3@y\\x7f\\xf7\\x8e\\xc3e<C\\xe4lN,\\xbc\\xc2UF\\xbd\\xaa\\xbeb\\x99\\xba\\x95\\xda\\xee\\xb5\\xea\\xf8\\nG\\x1e\\t\\x1eE\\xee^`*\\xa6[\\xcb\\xfd\\xfd\\x08\\xe3\\xc5w2\\x95v\\xf7\\xb9\\x10q\\xd8l\\x98\\x88\\x1d\\xd8\\t\\xe0\\x8b:\\xaf\\x9c\\xe4\\x81\\xc1\\x9c\\x0ee\\xa7cg\\x82,\\xea5\\xacQ\\x9c\\xb1\\x01Vr}\\xb34\\x9e(_\\x7f\\xef\\xed\\xaf\\xe2f\\xc2x\\x8d\\x16\\xb9\\x01\\x88\"\\xd4\\xa7f\\x13\\x9d1\\xe0\\x9dM\\x12\\x07\\x06`\\xd4\\xe0\\xbc*\\xb1\\x92\\xaf\\xdf\\xdbo\\xf7\\xf5\\x83\\xd5\\xca\\xca\\xb3-U\\xd93\\x04M\\x0cF+2\\xdd\\x80\\x9e\\t\\nU\\xae\\xf6\\xc8\\xf6yjn\\xff\\xff\\xbf\\xfc\\td\\xdd\\x9a\\x12\\xb20\\x18x\\xc51i\\xfe\\\\\\xd1\\x0f\\xa9B\\x9e\\x08\\xb5)\\x97\\xa8\\xdd#\\xb2\\x7f\"\\xf6\\xdb\\xfd\\xff\\xfd\\xff~\\xfd\\xfb\\x7f\\xfe\\xff\\xfb\\xf7Q pfO\\xfa\\x8b\\xe7\\xd6b\\xc2\\xd2\\xa3\\x00\\xf8\\xe6)\\'\\x97\\xbd\\xc8\\x97\\xef\\x98l\\'\\x88\\x1d\\xdaLA\\x16\\xa5_TG\\x85\\x86\\xed)\\xc11\\x04\\xdaV/\\xcfFrE\\x85F\\x08s\\x98\\xa4\\x9eM\\xdf\\xff\\xdf\\xbf\\x7f\\x136S\\xc4yj\\x94&\\x16E\\x9dO\\x9c\\x8d 7\\xd6N\\x93+\\x9e\\x9e\\x16\\x9e\\xf2\\xa9k\\xa8\\x9apfJ\\x90\\x04+\\x03\\xdc\\x8f\\xdf\\xdbo\\xff\\xeb/\\xebC\\xdbUr\\xb2\\xce\\xc9\\xecr\\x15\\xa7`\\x18[aJ\\xb5\\xae\\xc11\\x03Z\\x95\\xc9\\x13\\xbc\\xf2\\xa9_\\x7f\\xff\\xff\\xff\\xf5vAY\\x9d\\xab!YX\\xbeB\\x83l\\xe5\\x9a7i\\xd8& \\x90\\xa5^x\\x93\\xbd\\xb2<\\xd5\\x0b\\xff\\xfe\\xff\\xf1(iy\\xa0,\\xe3\\x01\\x87\\x8c;\\x19v\\xd7\\xa9EN\\xec\\x13\\x0b$)\\\\\\xbe\\x90\\xa4v\\x17`:L\\xadH\\xf0\\xb4\\xf1z\\xfe\\xff\\xfd\\xff\\xff\\xf7\\xff\\xff\\xfb\\xff\\xff\\xdb]D\\x81\\xac\\xcc\\x1a\\x9fB\\x15Z2\\x7f\\xd4_=\\x19\\xc9\\x16\\x15t\\x879\\x8e\\'\\x97\\xbd\\xc8\\x83\\x8f;a<C\\xe7`\\xa7\\x82m(\\x83\\xaf\\x1evZS\\xa4\\xc2\\xc9\\nU\\x1a\\xd6(\\xccX\\x80\\xab\\xa09\\xccp<\\x9b\\xdf\\xf7_\\xdb_\\xc4\\xcd\\x83\\x11\\x176\\xc3\\xa9@\\x9e\\t\\nWk#\\xc4\\'$\\xe2\\xc0jL\\xcf=<-?\\x95\\x0b\\xba\\x89\\x03\\x832Vr\\x08Uc%_\\xbf\\x7f\\x7f\\xbb\\xba\\xe4\\xee\\xc11\\xb0\\xa7v\\nx$)DP\\xbe\\xff\\xf7\\xef|\\xc4\\x02x\\x87\\xce\\xc00\\xb2A\\xd4}\\x9c\\xb7\\x10\\x1b\\xb4\\xec\\x14\\xedy\\xdc\\xcfp\\xb4\\xab8\\x0es\\x1cV\\xaf\\xb7\\x9c\\x17\\xef\\x98\\x86\\xb1`\\xee\\xc0O\\x04\\x85*\\x99n\\xc0O\\x04\\x83\\xaa\\x8dl\\xeeg,BU\\x9c\\x079\\x8e&\\xbd\\x07\\x9e\\x95R\\xea\\x15L\\xda\\xf4|\\x1b#\\x8f\\x00\\x8f&\\xef\\xbb\\xfb\\xf7\\xf6\\xdbbJ\\xc8O\\xa6^4,u)Fp \\x9e\\xee\\xc00\\xb2B\\x95L\\x97\\xbe\\xff\\xe2X\\xb0*\\x94d\\x9b\\x7f\\xffU\\xa5UUUUU[\\xdf\\x7fv\\x02u\\x91jU<\\xdf\\x12l\\xa6+d,\\x0b\\xff\\xff\\xdd\\xefPGe\\x99{7\\xd2\\x12pz\\x07\\xcb\\xab\\xe6)WR\\xa1SH\\xbfW\\xc1\\xb28\\xf0\\x08\\xd7\\xa8\\xeb\\x94\\x8e<\\x12Z\\xbf\\xff\\xef\\xfa\\xf5\\x1c\\n|\\xbf7\\xa9\\x018=\\x03\\xda\\xa8\\xe0R8\\xf0H\\xd7\\xa3\\xe5\\xcaG\\x1a\\x12<\\xbf\\xff\\xdf\\xfdz\\x8a\\x02_/\\xa8t\\x84\\x9cZ\\xe5\\xfd\\xaa\\xbea\\xd9\\xa9\\xa5B\\xba\\x8d}\\x1c\\x08G\\x1a\\x02<\\xbf\\xff\\x7f\\xff-\\x1d\\x02\\xc4\\x18\\x15\\x99}C\\x9bbqz\\x07\\xcb\\xab\\xe6)\\x9b\\xa9P\\xa9\\x9bO/}\\xff\\xb1\\xac\\xf7\\x0b\\n\\xb3\\x80\\xe71\\xc5\\xe6\\xfa\\x1e!E\\xef\\x7f\\xbf\\xd4v)WR\\xa5SO7\\xd6\\xa9\\xdf\\xff\\xef\\xf7\\xb21\\xe7 O@\\xecR\\xaa]P\\xa9\\xa6K\\xdf\\xff\\xba\\xf8\\x08G\\x1e\\x01:\\x86\\xadS\\xbf\\xff\\xff\\xfb#\\x1e\\xb0X\\xf4\\x0e\\xb8H\\xe3\\xd2L\\x97\\xbf\\xfb\\xc6\\x028\\xf1C\\xbe\\xff\\xaa\\xaa\\xabM*\\xad\\xff\\xfd\\xd8\\t\\xd6HR\\xa9\\xd48\\xb1\\x89L\\xbf\\xffm\\xaf\\xdf\\xdf\\xfd\\xbb\\xb0\\x13\\xc16\\x95O\\x15\\xe7l6 qc\\x12\\x99\\x96\\xe4)\\xe0\\x90uv/\\xces\\x14\\x84R\\x8fGd_:H\\xc6\\x16\\xd8\\xda\\xf5v@\\xb2\\x92;czcV\\xaf\\xfe\\xff\\xbb\\xff\\xff\\xef\\xff\\xff\\xbe\\xff\\xff\\xf4*\\x91\\xe0\\x1f=\\xe7\\x9a\\xbd)f\\x84\\xd5\\xff\\xdf\\xbf\\x7f\\xff\\xfb\\xff\\xbf\\xff\\xff\\xdf\\xff\\x15\\x99\\xd3)\\xf5g\\x8aa\\xcc\\xc5\\x88J\\xac\\x10\\xe71\\xc1\\xe6\\xb1_,#\\xb2\\xcc\\xb7\\x97\\xdf\\xffv\\x01\\x88$)T\\x1d\\x1b\\x93\\x83\\xcd{\\xd7\\xcb\\x08\\xec\\xb1\\xeaP\\xf6\\xaa;\\x14\\xab\\xa9@\\xa1\\xa3[Q\\xc0\\xb4\\xe3\\xc0\\x1b^\\xa3\\x80\\x08\\xe3\\xc1#\\xc6\\xb7\\xff\\xff\\xdd\\xdd\\xff\\xef\\xfb\\xbe\\xff\\xee\\xbdG\\x00,\\xb5\\x0fj\\xaf\\x80\\x84q\\xe0\\x92/\\xd0u\\xc8G\\x1e\\t-E\\xde\\xff~\\xfd\\xff\\x7f\\xdf\\xbf\\xdf\\x7f\\xffr\\xe7XM\\xe5\\xcd\\xed\\xaa\\xbe\\x9e\\x99\\xba\\x94*\\x1a5\\xb5|\\xb9H\\xe3\\xc0%\\xa8\\xbb\\xff\\xbb\\xff\\xfb}\\xfb\\xf7\\x7f\\xdf\\xff\\xf9h\\xe6\\xc3\\x0b0+2\\xe6\\xf7.\\xa3\\xcfL\\xdd\\xb5\\n\\x9aE\\xda\\x89W\\xff\\xf1\\xe7l\\xa7\\xb0t\\x80\\x9c\\x16\\xb5\\x01\\x88$)Tk\\xa9\\xc0N\\xb2B\\x95G\\xc7\\t8\\x06LQ\\x98\\xb0\\xb4\\xa8\\xc1\\x0f\\xb3\\x1cCV\\xaf\\x7f\\xfe\\xef\\xffw\\xff\\xf7\\xe5\\xa8\\xa9\\xae\\xc00\\xb2-J\\xbdWQ|\\xf4f,BU`\\x879\\x8aI\\xe5\\xef\\xff\\xef\\x98\\x81O`\\xee\\xd2b\\x1b\\nU<\\xd7\\xbd|\\xb0\\x8f;2\\xe6\\xf4y\\xe0\\x0cX;\\x90\\'Y\\x16\\xa5\\x11\\xf2\\xf1\\xd9cW\\xff\\xff\\xff\\xfb\\xff\\xdf\\xff\\xff\\xff\\xf5\\xea8\\x01e\\xa8q\\xe7l\\x98\\xb0w`\\'\\x82A\\xd5}\\x9c\\x8f\\x0b\\r\\xc5\\xdf\\xff\\xbf~\\xdf\\xff\\xf7\\xff\\xfe\\xff\\xf7\\xe5\\xcf\\x017\\x977\\xc7\\x9e\\x04\\xc4@\\xee\\xc11\\x03\\xdd\\xab\\xe78\\xd6\\x8e\\x0c\\xd69\\x8d_\\xff\\xf7~\\xff\\xf7\\xff\\x7f\\xfe\\xff\\xbb\\xafR:\\x05\\x881\\xb6e\\xcd\\xf7\\xcc6S\\xd8;\\xb0S\\xc1!J\\x8e\\xea$\\rfp9\\x91*\\xff\\xfe;\\x10&\"\\x07v\\t\\x85\\xb7iT\\x19OFr\\xc4\\x05Y\\xc8s\\x98\\xa4\\x86\\xb6\\x9d\\x80ad\\x83\\xaa\\x8dv(\\xceX\\x84\\xaa\\xc1\\x0es\\x1c\\x16\\xaf\\xff\\xe8G\\x1aW\\xbb\\x01<\\x11jU/{\\xbf\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\x7fn\\xfe\\xde\\xde\\xde\\xde\\xde\\xde\\xdd\\xfd\\xbd\\xbd\\xbd\\xbd\\xbb\\xfbw\\xf6\\xf6\\xef\\xed\\xed\\xed\\xed\\xdf\\xdb\\xbf\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\xb7\\x7fooooooon\\xfd\\xfd\\xbb\\xfb{w\\xf6\\xf6\\xf6\\xf7\\xb7\\xd9\\xa4(\\xd1!*\\xfa\\xac6q\\xe0:\\x99bY\\x81\\x86\\x13CMl\\xe4z\\x89\\xedF\\x85?bg8\\x07dZ\\x18\\x0c\\x9c\\xf2\\xf7\\x9c\\x97\\xd7\\xc0\\x86\\xb6r2\\x1dyF\\x88\\xb4\\xaa;\\x14g,-*\\xb0H\\xf8#\\xb2\\xcd\\xc1#\\x9a\\xec\\x96\\xbdb\\x1a\\xf9\\x84\\xa8\\x8d|ko\\xa7\\xa39a\\xe2\\x85\\xff\\xfe\\xdbm\\x7fl\\x90\\xe1Q\\x19s\\x80hG\\x9d\\x9ez3\\x16!\\xb4`\\xbe\\xc8\\xf1\\t\\xc92^\\xff\\x7f\\xb6\\x12\\xc4\\xb3\\xd3\\x0c\\x1d\\xff\\xfa\\xd3J\\xb4\\xd3M4\\xaa\\xb7\\xff\\xfc\\x01\\xbb\\xcd\\xec\\xb1\\x81LW8D\\x16\\xea\\xfa\\x9a\\'\\x17\\xb5Q\\xceY\\xba\\xc2F\\xbd\\x07\\x9d\\xd9\\xba\\x94*\\x9aZ\\xbd\\xff\\xfd\\x93\\xaa\\x1eI\\x81LV\\xc8D\\x16\\xb8:6\\'n\\xda\\xa8\\xe9,\\xdda\\x1b^\\xa3\\xaeB8\\xf0\\x08\\xf2\\xf7\\xdf\\xbe\\x91\\x1dCe\\x8cJb\\xb6B .\\xe0\\xe6\\xd8\\x9c\\x1e\\xd5\\x1fN\\xea\\xb9\\xd5\\n\\x9a4\\xf2\\xf7\\xfb\\xf70\\x95ST>\\xe3\\x02\\x98\\xad\\x90\\x88\\x0e\\xe0\\xe7\\t86\\xd5\\x07\\x9e\\x95u+\\xb54k\\xd0p\\x01\\x1cx\\x04y{\\xff\\xf7\\x00\\xd8\\xecQ\\x9c\\xb1\\xe6\\xf8YI\\x1d\\xef\\xff\\xe3\\x00\\x1cx\\xaa_\\xff\\xdai\\xadU\\xa5o\\xff\\xd9\\xf5\\x9c\\xb1\\tRrMP\\xe2\\xc6%1\\xae\\x8d\\x89In]_1L\\xdc\\xea\\x85M\\x1a\\xf5|\\x01#\\x8f\\x04\\x8dz\\x8e\\xbe\\x88\\xe3\\xc0#\\xcb\\xff\\xfe\\xed\\xf8\\xc5\\xb2\\xf3\\xb9\\x9c\\xb1\\tRr\\xfb#\\xc2\\xc3~\\x81\\xce\\x01\\xd8\\x8f\\x18*\\x9e\\xb1L\\xddJ\\x85M2_\\xff\\xaf\\xed\\xaf\\xef\\xfe\\xfa\\x8e\\xc3\\xb3s\\xaa\\x144k\\xe8\\xe0R8\\xf0I\\xe6\\xbb\\x99J\\xa9\\x91\\x1b\\x16\\x95\\xff\\xfa\\xc5\\x19\\xcb\\x10\\x15g\\x04\\xf1^\\xaar\\x06n\\xd9\\x99yu\\x1ezf\\xeaT\\xaah\\xd7\\xa0\\xe0B8\\xf0I\\x17\\xea8\\x14\\x8e<\\x12<\\xb5\\xbf\\xfe\\x14\\xc6\\xc4l+\\xf1*\\xaeV\\xaa\\xf9\\x8af\\xeaT\\xaaiiC\\x7f\\xff~\\xf2\\x80/\\xe6\\xbd\\x96\\xea\\xfc\\xc3j\\x83(\\x81\\xad\\xff\\xff\\xff\\xd8s1ceV\\x01\\x06V\\r|W\\xaa\\x95J\\x87\\x97\\x80\\xd7\\x0c\\x94\\x1a\\xdb\\x14My\\xa5\\x00]X\\x9d\\xad\\xd8.\\x16\\xbb!\\xeb\\x10\\xa3\\xd8\\xa2_\\xef\\xfb\\xf7\\xb1FrHJ\\x93\\x82\\x0c\\xac\\x1a\\xe4\\x0b\\x04c)\\xb9\\xba>\\x02\\x11\\xc7\\x80O\\x17\\xafe\\x13b\\xe2\\xbe\\tq\\xd8\\xa31b\\xff\\xef@8\\xf1^\\xc5\\x19\\xc94U\\x9c\\x12\\xf7\\xbc\\xe0\\x1d\\xf1!\\xc39\\x19\\x0e\\xdc\\xa3D\\x80\\xaa;\\x14f,BU`\\x90sX\\xa7\\xb5\\x80G5\\xac\\x96\\xbe\\xc45\\xf4\\xa5T\\x8b\\xd4%\\xdf0\\xe6bG\\x93w\\xff\\xfbm\\xb6\\xdbl\\x90\\xd6\\xac\\xb49\\xb7\\xbap\"\\xecQ\\x98\\xb0\\xb4\\xaa\\xc0|\\xe4x\\x80\\xda\\xb7\\xbf\\xff\\xdb\\t \\xb3\\xd3\\x0c%\\xf7\\xfe\\xaa\\xaa\\xb4\\xaa\\xad4\\xaa\\xb7\\xdf\\xfe5\\x1d\\xaa\\x1b,`S\\x1a\\xb1h\\x82\\xf4\\x0em\\xeb\\x8bmPt\\x96\\xa9\\xb0\\x91\\xafG\\xd3\\xbb7R\\xa5SG\\x97\\xbf\\xff\\xb2|\\xdf\\x12`S\\x1a\\xb2\\x11\\x05\\xae_\\xa3z\\xe0\\xf9u\\x1d%\\x9b\\xac\\xd4k\\xeb\\xe0\\t\\x1e\\xe0\\x92\\xd5\\xef\\xff\\xf5\\x88\\xf3z,$\\xa6+\\x9c\"\\x03\\xd0:@N\\x0f\\x97Q\\xd8\\xa6n\\xa5B\\x86\\x8d<\\xbd\\xff\\xfb\\xa1*\\xa7P\\xd9c\\x12\\x98\\xaep\\xb0;\\x83\\xa3bp{T|\\xc5*\\xa6\\x94*\\x1aE\\xfa\\xbe\\x00\\x91\\xc7\\x80G\\x97\\xbe\\xff\\xf0\\x0b\\x8e\\xc5\\x19\\x8b\\x1eo\\x85\\x94\\x91\\xde\\xff\\x7f\\x1aH\\xe3\\xc5R\\xff\\xee\\xb4\\xae\\xaa\\xabJ\\xdfw\\xf6\\x1c\\xceXZU`\\xbc\\xdf\\x16\\xe2S\\x1a\\xe6\\xde\\xb86\\xd5\\x1f\\x01\\n8\\xf0\\x08\\xd7\\xae\\xaf\\xa2\\xd8\\xf0\\x08\\xf2\\xff\\xef\\xdf\\xba1l9\\xc0\\xa7\\xec9\\x9c\\xb1\\x01U\\x82\\xf9\\x88\\xd1a\\xbd\\xa0s\\x80v)WR\\xa5SL\\x97\\xff\\xf7\\xf6\\xd7\\xf7\\xffvL\\xd7\\x1d\\x96{\\xecW\\xab\\x95\\'\\x1d\\xa6YX\\x9d\\xadd\\xbc\\xbe\\xff\\xe4\\xcdq\\xea\\x12\\xa9\\xbd\\xfc\\xd7\\xd7rOC\\xb5X\\x8e3\\xdc\\xcaUL\\x83\\x18\\xbf\\x99mQ\\xe5\\xff\\xfd\\x8a3\\x16 *0\\x1b\\x15y3\\\\vY\\xef\\xaa\\xf93m\\xf6`*\\xa3\\xd3\\xbe\\xff\\xe7\\xa39\"\\xc2\\xa4\\xe5\\xac\\x84\\xd7kfC\\x8f;V\\xaf\\xbb\\xbb=\\x19\\xcb\\x1b*NY\\x02\\xc1\\x1a\\x8e\\xa17aV\\xd3\\x0eg,Cj\\xc1Z\\xf1w{\\x8dtg5\\xf8&\\xdf1Fr\\xc5\\xff\\xff\\x04q\\xe3{\\x14g\\xb8\\x84\\xaa\\xc1^\\xf7 \\x0e\\xf8\\x10\\xe1\\x98\\x8c\\x87nQ\\xa2Ctv(\\xcfq\\tU\\x82A\\xca\\x02n\\xd6\\x01\\x1c\\xd7d\\xc5\\xfaDE\\xde\\xa0*#_\\x00\\xd8\\xecQ\\x9c\\x93f\\xef\\xff\\xf6\\xdbk\\xf1\\x86\\x87\\x0c\\xe4e\\xf5\\xb2\\xd2\\x80\\x97\\xa5\\x05gb\\x8c\\xe5\\x88J\\xac\\x17fL\\x1d\\x11\\x15\\xbd\\xff\\xfe%\\xcb\\x12\\xcc\\x8c0\\x97\\xff\\xea\\xaa\\xb4\\xaa\\xad4\\xaa\\xad_\\x7f\\xf8$SJ\\xa2\\xd2[8\\x1c\\t<\\xdf\\x92bS\\x15\\xb2\\x11\\x05\\xb4\\x0e\\x8d\\x89\\xc5\\xedU\\xf2J\\xae\\xb0\\x12/\\xd5\\xf4\\xfb\\x9b\\xb6\\x9bCG\\x97\\xbf\\xdf\\xd97\\x9b\\xf2\\xc2Jb\\xb6B \\xbd\\x03Q\\xb18=\\xaa\\x8e\\x92\\xcd\\xd9\\x825\\xea\\xf8\\x00Q\\xc7\\x8d7\\x97\\xbf\\xffk\\x11\\xe6\\xf8\\xb1\\x81LW8D\\x05\\xe8\\x1d\\x1b\\x13\\x8b\\xda\\xa8\\xf3\\xd2\\xae\\xa5\\n\\x86\\x8d<\\xbd\\xff\\xfb\\x98\\n\\xa9\\xe6\\xfc\\xb1\\x81LV\\xc8D\\x17\\xa0tnJK\\xda\\xa8\\xfbL\\xdc\\xea\\x85M\\x1a\\xda\\xbe\\\\\\xa4{\\x82KW\\xbe\\xff\\xb8&\\xc7\\x9d\\xcc\\xc5\\x8e\\xa1\\xc2\\xcai\\xde\\xffw\\x8c\\x00q\\xe2\\xa7\\x7f\\xbb\\xd5i\\xa6\\x95U\\xab\\xff\\xbd\\x8a3\\x96!*\\xb0I\\xe6\\xfc\\xb7\\x02\\x99\\x17\\xd2\\x1a\\xe0\\xf9t}=3s\\xab\\xb54k\\xd4p!G\\x1e\\x01\\x1e_\\xff\\xff\\xfcb\\xd8y\\xe8\\xceX\\x80\\xab9vd\\xc1\\xd3\\x1e\\x81\\xa6\\xd9v#\\xc6\\n\\xa7y\\xddWR\\xa1SL\\x97\\xdf\\xee\\xfd\\xfd\\xb6\\xff~\\x89\\x9bc\\xb2\\xcfO\\xcd}\\x1d\\x92z\\x1d\\xac\\x029Q\\x8b]\\x96\\xef;&\\xd7d=b\\x06J\\rz\\xa9\\xc9P\\xca\\x10\\xda\\xc6\\xa2_\\xef\\xf2f\\xb8\\xf5)U\\x1e\\x9e\\xc5z\\x86\\xd58\\xcd\\xe7{\\xdf\\xff\\xb2f\\xd8\\xec\\x91\\xf3)P\\xf6k\\xeaB\\xaaq\\x9f\\xaa\\x95J\\x87k\\x00\\x8e\\xc81k\\xb2^nM\\xac@\\xcan/\\xd5\\xca\\xd4\\x06\\xe46\\xb2\\ro\\xfe\\xea\\x01\\xc7\\x8a\\xf13m\\xf3%\\xef\\xaa\\xf7\\xa7\\xc6~L\\xd7|\\xc9\\x1e\\xa1*\\xa7\\x8b\\xd13\\\\z\\x84\\xaa\\x8f~3\\xf8\\x05\\xc7\\x9e\\x8c\\xe5\\x8b\\xde\\xe4A\\xdf\\x12\\x1a\\xd9\\x88\\xf4v\\xe5\\x1a$%A\\xd8\\xa39b\\x02\\xae\\x92>E-\\x86 \\xc4\\xac\\xb5\\x80GE\\xf6Y\\xaf[\\x1a\\xbd@UF\\xbe\\t\\xb1\\xe7\\xa39b\\xd4\\xdd\\xff\\xfd\\xfb\\xf7\\xf6\\xc9\\x0e\\x19\\x88\\xcb\\x9be\\xa8\\xe8\\x06!<\\xac\\xec\\xc5\\x85\\xa5Y\\xcb\\xb3\\x16q\\x82d\\xbd\\xff\\xdf\\x12\\xc5\\x81f\\x06H\\x97\\xff\\xf6\\x95iUZU\\xa5Z\\xbf\\xf7\\xf8\\xd4u(\\x8b0\\xb5\\x905\\x88\\xf6o\\x8bRS\\x15\\xb1h\\x8d\\xda\\x06\\xa4\\x04\\xa4\\xb6\\xd5\\x07\\xd1f\\xec\\xc9\\x1a\\xf4\\x1d\\x8aU\\xd4\\xa0P\\xd1\\xe5\\xef\\xff\\xec\\xb7P\\xf2\\xc6%1\\xab\\x16\\x88\\x0fE\\xfa6\\'\\x15\\xedTt\\x16n\\xcc\\x91\\xafQ\\xc3dq\\xe0\\x12\\xd5\\xef\\xff\\xda\\xc4u\\r\\x961)\\x8a\\xd8\\xb5\\x85\\xb4_\\xa4$\\xa4\\xb6\\xd5_N\\xec\\xf6\\x95-3ko\\x7f\\xfe\\xe6R\\xaal\\xdf\\x961)\\x8a\\xe6\\xb5\\x85\\xb4_\\xa4$\\xed\\xdc\\xba\\xbe\\x9e\\x9a\\xeaT(i\\x17\\xea\\xf9p\\x11\\xc7\\x80G\\x97\\xbf\\xfb\\xf0K\\xbeb\\x8c\\xc5\\x8e\\xa1\\xd7\\xb2\\x92;\\xdf\\xfd\\xb8\\xc0\\x07\\x1e*\\x97\\xdf\\xba\\xd3J\\xaa\\xabJ\\xdf\\xff\\xd9\\xcb\\x10\\x15X\\x04\\xf3~X\\xc4\\xa6E\\xea6\\'\\x06\\xda\\xa8\\xecS7R\\x85SF\\x9e^\\xfb\\xf7\\xef\\xe3\\x16\\xc3\\xb3\\x16\\xc3k8vr\\xb2=OE\\xf8Jv\\xfb\\x14\\xab\\x9d\\xa5SL\\x97\\xff{\\xfbm\\xb6\\xff\\xfd\\xc1\\x1cx\\xa7\\x1c\\x0c\\xe1\\x98\\x8c\\x07^Q\\xa1\\xc2T\\x1d\\x8a3\\x96\\x16\\x95X$\\x1exI\\xbbX$s]\\x92\\xd7\\xacD]\\xff\\xff\\xff\\xbb\\xef\\xff\\xfe\\xfb\\xbf\\xff\\x7f\\xff\\xff~\\xef\\xdd\\xff\\xff\\xbf\\xef\\xcc\\x05Sk\\xe0\\x17}=\\x19\\xcb\\x0f2f\\x1b[O{W\\xbd\\xe7\\x00\\xe3\\x92\\x1c+\\xa6\\x03\\xaf(\\xd1\\x16\\x95Gt\\xb6Y\\x81\\x86\\x12\\xd3%\\xad\\xd0G5\\xf0\\x0b\\x8e\\xc52\\xa5\\x86\\xbb\\x0ef,@U\\x9c\\x079\\x8e+Sw\\xff\\xf7\\xf6\\xd7\\xe3\\r\\x0fk#\\r8\\x07zB\\x8d\\x11iW\\x94\\x10\\xf1\\tFpuz\\x91bU\\xd3\\x0c&K\\xdf\\xfb\\xf8\\x97,K22\\xc2_w\\xea\\xaa\\xb4\\xabJ\\xb4\\xaa\\xaa\\xee\\xee\\xeb-\\xe6\\xf7S\\x12\\x98\\xad\\x90\\x88+\\xb8:7\\'\\x06\\xda\\xab\\xe4\\x96n\\xb0\\x11\\xad\\xa8\\xe0\\x128\\xf0Ij\\xff\\x7f\\xffx\\xc5\\xb2\\xf0\\xab\\xa3>B9h\\x93\\x12\\x99\\x92\\xf7\\xff\\xea\\x11\\xbb\\xcd\\xf1c\\x12\\x98\\xd5\\x90\\x88\\x0e\\xe0\\xd4nN/\\x97W\\xc9*\\xba\\xc0F\\xbdGa\\xd9\\xba\\x94\\xda\\x1a<\\xbf\\xff\\xff\\xfcN\\xd9|\\x12m*\\x8b1\\x0c\\xe0p$\\xe1D\\xd0\\x94\\xf0\\xd2\\x11\\x8b\\xa0\\xb3ve\\xd6\\xafd\\xe4\\xbd\\xff\\xff\\x00\\xdb\\xe9\\xe8\\xcfq\\xd48f\\xe9\\x1d\\xff\\xfb\\xbb\\xf8\\xc5\\xb2\\xdc\\x03q\\xd8$\\xd6T\\x8e\\x14\\xa7\\xd9\\xc8\\'\\xe7Nm\\xee\\x92\\xd2^\\x95\\x95\\x9e\\x81\\xa6\\xde\\xf6\\x1c\\xceXXU\\x9c>r<,\\xc1nK\\xdf\\xdf\\xf6(\\xcc[\\xb2\\xa3\\x04\\xf8\\xe68\\xbc\\xdfz\\xefPGe\\x99m|\\xb3X\\x89\\xea\\x8b\\xf9s\\xad%\\xf2\\xda\\xf9z\\xa6\\x05\\x880+2\\xe2U\\xf7\\xff\\xf7\\xe8\\xc5\\xb2\\xe71\\xc5\\xe8\\xbe\\xbb\\x01<\\x12\\x14\\xad\\xeb(\\xd2\\x0c\\x02d\\xbd\\xff\\xde4\\x91\\xc7\\x8a\\xed\\xf7\\xfe\\xabM*\\xd3J\\xdf\\x7f\\xf4\\x88\\xd9\\xbd\\x960)\\x8a\\xd9\\x08\\x80\\xf4\\x0e\\x8d\\xc9\\xc5\\xf2\\xea>\\xba\\xaeuJ\\xa6\\x8dZ\\xbf\\xff\\xee\\xff\\x13\\xb6\\x1e\\xb1\\xd6E\\x84\\xda\\x07\\x9cF-IU\\xda\\x07\\xd6\\xa76\\xf7g\\x8f\\x18*\\x9fa\\xd9\\xa9uJ\\xa6j\\xde\\xff\\xff\\x98J\\xa9\\xe6\\xf4X\\xc0\\xa6+\\x9a\\xd6\\x07\\xa2\\xfa\\x90\\x96\\x86\\xda\\xab\\xe6\\x1dW:\\x81SF\\xbd_.\\x128\\xd0\\x11\\xe5\\xff\\xff\\xff\\xc60\\r`\\xaa`\\x89\\xe8\\xbf6\\xcb\\xcf\\x1e0U?=*\\xed\\xa0WQ[\\xdf\\xff\\xe7\\xa31l%Y\\xc9<\\xdf\\x961\\xb3\\x15\\xb2\\x16\\x15\\xff\\xfb}\\xfcb\\xd8}s9$%Y\\xcb\\xd4G\\x88\\r\\xfa\\x076\\xcb\\xcf\\x1e0\\x15>\\xc53SJ\\x95M2_\\xff\\xff\\xfa1\\x81s\\x80\\x9c\\x1a@\\xe0\\xa1\\'\\xa0s\\x81v(\\xccH\\xb0\\xaa\\xc1>9\\x8aK%\\xfe\\xfe\\xfd\\xfb\\xfb\\xed\\xff\\xacF\\xc5|\\x02;\"G\\x9e\\\\\\x86\\xe0\\x91Og\\x9b\\x17\\xafg\\xb7y\\xf5\\xca\\x84*\\x0e\\xb5\\x82G*G1\\xc0\\xf3 );\\xfd\\xdfR\\x95\\x13\\xc5z9R\\xa1\\xda\\xc1&\\xaa1k\\xb2\\xcf;!\\xe9\\x102Pkj\\xec\\x94\\xdc\\xa9\\r\\xac\\x83[\\xff\\xfc\\xf4f,@U`\\x93\\xc5w\\xafm\\x08\\xec\\xb1\\xfa\\x87}\\xa8p\\xa8\\x8c5\\xb1F\\x88\\xb4\\xa8<\\xf4f,BT\\x9c\\x11\\xf2\\xf1\\xe7\\x9c]\\xff\\xdf\\xff\\xdd\\xff\\xff\\xf7o\\xaf\\xce\\x01;\\xf5\\x0e9!\\xadQ\\x19>lZ\\x89\\tU\\xf3\\x14g$\\x84\\xab8\\x1b\\xe3\\x81\\x14^\\xfd\\xfb\\xff\\xfb\\xff\\xff\\x7f\\xfd\\xf9-&\\xdf\\xcd\\xf1\\xc1\\rl\\xe4`:\\xe2\\x8d\\x0e\\x12\\xab\\xe9\\xdc\\xceX\\x84\\xaa\\xc1 \\xe4\\xb4\\x97\\x8b\\xbf\\xfb\\xbb\\xff\\xfb\\xfe\\xef\\xfb\\xfb\\xf4t\\x0bV\\x9cV?P\\xef\\x81\\x0e\\x15\\x91\\x83\\xe5\\xe5\\x1a\"\\xd2\\xd1\\xd8s1b\\x12\\xac\\xe4\\x8f\\xb5\\xcd\\x86 \\xc0\\xac\\xbe\\xff\\xfe\\xff\\xfe\\xef\\xfb\\xff\\xf1)Ga\\xcc\\xe5\\x88J\\xac\\x00\\xe71\\xc4\\xa2e\\xa1#\\x9a\\xec\\x96\\xbdb\\x1a\\xdc\\xc2TH\\xbf\\xa4\\xbb\\xe6(\\xceX\\xb5\\x7f\\xf7P\\x8e<Si\\x11\\x17\\xb9\\x80\\xaa\\x8dy\\xf5\\x9c\\xb0\\xb0\\xaa\\xc1%\\xefy\\xc1}\\x1ezf\\xe8\\xe3!\\xd4\\xe0\\x18\\x82B\\x95|\\xc3t\\xb0\\x92\"e\\xa9\\xe8\\xce[\\xb2\\xab\\x00\\x8dv(\\xcc[\\x01Vr\\x1c\\xe68\\x9e(_\\x7f\\xef\\xdf\\xbfz)\\x9b\\xa3=\\xe7\\x02\\xd8\\x99\\xb7XI\\x113\\xceS\\xbb7Q\\x16\\x8e\\x14\\xafr\\xfc\\xdb\\x0e\\xec\\x14\\xeb$)D\\xc9{\\xef\\xfe%\\xcb\\x02\\xcc\\x8c\\xb0\\x97\\xbe\\xfe\\xaa\\xad*\\xaa\\xaa\\xaa\\xaa\\xb7\\xdf\\xfc\\xf4g,BU\\x9c\\x93\\xcd\\xf1n6cY\\xc2\\xcd\\xbe\\xee\\xef\\xdf\\xe2v\\xcbX\\xa39cEY\\xcb\\xd6F\\x90\\x1b\\xf4\\x0ep-b<`\\xb4\\xfc\\xf4\\xcd\\xd4\\xa9T\\xf7%\\xff\\xdd\\xffx\\xc6\\x05\\xf5\\xb1)/98\\xab:z\\x06\\x9c7\\xb1Fb\\xc2\\xc2\\xa3\\x049\\xccpd\\xbd\\xff\\xdf;\\x99\\xcbtU`\\x9f\\x1c\\xc7\\x17\\x9b\\xef_,#\\xce\\xcc\\xb6\\xb7,\\xe0E\\x96\\xd7\\xcb\\x9e\\x02m\\xeaj\\xf9h\\xe6\\xc3\\x0bO+2\\xe2U\\xff\\xff\\xfd\\xf1;e\\xcec\\x83\\xd05\\xd8\\xd6 \\x8bR\\x9e\\xa2<-\\xa4\\x99/}\\xfb\\xc6\\x908\\xf1T\\xbf\\xff\\xb4\\xd2\\xaa\\xaa\\xabW\\xfb\\xfa\\x9c\\x04\\xf0E\\xa9T|\\xc4)`\\x1cD\\xcdP\\xf2\\xc6%1\\\\\\xd6\\xb0/\\xfd\\xff\\xdf\\xc6-\\x97\\x9d\\xb7XId\\xcd\\x9c\\xa7\\xa5]DX\\xe1J\\xf7\\x06\\xa0\\xb3ve\\xae\\xc1O\\x04\\x85(\\x9d\\xcb\\xe9\\xb6\\x1b<x\\xc0V;\\xff\\xff\\xdd\\xecR\\xae\\xa5B\\x86\\x8a\\xe8\\xc5\\xb2\\xd4lN\\x0e@\\xe2\\xae\\xef\\xa0x\\xe0\\x1b;\\x99\\x89 -`\\x87\\xd9\\x8aI]\\xff\\xed\\xb6\\xda\\xfe\\xff~\\x92\\x1c3\\x91\\x80\\xee\\xc0N\\xb2-J\\x8eX\\xc3\\xb0>`\\x89%\\xcb\\xc5{W\\xff\\xfb\\xef\\xef\\xde\\x92\\xc6kU~m\\x96\\xe7\\x01\\xb3\\x8f\\x01\\xf3\\xa6\\x95\\x9c%\\x0b\\n\\x7f \\x9fcB\\xe9L\\xc3\\xb1\\xb9\\xa9\\xa5J\\xa6\\x9b\\x01e\\x17\\x7f\\x7f\\xbf\\xff\\xf5\\xfa\\xd6f\\xac\\xe0\\xba\\xd5)\\xeeY\\xba\\x18Z}\\xb3\\xb1Fr\\xc4%V7m/LxU\\x0cU\\x9c\\xb5\\x89F\\x85?bgHQ\\xbc\\xc0\\xe9^\\xfe\\xff\\xee\\xef\\xfa\\xfd\\xd8\\xd9\\xe9fbr\\x11n\\x8b7X\\x08\\xf3\\'\\x89\\xf13\\xc7ND\\xc6\\x02H[\\x1c\\x0bi\\x1dX,z\\x07a\\xd9\\xba\\x95\\r4\\x8b\\xef\\xef\\xbf\\xef\\xfb\\xed\\xb4\\xc7\\x85\\'@\\x12\\x17\\xc16<\\xeef$']"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#fitting pipeline for the dummy classifier \n",
    "re1 = RankEncoder(extractor=ExtractContext(size=3),\n",
    "                 estimator=sklearn.dummy.DummyClassifier(random_state=0))\n",
    "\n",
    "huff1 = HuffmanEncoder(alphabet = ALPHABET)\n",
    "\n",
    "compress1 = sklearn.pipeline.Pipeline([('RankEncoder', re1),('HuffmanEncoder', huff1)])\n",
    "compress1.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O99vPY0YJYfn",
    "outputId": "f2b40229-ac31-4cc6-a8be-9a5f98dd764f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy: trn=1.609528 tst=1.609788\n",
      "dtree: trn=2.107778 tst=1.931807 time=1.8\n",
      "rf:    trn=3.343363 tst=2.334267 time=4.8\n",
      "lr:    trn=3.394049 tst=2.240394 time=20.0\n",
      "ab:    trn=3.601873 tst=2.259632 time=8.6\n",
      "hgb:   trn=1.962452 tst=1.840773 time=7.6\n",
      "svm:   trn=1.765537 tst=1.748557 time=10.6\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print('dummy: trn=%f tst=%f' %(compress1.score(train), compress1.score(test)))\n",
    "print('dtree: trn=%f tst=%f time=%.1f' %(decision_tree.best_estimator_.score(train), decision_tree.best_estimator_.score(test), decision_tree.refit_time_))\n",
    "print('rf:    trn=%f tst=%f time=%.1f' %(random_forest.best_estimator_.score(train), random_forest.best_estimator_.score(test), random_forest.refit_time_))\n",
    "print('lr:    trn=%f tst=%f time=%.1f' %(logistic_regression.best_estimator_.score(train), logistic_regression.best_estimator_.score(test), logistic_regression.refit_time_))\n",
    "print('ab:    trn=%f tst=%f time=%.1f' %(Aboost.best_estimator_.score(train), Aboost.best_estimator_.score(test), Aboost.refit_time_))\n",
    "print('hgb:   trn=%f tst=%f time=%.1f' %(HGboost.best_estimator_.score(train),HGboost.best_estimator_.score(test), HGboost.refit_time_))\n",
    "print('svm:   trn=%f tst=%f time=%.1f' %(SVM.best_estimator_.score(train) ,SVM.best_estimator_.score(test), SVM.refit_time_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnKYZLaWJYfo"
   },
   "source": [
    "**Question.** \n",
    "* Which classifier do you think would be most useful in a real command-line compression tool? Why?\n",
    "* Which classifier would be the least useful in a command-line compression tool? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUdCnrfCJYfo"
   },
   "source": [
    "Your answer here.\n",
    "\n",
    "The least favourite can be the dummy classifier. Because it just predict based on most frequent alphabet in the text and it does not help.\n",
    "\n",
    "The most favourite can be ADaboost, however it has long training time but Since it uses boosting method, it can help to predict the next symbol better and compress the text really better.\n",
    "\n",
    "My answers are based on the test performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3hphDSiJYfo"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q5 (BONUS) &mdash; Compress MORE!!! [5 marks]\n",
    "\n",
    "<table><tr><td><img src=\"img/more1.png\" width=300/></td><td><img src=\"img/more2.png\" width=300/></td></tr></table>\n",
    "\n",
    "Up until now you've used relatively small training sets, involving only a handful of (truncated) files. You probably also found that the best hyperparameters do not use of very much \"context\", and so the predictions are primitive.\n",
    "\n",
    "For this bonus question, you should **\"go all out\" maximizing the compression ratio**, even more than you did so in Q4. \n",
    "\n",
    "Specifically, here are the requirements:\n",
    "1. **Python packages.** You cannot rely on new Python packages. Only scikit-learn and its dependencies. \n",
    "2. **Training data.** You can train on any Python file from the scikit-learn 0.24.1 source code. (It is too large to train on all of it, so choose some files.)\n",
    "3. **Estimators.** You can only use built-in scikit-learn estimators, alone or in combination. You *can* use estimators that were not yet convered in the assignment, however.)\n",
    "4. **New features.** You are encouraged to introduce new hand-engineered features alongside the context features. See [*FeatureUnion*](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) for example. \n",
    "5. **Features from classical compression algorithms not allowed.** A caveat to #4: new features should be based on the semantic meaning of symbols or words, like whether previous symbols were digits, or whether the previous symbols were a particular Python syntax elements (keywords, comments, etc), etc. If you instead try to incorporate classical string compression techniques, then you make the machine learning component trivial and that defeats the purpose of the exercise.\n",
    "\n",
    "**Grading.** Your final tuned compression pipeline should be saved to a file, which the TA will load and run on a separate withheld test set. Your bonus grade will be computed by scaling your rank among all other students who submitted a bonus question. For example, if 23 students completed the bonus question, and your compression ratio was the 3rd-best (21 of 23), then your grade would be 21/23 = 4.57 extra marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSfmt1myJYfp"
   },
   "outputs": [],
   "source": [
    "# Load your training set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIN0oV2YJYfp"
   },
   "outputs": [],
   "source": [
    "# Define your own unique compression pipeline architecture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GhVqEMVJYfp"
   },
   "outputs": [],
   "source": [
    "# Perform hyperparameter search on your pipeline architecture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSZ33K11JYfq"
   },
   "outputs": [],
   "source": [
    "#FINAL_SEARCH_FILE == 'yourname-final.joblib'   # <-- Put your name here\n",
    "# Save your model to FINAL_SEARCH_FILE here. INCLUDE THE FILE WITH YOUR SUBMISSION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5JI5Kb5JYfr"
   },
   "source": [
    "**Edit and run the code cell below** to demonstrate the performance of your final model on your own test set. The TA will replace *FINAL_ZIP* and *FINAL_FILTER* with a withheld test set, not necessarily from scikit-learn's source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaQXBP4CJYfr"
   },
   "outputs": [],
   "source": [
    "# Uncomment these lines and complete them.\n",
    "\n",
    "# Load a final test set to try compressing\n",
    "#FINAL_ZIP = ...       # The location of a ZIP from which to load test files\n",
    "#FINAL_FILTER = ...    # A filename filter; THE TA WILL REPLACE THIS WITH MYSTERY TEST SET\n",
    "#x_final_names, x_final = read_textfiles(FINAL_ZIP, FINAL_FILTER)\n",
    "\n",
    "# Load and score the search object that performed the Q5 hyperparameter search.\n",
    "#search_final = ...            # Load FINAL_SEARCH_FILE\n",
    "#search_final.score(x_final)   # Return the compression ratio on the test files"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ex2UG6-9JYdg",
    "hh_oSmhyJYdh",
    "w4662Se3JYec",
    "lo0Z9YlBJYfG"
   ],
   "name": "a1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
